{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN metric evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib  inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare initial set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000 # number of epochs of training\n",
    "batch_size = 1000 # size of  the batches\n",
    "lr = 0.0002 # learning rate\n",
    "b1 = 0.5  #  adam: decay of first order momentum of gradient\n",
    "b2 = 0.999  #  adam: decay of first order momentum of gradient\"\n",
    "n_cpu = 8  #  number of cpu threads to use during batch generation\n",
    "latent_dim = 2 #5 # dimensionality of the latent space\n",
    "img_size = 2 #5 # size of each image dimension\n",
    "channels = 1 # number of image channels\n",
    "sample_interval = 400 # interval betwen image samples\n",
    "outf = 'models3' # save models at each iteration during epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"images_generated3\", exist_ok=True)\n",
    "os.makedirs(outf, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (channels, img_size, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    #'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, list_IDs, labels):\n",
    "    #'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "    def __len__(self):\n",
    "        #'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        X = torch.load('my_data/' + ID + '.pt')\n",
    "        y = self.labels[ID]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 4, normalize=False),\n",
    "            *block(4, 8),\n",
    "            *block(8, 16),\n",
    "            *block(16, 32),\n",
    "            nn.Linear(32, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(4, 1),\n",
    "            #nn.LeakyReLU(0.2, inplace=True),\n",
    "            #nn.Linear(8, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "[partition_list, labels] = pickle.load(open('train_test_info.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = Dataset(partition_list['train'], labels)\n",
    "test_dataset = Dataset(partition_list['test'], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(training_dataset, batch_size=batch_size)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Configure data loader\n",
    "os.makedirs(\"../../data/mnist\", exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../../data/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataloader.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2000] [Batch 9/10] [D loss: 0.689490] [G loss: 0.607883]\n",
      "[Epoch 1/2000] [Batch 9/10] [D loss: 0.689383] [G loss: 0.609073]\n",
      "[Epoch 2/2000] [Batch 9/10] [D loss: 0.689295] [G loss: 0.610248]\n",
      "[Epoch 3/2000] [Batch 9/10] [D loss: 0.689242] [G loss: 0.611379]\n",
      "[Epoch 4/2000] [Batch 9/10] [D loss: 0.689205] [G loss: 0.612498]\n",
      "[Epoch 5/2000] [Batch 9/10] [D loss: 0.689225] [G loss: 0.613534]\n",
      "[Epoch 6/2000] [Batch 9/10] [D loss: 0.689261] [G loss: 0.614557]\n",
      "[Epoch 7/2000] [Batch 9/10] [D loss: 0.689323] [G loss: 0.615552]\n",
      "[Epoch 8/2000] [Batch 9/10] [D loss: 0.689428] [G loss: 0.616486]\n",
      "[Epoch 9/2000] [Batch 9/10] [D loss: 0.689554] [G loss: 0.617400]\n",
      "[Epoch 10/2000] [Batch 9/10] [D loss: 0.689714] [G loss: 0.618276]\n",
      "[Epoch 11/2000] [Batch 9/10] [D loss: 0.689899] [G loss: 0.619130]\n",
      "[Epoch 12/2000] [Batch 9/10] [D loss: 0.690123] [G loss: 0.619942]\n",
      "[Epoch 13/2000] [Batch 9/10] [D loss: 0.690336] [G loss: 0.620793]\n",
      "[Epoch 14/2000] [Batch 9/10] [D loss: 0.690578] [G loss: 0.621618]\n",
      "[Epoch 15/2000] [Batch 9/10] [D loss: 0.690846] [G loss: 0.622426]\n",
      "[Epoch 16/2000] [Batch 9/10] [D loss: 0.691135] [G loss: 0.623221]\n",
      "[Epoch 17/2000] [Batch 9/10] [D loss: 0.691366] [G loss: 0.624140]\n",
      "[Epoch 18/2000] [Batch 9/10] [D loss: 0.691593] [G loss: 0.625084]\n",
      "[Epoch 19/2000] [Batch 9/10] [D loss: 0.691848] [G loss: 0.626002]\n",
      "[Epoch 20/2000] [Batch 9/10] [D loss: 0.692073] [G loss: 0.626992]\n",
      "[Epoch 21/2000] [Batch 9/10] [D loss: 0.692271] [G loss: 0.628054]\n",
      "[Epoch 22/2000] [Batch 9/10] [D loss: 0.692439] [G loss: 0.629187]\n",
      "[Epoch 23/2000] [Batch 9/10] [D loss: 0.692530] [G loss: 0.630479]\n",
      "[Epoch 24/2000] [Batch 9/10] [D loss: 0.692578] [G loss: 0.631867]\n",
      "[Epoch 25/2000] [Batch 9/10] [D loss: 0.692688] [G loss: 0.633167]\n",
      "[Epoch 26/2000] [Batch 9/10] [D loss: 0.692747] [G loss: 0.634574]\n",
      "[Epoch 27/2000] [Batch 9/10] [D loss: 0.692741] [G loss: 0.636117]\n",
      "[Epoch 28/2000] [Batch 9/10] [D loss: 0.692579] [G loss: 0.637958]\n",
      "[Epoch 29/2000] [Batch 9/10] [D loss: 0.692569] [G loss: 0.639536]\n",
      "[Epoch 30/2000] [Batch 9/10] [D loss: 0.692428] [G loss: 0.641368]\n",
      "[Epoch 31/2000] [Batch 9/10] [D loss: 0.692200] [G loss: 0.643377]\n",
      "[Epoch 32/2000] [Batch 9/10] [D loss: 0.691943] [G loss: 0.645458]\n",
      "[Epoch 33/2000] [Batch 9/10] [D loss: 0.691725] [G loss: 0.647485]\n",
      "[Epoch 34/2000] [Batch 9/10] [D loss: 0.691345] [G loss: 0.649821]\n",
      "[Epoch 35/2000] [Batch 9/10] [D loss: 0.690904] [G loss: 0.652283]\n",
      "[Epoch 36/2000] [Batch 9/10] [D loss: 0.690455] [G loss: 0.654770]\n",
      "[Epoch 37/2000] [Batch 9/10] [D loss: 0.690087] [G loss: 0.657113]\n",
      "[Epoch 38/2000] [Batch 9/10] [D loss: 0.689538] [G loss: 0.659805]\n",
      "[Epoch 39/2000] [Batch 9/10] [D loss: 0.688954] [G loss: 0.662573]\n",
      "[Epoch 40/2000] [Batch 9/10] [D loss: 0.688312] [G loss: 0.665451]\n",
      "[Epoch 41/2000] [Batch 9/10] [D loss: 0.687565] [G loss: 0.668525]\n",
      "[Epoch 42/2000] [Batch 9/10] [D loss: 0.686931] [G loss: 0.671366]\n",
      "[Epoch 43/2000] [Batch 9/10] [D loss: 0.686144] [G loss: 0.674482]\n",
      "[Epoch 44/2000] [Batch 9/10] [D loss: 0.685340] [G loss: 0.677599]\n",
      "[Epoch 45/2000] [Batch 9/10] [D loss: 0.684568] [G loss: 0.680622]\n",
      "[Epoch 46/2000] [Batch 9/10] [D loss: 0.683750] [G loss: 0.683694]\n",
      "[Epoch 47/2000] [Batch 9/10] [D loss: 0.682962] [G loss: 0.686652]\n",
      "[Epoch 48/2000] [Batch 9/10] [D loss: 0.682055] [G loss: 0.689784]\n",
      "[Epoch 49/2000] [Batch 9/10] [D loss: 0.681141] [G loss: 0.692876]\n",
      "[Epoch 50/2000] [Batch 9/10] [D loss: 0.680327] [G loss: 0.695689]\n",
      "[Epoch 51/2000] [Batch 9/10] [D loss: 0.679489] [G loss: 0.698469]\n",
      "[Epoch 52/2000] [Batch 9/10] [D loss: 0.678742] [G loss: 0.700961]\n",
      "[Epoch 53/2000] [Batch 9/10] [D loss: 0.677986] [G loss: 0.703356]\n",
      "[Epoch 54/2000] [Batch 9/10] [D loss: 0.677347] [G loss: 0.705376]\n",
      "[Epoch 55/2000] [Batch 9/10] [D loss: 0.676722] [G loss: 0.707242]\n",
      "[Epoch 56/2000] [Batch 9/10] [D loss: 0.676168] [G loss: 0.708836]\n",
      "[Epoch 57/2000] [Batch 9/10] [D loss: 0.675697] [G loss: 0.710122]\n",
      "[Epoch 58/2000] [Batch 9/10] [D loss: 0.675211] [G loss: 0.711313]\n",
      "[Epoch 59/2000] [Batch 9/10] [D loss: 0.674738] [G loss: 0.712335]\n",
      "[Epoch 60/2000] [Batch 9/10] [D loss: 0.674409] [G loss: 0.712936]\n",
      "[Epoch 61/2000] [Batch 9/10] [D loss: 0.673971] [G loss: 0.713636]\n",
      "[Epoch 62/2000] [Batch 9/10] [D loss: 0.673871] [G loss: 0.713534]\n",
      "[Epoch 63/2000] [Batch 9/10] [D loss: 0.673604] [G loss: 0.713655]\n",
      "[Epoch 64/2000] [Batch 9/10] [D loss: 0.673665] [G loss: 0.713039]\n",
      "[Epoch 65/2000] [Batch 9/10] [D loss: 0.673710] [G loss: 0.712373]\n",
      "[Epoch 66/2000] [Batch 9/10] [D loss: 0.673658] [G loss: 0.711829]\n",
      "[Epoch 67/2000] [Batch 9/10] [D loss: 0.673452] [G loss: 0.711530]\n",
      "[Epoch 68/2000] [Batch 9/10] [D loss: 0.673783] [G loss: 0.710100]\n",
      "[Epoch 69/2000] [Batch 9/10] [D loss: 0.673467] [G loss: 0.709938]\n",
      "[Epoch 70/2000] [Batch 9/10] [D loss: 0.673632] [G loss: 0.708769]\n",
      "[Epoch 71/2000] [Batch 9/10] [D loss: 0.673725] [G loss: 0.707686]\n",
      "[Epoch 72/2000] [Batch 9/10] [D loss: 0.673743] [G loss: 0.706728]\n",
      "[Epoch 73/2000] [Batch 9/10] [D loss: 0.674053] [G loss: 0.705127]\n",
      "[Epoch 74/2000] [Batch 9/10] [D loss: 0.675994] [G loss: 0.700672]\n",
      "[Epoch 75/2000] [Batch 9/10] [D loss: 0.680185] [G loss: 0.692749]\n",
      "[Epoch 76/2000] [Batch 9/10] [D loss: 0.685898] [G loss: 0.682558]\n",
      "[Epoch 77/2000] [Batch 9/10] [D loss: 0.690446] [G loss: 0.675010]\n",
      "[Epoch 78/2000] [Batch 9/10] [D loss: 0.693859] [G loss: 0.669691]\n",
      "[Epoch 79/2000] [Batch 9/10] [D loss: 0.697308] [G loss: 0.664424]\n",
      "[Epoch 80/2000] [Batch 9/10] [D loss: 0.699671] [G loss: 0.661559]\n",
      "[Epoch 81/2000] [Batch 9/10] [D loss: 0.702376] [G loss: 0.657840]\n",
      "[Epoch 82/2000] [Batch 9/10] [D loss: 0.704446] [G loss: 0.655628]\n",
      "[Epoch 83/2000] [Batch 9/10] [D loss: 0.704523] [G loss: 0.657065]\n",
      "[Epoch 84/2000] [Batch 9/10] [D loss: 0.706389] [G loss: 0.655023]\n",
      "[Epoch 85/2000] [Batch 9/10] [D loss: 0.706306] [G loss: 0.656702]\n",
      "[Epoch 86/2000] [Batch 9/10] [D loss: 0.706170] [G loss: 0.658473]\n",
      "[Epoch 87/2000] [Batch 9/10] [D loss: 0.704603] [G loss: 0.663037]\n",
      "[Epoch 88/2000] [Batch 9/10] [D loss: 0.705893] [G loss: 0.661955]\n",
      "[Epoch 89/2000] [Batch 9/10] [D loss: 0.705201] [G loss: 0.664828]\n",
      "[Epoch 90/2000] [Batch 9/10] [D loss: 0.704362] [G loss: 0.667932]\n",
      "[Epoch 91/2000] [Batch 9/10] [D loss: 0.704341] [G loss: 0.669449]\n",
      "[Epoch 92/2000] [Batch 9/10] [D loss: 0.704000] [G loss: 0.671590]\n",
      "[Epoch 93/2000] [Batch 9/10] [D loss: 0.703849] [G loss: 0.673387]\n",
      "[Epoch 94/2000] [Batch 9/10] [D loss: 0.702985] [G loss: 0.676533]\n",
      "[Epoch 95/2000] [Batch 9/10] [D loss: 0.703188] [G loss: 0.677503]\n",
      "[Epoch 96/2000] [Batch 9/10] [D loss: 0.702029] [G loss: 0.681260]\n",
      "[Epoch 97/2000] [Batch 9/10] [D loss: 0.702621] [G loss: 0.681362]\n",
      "[Epoch 98/2000] [Batch 9/10] [D loss: 0.701919] [G loss: 0.684044]\n",
      "[Epoch 99/2000] [Batch 9/10] [D loss: 0.701456] [G loss: 0.686202]\n",
      "[Epoch 100/2000] [Batch 9/10] [D loss: 0.701853] [G loss: 0.686533]\n",
      "[Epoch 101/2000] [Batch 9/10] [D loss: 0.701676] [G loss: 0.687874]\n",
      "[Epoch 102/2000] [Batch 9/10] [D loss: 0.701440] [G loss: 0.689391]\n",
      "[Epoch 103/2000] [Batch 9/10] [D loss: 0.700846] [G loss: 0.691480]\n",
      "[Epoch 104/2000] [Batch 9/10] [D loss: 0.700848] [G loss: 0.692350]\n",
      "[Epoch 105/2000] [Batch 9/10] [D loss: 0.700051] [G loss: 0.694622]\n",
      "[Epoch 106/2000] [Batch 9/10] [D loss: 0.699309] [G loss: 0.696758]\n",
      "[Epoch 107/2000] [Batch 9/10] [D loss: 0.699313] [G loss: 0.697334]\n",
      "[Epoch 108/2000] [Batch 9/10] [D loss: 0.699284] [G loss: 0.697952]\n",
      "[Epoch 109/2000] [Batch 9/10] [D loss: 0.698817] [G loss: 0.699347]\n",
      "[Epoch 110/2000] [Batch 9/10] [D loss: 0.697255] [G loss: 0.702861]\n",
      "[Epoch 111/2000] [Batch 9/10] [D loss: 0.697269] [G loss: 0.703145]\n",
      "[Epoch 112/2000] [Batch 9/10] [D loss: 0.696754] [G loss: 0.704381]\n",
      "[Epoch 113/2000] [Batch 9/10] [D loss: 0.696819] [G loss: 0.704369]\n",
      "[Epoch 114/2000] [Batch 9/10] [D loss: 0.695137] [G loss: 0.707868]\n",
      "[Epoch 115/2000] [Batch 9/10] [D loss: 0.695191] [G loss: 0.707837]\n",
      "[Epoch 116/2000] [Batch 9/10] [D loss: 0.695754] [G loss: 0.706733]\n",
      "[Epoch 117/2000] [Batch 9/10] [D loss: 0.692947] [G loss: 0.712181]\n",
      "[Epoch 118/2000] [Batch 9/10] [D loss: 0.693547] [G loss: 0.710876]\n",
      "[Epoch 119/2000] [Batch 9/10] [D loss: 0.692644] [G loss: 0.712369]\n",
      "[Epoch 120/2000] [Batch 9/10] [D loss: 0.694025] [G loss: 0.709349]\n",
      "[Epoch 121/2000] [Batch 9/10] [D loss: 0.693238] [G loss: 0.710438]\n",
      "[Epoch 122/2000] [Batch 9/10] [D loss: 0.693894] [G loss: 0.708641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 123/2000] [Batch 9/10] [D loss: 0.694545] [G loss: 0.706689]\n",
      "[Epoch 124/2000] [Batch 9/10] [D loss: 0.692862] [G loss: 0.709305]\n",
      "[Epoch 125/2000] [Batch 9/10] [D loss: 0.694195] [G loss: 0.705728]\n",
      "[Epoch 126/2000] [Batch 9/10] [D loss: 0.694977] [G loss: 0.703325]\n",
      "[Epoch 127/2000] [Batch 9/10] [D loss: 0.694616] [G loss: 0.703012]\n",
      "[Epoch 128/2000] [Batch 9/10] [D loss: 0.695693] [G loss: 0.699869]\n",
      "[Epoch 129/2000] [Batch 9/10] [D loss: 0.694821] [G loss: 0.700630]\n",
      "[Epoch 130/2000] [Batch 9/10] [D loss: 0.695349] [G loss: 0.698713]\n",
      "[Epoch 131/2000] [Batch 9/10] [D loss: 0.694232] [G loss: 0.700049]\n",
      "[Epoch 132/2000] [Batch 9/10] [D loss: 0.695057] [G loss: 0.697598]\n",
      "[Epoch 133/2000] [Batch 9/10] [D loss: 0.694410] [G loss: 0.698038]\n",
      "[Epoch 134/2000] [Batch 9/10] [D loss: 0.693123] [G loss: 0.699776]\n",
      "[Epoch 135/2000] [Batch 9/10] [D loss: 0.692933] [G loss: 0.699379]\n",
      "[Epoch 136/2000] [Batch 9/10] [D loss: 0.692370] [G loss: 0.699683]\n",
      "[Epoch 137/2000] [Batch 9/10] [D loss: 0.691787] [G loss: 0.700100]\n",
      "[Epoch 138/2000] [Batch 9/10] [D loss: 0.690697] [G loss: 0.701519]\n",
      "[Epoch 139/2000] [Batch 9/10] [D loss: 0.690054] [G loss: 0.702033]\n",
      "[Epoch 140/2000] [Batch 9/10] [D loss: 0.689833] [G loss: 0.701709]\n",
      "[Epoch 141/2000] [Batch 9/10] [D loss: 0.689735] [G loss: 0.701145]\n",
      "[Epoch 142/2000] [Batch 9/10] [D loss: 0.688679] [G loss: 0.702530]\n",
      "[Epoch 143/2000] [Batch 9/10] [D loss: 0.687813] [G loss: 0.703496]\n",
      "[Epoch 144/2000] [Batch 9/10] [D loss: 0.688290] [G loss: 0.701808]\n",
      "[Epoch 145/2000] [Batch 9/10] [D loss: 0.688675] [G loss: 0.700384]\n",
      "[Epoch 146/2000] [Batch 9/10] [D loss: 0.687873] [G loss: 0.701337]\n",
      "[Epoch 147/2000] [Batch 9/10] [D loss: 0.688322] [G loss: 0.699903]\n",
      "[Epoch 148/2000] [Batch 9/10] [D loss: 0.688327] [G loss: 0.699438]\n",
      "[Epoch 149/2000] [Batch 9/10] [D loss: 0.688550] [G loss: 0.698587]\n",
      "[Epoch 150/2000] [Batch 9/10] [D loss: 0.688427] [G loss: 0.698582]\n",
      "[Epoch 151/2000] [Batch 9/10] [D loss: 0.688719] [G loss: 0.697726]\n",
      "[Epoch 152/2000] [Batch 9/10] [D loss: 0.688281] [G loss: 0.698374]\n",
      "[Epoch 153/2000] [Batch 9/10] [D loss: 0.687747] [G loss: 0.699371]\n",
      "[Epoch 154/2000] [Batch 9/10] [D loss: 0.687988] [G loss: 0.698740]\n",
      "[Epoch 155/2000] [Batch 9/10] [D loss: 0.687645] [G loss: 0.699396]\n",
      "[Epoch 156/2000] [Batch 9/10] [D loss: 0.686816] [G loss: 0.701102]\n",
      "[Epoch 157/2000] [Batch 9/10] [D loss: 0.687387] [G loss: 0.699903]\n",
      "[Epoch 158/2000] [Batch 9/10] [D loss: 0.687087] [G loss: 0.700488]\n",
      "[Epoch 159/2000] [Batch 9/10] [D loss: 0.687433] [G loss: 0.699832]\n",
      "[Epoch 160/2000] [Batch 9/10] [D loss: 0.686649] [G loss: 0.701509]\n",
      "[Epoch 161/2000] [Batch 9/10] [D loss: 0.686508] [G loss: 0.701916]\n",
      "[Epoch 162/2000] [Batch 9/10] [D loss: 0.687053] [G loss: 0.700829]\n",
      "[Epoch 163/2000] [Batch 9/10] [D loss: 0.686608] [G loss: 0.701893]\n",
      "[Epoch 164/2000] [Batch 9/10] [D loss: 0.686464] [G loss: 0.702277]\n",
      "[Epoch 165/2000] [Batch 9/10] [D loss: 0.686504] [G loss: 0.702365]\n",
      "[Epoch 166/2000] [Batch 9/10] [D loss: 0.685902] [G loss: 0.703751]\n",
      "[Epoch 167/2000] [Batch 9/10] [D loss: 0.685859] [G loss: 0.704016]\n",
      "[Epoch 168/2000] [Batch 9/10] [D loss: 0.685782] [G loss: 0.704308]\n",
      "[Epoch 169/2000] [Batch 9/10] [D loss: 0.685855] [G loss: 0.704345]\n",
      "[Epoch 170/2000] [Batch 9/10] [D loss: 0.685719] [G loss: 0.704843]\n",
      "[Epoch 171/2000] [Batch 9/10] [D loss: 0.685999] [G loss: 0.704366]\n",
      "[Epoch 172/2000] [Batch 9/10] [D loss: 0.685926] [G loss: 0.704758]\n",
      "[Epoch 173/2000] [Batch 9/10] [D loss: 0.685798] [G loss: 0.705266]\n",
      "[Epoch 174/2000] [Batch 9/10] [D loss: 0.685796] [G loss: 0.705474]\n",
      "[Epoch 175/2000] [Batch 9/10] [D loss: 0.685901] [G loss: 0.705525]\n",
      "[Epoch 176/2000] [Batch 9/10] [D loss: 0.686021] [G loss: 0.705544]\n",
      "[Epoch 177/2000] [Batch 9/10] [D loss: 0.686031] [G loss: 0.705817]\n",
      "[Epoch 178/2000] [Batch 9/10] [D loss: 0.686060] [G loss: 0.706083]\n",
      "[Epoch 179/2000] [Batch 9/10] [D loss: 0.686284] [G loss: 0.705940]\n",
      "[Epoch 180/2000] [Batch 9/10] [D loss: 0.686531] [G loss: 0.705777]\n",
      "[Epoch 181/2000] [Batch 9/10] [D loss: 0.686193] [G loss: 0.706954]\n",
      "[Epoch 182/2000] [Batch 9/10] [D loss: 0.686133] [G loss: 0.707478]\n",
      "[Epoch 183/2000] [Batch 9/10] [D loss: 0.686600] [G loss: 0.706911]\n",
      "[Epoch 184/2000] [Batch 9/10] [D loss: 0.686194] [G loss: 0.708266]\n",
      "[Epoch 185/2000] [Batch 9/10] [D loss: 0.686594] [G loss: 0.707945]\n",
      "[Epoch 186/2000] [Batch 9/10] [D loss: 0.686282] [G loss: 0.709149]\n",
      "[Epoch 187/2000] [Batch 9/10] [D loss: 0.686598] [G loss: 0.709077]\n",
      "[Epoch 188/2000] [Batch 9/10] [D loss: 0.686930] [G loss: 0.708924]\n",
      "[Epoch 189/2000] [Batch 9/10] [D loss: 0.687039] [G loss: 0.709354]\n",
      "[Epoch 190/2000] [Batch 9/10] [D loss: 0.686635] [G loss: 0.710914]\n",
      "[Epoch 191/2000] [Batch 9/10] [D loss: 0.686803] [G loss: 0.711245]\n",
      "[Epoch 192/2000] [Batch 9/10] [D loss: 0.686615] [G loss: 0.712325]\n",
      "[Epoch 193/2000] [Batch 9/10] [D loss: 0.686659] [G loss: 0.712980]\n",
      "[Epoch 194/2000] [Batch 9/10] [D loss: 0.686450] [G loss: 0.714177]\n",
      "[Epoch 195/2000] [Batch 9/10] [D loss: 0.686435] [G loss: 0.714958]\n",
      "[Epoch 196/2000] [Batch 9/10] [D loss: 0.686369] [G loss: 0.715819]\n",
      "[Epoch 197/2000] [Batch 9/10] [D loss: 0.686464] [G loss: 0.716302]\n",
      "[Epoch 198/2000] [Batch 9/10] [D loss: 0.686003] [G loss: 0.718043]\n",
      "[Epoch 199/2000] [Batch 9/10] [D loss: 0.685801] [G loss: 0.719165]\n",
      "[Epoch 200/2000] [Batch 9/10] [D loss: 0.685443] [G loss: 0.720612]\n",
      "[Epoch 201/2000] [Batch 9/10] [D loss: 0.685120] [G loss: 0.721900]\n",
      "[Epoch 202/2000] [Batch 9/10] [D loss: 0.684857] [G loss: 0.723065]\n",
      "[Epoch 203/2000] [Batch 9/10] [D loss: 0.684372] [G loss: 0.724662]\n",
      "[Epoch 204/2000] [Batch 9/10] [D loss: 0.683993] [G loss: 0.725995]\n",
      "[Epoch 205/2000] [Batch 9/10] [D loss: 0.683661] [G loss: 0.727167]\n",
      "[Epoch 206/2000] [Batch 9/10] [D loss: 0.683162] [G loss: 0.728652]\n",
      "[Epoch 207/2000] [Batch 9/10] [D loss: 0.682771] [G loss: 0.729815]\n",
      "[Epoch 208/2000] [Batch 9/10] [D loss: 0.682369] [G loss: 0.730939]\n",
      "[Epoch 209/2000] [Batch 9/10] [D loss: 0.682230] [G loss: 0.731360]\n",
      "[Epoch 210/2000] [Batch 9/10] [D loss: 0.682574] [G loss: 0.730547]\n",
      "[Epoch 211/2000] [Batch 9/10] [D loss: 0.683754] [G loss: 0.727811]\n",
      "[Epoch 212/2000] [Batch 9/10] [D loss: 0.684845] [G loss: 0.725276]\n",
      "[Epoch 213/2000] [Batch 9/10] [D loss: 0.685687] [G loss: 0.723280]\n",
      "[Epoch 214/2000] [Batch 9/10] [D loss: 0.685548] [G loss: 0.723323]\n",
      "[Epoch 215/2000] [Batch 9/10] [D loss: 0.685796] [G loss: 0.722469]\n",
      "[Epoch 216/2000] [Batch 9/10] [D loss: 0.685687] [G loss: 0.722333]\n",
      "[Epoch 217/2000] [Batch 9/10] [D loss: 0.685360] [G loss: 0.722600]\n",
      "[Epoch 218/2000] [Batch 9/10] [D loss: 0.684843] [G loss: 0.723233]\n",
      "[Epoch 219/2000] [Batch 9/10] [D loss: 0.684516] [G loss: 0.723462]\n",
      "[Epoch 220/2000] [Batch 9/10] [D loss: 0.683870] [G loss: 0.724319]\n",
      "[Epoch 221/2000] [Batch 9/10] [D loss: 0.684097] [G loss: 0.723322]\n",
      "[Epoch 222/2000] [Batch 9/10] [D loss: 0.683650] [G loss: 0.723719]\n",
      "[Epoch 223/2000] [Batch 9/10] [D loss: 0.683050] [G loss: 0.724369]\n",
      "[Epoch 224/2000] [Batch 9/10] [D loss: 0.682293] [G loss: 0.725334]\n",
      "[Epoch 225/2000] [Batch 9/10] [D loss: 0.682468] [G loss: 0.724395]\n",
      "[Epoch 226/2000] [Batch 9/10] [D loss: 0.681142] [G loss: 0.726556]\n",
      "[Epoch 227/2000] [Batch 9/10] [D loss: 0.680874] [G loss: 0.726503]\n",
      "[Epoch 228/2000] [Batch 9/10] [D loss: 0.680459] [G loss: 0.726724]\n",
      "[Epoch 229/2000] [Batch 9/10] [D loss: 0.680720] [G loss: 0.725574]\n",
      "[Epoch 230/2000] [Batch 9/10] [D loss: 0.680027] [G loss: 0.726308]\n",
      "[Epoch 231/2000] [Batch 9/10] [D loss: 0.679578] [G loss: 0.726477]\n",
      "[Epoch 232/2000] [Batch 9/10] [D loss: 0.679594] [G loss: 0.725590]\n",
      "[Epoch 233/2000] [Batch 9/10] [D loss: 0.679304] [G loss: 0.725310]\n",
      "[Epoch 234/2000] [Batch 9/10] [D loss: 0.678720] [G loss: 0.725640]\n",
      "[Epoch 235/2000] [Batch 9/10] [D loss: 0.678898] [G loss: 0.724431]\n",
      "[Epoch 236/2000] [Batch 9/10] [D loss: 0.678278] [G loss: 0.724883]\n",
      "[Epoch 237/2000] [Batch 9/10] [D loss: 0.678838] [G loss: 0.722871]\n",
      "[Epoch 238/2000] [Batch 9/10] [D loss: 0.677603] [G loss: 0.724451]\n",
      "[Epoch 239/2000] [Batch 9/10] [D loss: 0.678337] [G loss: 0.722041]\n",
      "[Epoch 240/2000] [Batch 9/10] [D loss: 0.677963] [G loss: 0.722056]\n",
      "[Epoch 241/2000] [Batch 9/10] [D loss: 0.677919] [G loss: 0.721175]\n",
      "[Epoch 242/2000] [Batch 9/10] [D loss: 0.677183] [G loss: 0.721726]\n",
      "[Epoch 243/2000] [Batch 9/10] [D loss: 0.677166] [G loss: 0.720816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 244/2000] [Batch 9/10] [D loss: 0.677311] [G loss: 0.719594]\n",
      "[Epoch 245/2000] [Batch 9/10] [D loss: 0.677286] [G loss: 0.718769]\n",
      "[Epoch 246/2000] [Batch 9/10] [D loss: 0.677044] [G loss: 0.718221]\n",
      "[Epoch 247/2000] [Batch 9/10] [D loss: 0.677089] [G loss: 0.717106]\n",
      "[Epoch 248/2000] [Batch 9/10] [D loss: 0.677000] [G loss: 0.716235]\n",
      "[Epoch 249/2000] [Batch 9/10] [D loss: 0.677728] [G loss: 0.713597]\n",
      "[Epoch 250/2000] [Batch 9/10] [D loss: 0.676529] [G loss: 0.714936]\n",
      "[Epoch 251/2000] [Batch 9/10] [D loss: 0.677209] [G loss: 0.712423]\n",
      "[Epoch 252/2000] [Batch 9/10] [D loss: 0.676623] [G loss: 0.712489]\n",
      "[Epoch 253/2000] [Batch 9/10] [D loss: 0.676814] [G loss: 0.710912]\n",
      "[Epoch 254/2000] [Batch 9/10] [D loss: 0.675891] [G loss: 0.711457]\n",
      "[Epoch 255/2000] [Batch 9/10] [D loss: 0.675690] [G loss: 0.710817]\n",
      "[Epoch 256/2000] [Batch 9/10] [D loss: 0.675953] [G loss: 0.709116]\n",
      "[Epoch 257/2000] [Batch 9/10] [D loss: 0.675302] [G loss: 0.709291]\n",
      "[Epoch 258/2000] [Batch 9/10] [D loss: 0.674837] [G loss: 0.709023]\n",
      "[Epoch 259/2000] [Batch 9/10] [D loss: 0.675599] [G loss: 0.706228]\n",
      "[Epoch 260/2000] [Batch 9/10] [D loss: 0.675951] [G loss: 0.704226]\n",
      "[Epoch 261/2000] [Batch 9/10] [D loss: 0.674848] [G loss: 0.705362]\n",
      "[Epoch 262/2000] [Batch 9/10] [D loss: 0.673888] [G loss: 0.706192]\n",
      "[Epoch 263/2000] [Batch 9/10] [D loss: 0.674671] [G loss: 0.703489]\n",
      "[Epoch 264/2000] [Batch 9/10] [D loss: 0.674511] [G loss: 0.702792]\n",
      "[Epoch 265/2000] [Batch 9/10] [D loss: 0.673732] [G loss: 0.703450]\n",
      "[Epoch 266/2000] [Batch 9/10] [D loss: 0.675300] [G loss: 0.699406]\n",
      "[Epoch 267/2000] [Batch 9/10] [D loss: 0.674912] [G loss: 0.699585]\n",
      "[Epoch 268/2000] [Batch 9/10] [D loss: 0.675463] [G loss: 0.698130]\n",
      "[Epoch 269/2000] [Batch 9/10] [D loss: 0.675555] [G loss: 0.697862]\n",
      "[Epoch 270/2000] [Batch 9/10] [D loss: 0.677245] [G loss: 0.694657]\n",
      "[Epoch 271/2000] [Batch 9/10] [D loss: 0.677752] [G loss: 0.694118]\n",
      "[Epoch 272/2000] [Batch 9/10] [D loss: 0.678306] [G loss: 0.693816]\n",
      "[Epoch 273/2000] [Batch 9/10] [D loss: 0.678969] [G loss: 0.693354]\n",
      "[Epoch 274/2000] [Batch 9/10] [D loss: 0.679322] [G loss: 0.693739]\n",
      "[Epoch 275/2000] [Batch 9/10] [D loss: 0.680338] [G loss: 0.692752]\n",
      "[Epoch 276/2000] [Batch 9/10] [D loss: 0.680141] [G loss: 0.694277]\n",
      "[Epoch 277/2000] [Batch 9/10] [D loss: 0.679954] [G loss: 0.695676]\n",
      "[Epoch 278/2000] [Batch 9/10] [D loss: 0.679891] [G loss: 0.696797]\n",
      "[Epoch 279/2000] [Batch 9/10] [D loss: 0.680102] [G loss: 0.697243]\n",
      "[Epoch 280/2000] [Batch 9/10] [D loss: 0.679381] [G loss: 0.699460]\n",
      "[Epoch 281/2000] [Batch 9/10] [D loss: 0.678871] [G loss: 0.701148]\n",
      "[Epoch 282/2000] [Batch 9/10] [D loss: 0.678441] [G loss: 0.702508]\n",
      "[Epoch 283/2000] [Batch 9/10] [D loss: 0.677310] [G loss: 0.705140]\n",
      "[Epoch 284/2000] [Batch 9/10] [D loss: 0.676672] [G loss: 0.706616]\n",
      "[Epoch 285/2000] [Batch 9/10] [D loss: 0.676583] [G loss: 0.706726]\n",
      "[Epoch 286/2000] [Batch 9/10] [D loss: 0.675431] [G loss: 0.708914]\n",
      "[Epoch 287/2000] [Batch 9/10] [D loss: 0.674854] [G loss: 0.709786]\n",
      "[Epoch 288/2000] [Batch 9/10] [D loss: 0.674248] [G loss: 0.710502]\n",
      "[Epoch 289/2000] [Batch 9/10] [D loss: 0.673039] [G loss: 0.712364]\n",
      "[Epoch 290/2000] [Batch 9/10] [D loss: 0.673383] [G loss: 0.710831]\n",
      "[Epoch 291/2000] [Batch 9/10] [D loss: 0.672580] [G loss: 0.711517]\n",
      "[Epoch 292/2000] [Batch 9/10] [D loss: 0.671859] [G loss: 0.711884]\n",
      "[Epoch 293/2000] [Batch 9/10] [D loss: 0.671748] [G loss: 0.710948]\n",
      "[Epoch 294/2000] [Batch 9/10] [D loss: 0.671936] [G loss: 0.709191]\n",
      "[Epoch 295/2000] [Batch 9/10] [D loss: 0.671290] [G loss: 0.709047]\n",
      "[Epoch 296/2000] [Batch 9/10] [D loss: 0.671348] [G loss: 0.707355]\n",
      "[Epoch 297/2000] [Batch 9/10] [D loss: 0.671255] [G loss: 0.705900]\n",
      "[Epoch 298/2000] [Batch 9/10] [D loss: 0.670783] [G loss: 0.705237]\n",
      "[Epoch 299/2000] [Batch 9/10] [D loss: 0.670695] [G loss: 0.703824]\n",
      "[Epoch 300/2000] [Batch 9/10] [D loss: 0.670626] [G loss: 0.702383]\n",
      "[Epoch 301/2000] [Batch 9/10] [D loss: 0.669703] [G loss: 0.702719]\n",
      "[Epoch 302/2000] [Batch 9/10] [D loss: 0.669218] [G loss: 0.702201]\n",
      "[Epoch 303/2000] [Batch 9/10] [D loss: 0.668560] [G loss: 0.702105]\n",
      "[Epoch 304/2000] [Batch 9/10] [D loss: 0.667850] [G loss: 0.702141]\n",
      "[Epoch 305/2000] [Batch 9/10] [D loss: 0.667462] [G loss: 0.701619]\n",
      "[Epoch 306/2000] [Batch 9/10] [D loss: 0.667426] [G loss: 0.700442]\n",
      "[Epoch 307/2000] [Batch 9/10] [D loss: 0.667492] [G loss: 0.699202]\n",
      "[Epoch 308/2000] [Batch 9/10] [D loss: 0.668261] [G loss: 0.696839]\n",
      "[Epoch 309/2000] [Batch 9/10] [D loss: 0.670529] [G loss: 0.691925]\n",
      "[Epoch 310/2000] [Batch 9/10] [D loss: 0.674042] [G loss: 0.685197]\n",
      "[Epoch 311/2000] [Batch 9/10] [D loss: 0.677559] [G loss: 0.679053]\n",
      "[Epoch 312/2000] [Batch 9/10] [D loss: 0.680648] [G loss: 0.674137]\n",
      "[Epoch 313/2000] [Batch 9/10] [D loss: 0.684734] [G loss: 0.667516]\n",
      "[Epoch 314/2000] [Batch 9/10] [D loss: 0.688295] [G loss: 0.662072]\n",
      "[Epoch 315/2000] [Batch 9/10] [D loss: 0.690851] [G loss: 0.658688]\n",
      "[Epoch 316/2000] [Batch 9/10] [D loss: 0.692886] [G loss: 0.656442]\n",
      "[Epoch 317/2000] [Batch 9/10] [D loss: 0.695941] [G loss: 0.652451]\n",
      "[Epoch 318/2000] [Batch 9/10] [D loss: 0.698099] [G loss: 0.650345]\n",
      "[Epoch 319/2000] [Batch 9/10] [D loss: 0.698854] [G loss: 0.650912]\n",
      "[Epoch 320/2000] [Batch 9/10] [D loss: 0.701489] [G loss: 0.648028]\n",
      "[Epoch 321/2000] [Batch 9/10] [D loss: 0.702756] [G loss: 0.647789]\n",
      "[Epoch 322/2000] [Batch 9/10] [D loss: 0.703211] [G loss: 0.649087]\n",
      "[Epoch 323/2000] [Batch 9/10] [D loss: 0.704105] [G loss: 0.649569]\n",
      "[Epoch 324/2000] [Batch 9/10] [D loss: 0.703652] [G loss: 0.652507]\n",
      "[Epoch 325/2000] [Batch 9/10] [D loss: 0.705561] [G loss: 0.650792]\n",
      "[Epoch 326/2000] [Batch 9/10] [D loss: 0.705044] [G loss: 0.653811]\n",
      "[Epoch 327/2000] [Batch 9/10] [D loss: 0.706147] [G loss: 0.653711]\n",
      "[Epoch 328/2000] [Batch 9/10] [D loss: 0.706982] [G loss: 0.653960]\n",
      "[Epoch 329/2000] [Batch 9/10] [D loss: 0.706310] [G loss: 0.657094]\n",
      "[Epoch 330/2000] [Batch 9/10] [D loss: 0.704132] [G loss: 0.663086]\n",
      "[Epoch 331/2000] [Batch 9/10] [D loss: 0.705053] [G loss: 0.663157]\n",
      "[Epoch 332/2000] [Batch 9/10] [D loss: 0.704995] [G loss: 0.664859]\n",
      "[Epoch 333/2000] [Batch 9/10] [D loss: 0.705979] [G loss: 0.664716]\n",
      "[Epoch 334/2000] [Batch 9/10] [D loss: 0.703387] [G loss: 0.671520]\n",
      "[Epoch 335/2000] [Batch 9/10] [D loss: 0.704135] [G loss: 0.671436]\n",
      "[Epoch 336/2000] [Batch 9/10] [D loss: 0.702805] [G loss: 0.675631]\n",
      "[Epoch 337/2000] [Batch 9/10] [D loss: 0.703924] [G loss: 0.674919]\n",
      "[Epoch 338/2000] [Batch 9/10] [D loss: 0.702336] [G loss: 0.679462]\n",
      "[Epoch 339/2000] [Batch 9/10] [D loss: 0.701422] [G loss: 0.682361]\n",
      "[Epoch 340/2000] [Batch 9/10] [D loss: 0.700804] [G loss: 0.684711]\n",
      "[Epoch 341/2000] [Batch 9/10] [D loss: 0.701308] [G loss: 0.684878]\n",
      "[Epoch 342/2000] [Batch 9/10] [D loss: 0.702190] [G loss: 0.684065]\n",
      "[Epoch 343/2000] [Batch 9/10] [D loss: 0.700577] [G loss: 0.688195]\n",
      "[Epoch 344/2000] [Batch 9/10] [D loss: 0.700044] [G loss: 0.690042]\n",
      "[Epoch 345/2000] [Batch 9/10] [D loss: 0.700161] [G loss: 0.690527]\n",
      "[Epoch 346/2000] [Batch 9/10] [D loss: 0.700145] [G loss: 0.691298]\n",
      "[Epoch 347/2000] [Batch 9/10] [D loss: 0.699990] [G loss: 0.692013]\n",
      "[Epoch 348/2000] [Batch 9/10] [D loss: 0.700735] [G loss: 0.690971]\n",
      "[Epoch 349/2000] [Batch 9/10] [D loss: 0.700721] [G loss: 0.691406]\n",
      "[Epoch 350/2000] [Batch 9/10] [D loss: 0.703213] [G loss: 0.686905]\n",
      "[Epoch 351/2000] [Batch 9/10] [D loss: 0.704482] [G loss: 0.684806]\n",
      "[Epoch 352/2000] [Batch 9/10] [D loss: 0.704836] [G loss: 0.684491]\n",
      "[Epoch 353/2000] [Batch 9/10] [D loss: 0.704871] [G loss: 0.684959]\n",
      "[Epoch 354/2000] [Batch 9/10] [D loss: 0.705685] [G loss: 0.683814]\n",
      "[Epoch 355/2000] [Batch 9/10] [D loss: 0.707152] [G loss: 0.681711]\n",
      "[Epoch 356/2000] [Batch 9/10] [D loss: 0.707702] [G loss: 0.681440]\n",
      "[Epoch 357/2000] [Batch 9/10] [D loss: 0.709167] [G loss: 0.679292]\n",
      "[Epoch 358/2000] [Batch 9/10] [D loss: 0.709455] [G loss: 0.679715]\n",
      "[Epoch 359/2000] [Batch 9/10] [D loss: 0.710482] [G loss: 0.678512]\n",
      "[Epoch 360/2000] [Batch 9/10] [D loss: 0.710461] [G loss: 0.679690]\n",
      "[Epoch 361/2000] [Batch 9/10] [D loss: 0.711817] [G loss: 0.677998]\n",
      "[Epoch 362/2000] [Batch 9/10] [D loss: 0.712465] [G loss: 0.677529]\n",
      "[Epoch 363/2000] [Batch 9/10] [D loss: 0.712274] [G loss: 0.678794]\n",
      "[Epoch 364/2000] [Batch 9/10] [D loss: 0.711895] [G loss: 0.680404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 365/2000] [Batch 9/10] [D loss: 0.710694] [G loss: 0.683301]\n",
      "[Epoch 366/2000] [Batch 9/10] [D loss: 0.709973] [G loss: 0.685327]\n",
      "[Epoch 367/2000] [Batch 9/10] [D loss: 0.711714] [G loss: 0.682202]\n",
      "[Epoch 368/2000] [Batch 9/10] [D loss: 0.710253] [G loss: 0.685467]\n",
      "[Epoch 369/2000] [Batch 9/10] [D loss: 0.710247] [G loss: 0.685572]\n",
      "[Epoch 370/2000] [Batch 9/10] [D loss: 0.709702] [G loss: 0.686682]\n",
      "[Epoch 371/2000] [Batch 9/10] [D loss: 0.709434] [G loss: 0.687157]\n",
      "[Epoch 372/2000] [Batch 9/10] [D loss: 0.708106] [G loss: 0.689633]\n",
      "[Epoch 373/2000] [Batch 9/10] [D loss: 0.707492] [G loss: 0.690705]\n",
      "[Epoch 374/2000] [Batch 9/10] [D loss: 0.707182] [G loss: 0.690986]\n",
      "[Epoch 375/2000] [Batch 9/10] [D loss: 0.707236] [G loss: 0.690337]\n",
      "[Epoch 376/2000] [Batch 9/10] [D loss: 0.706558] [G loss: 0.691202]\n",
      "[Epoch 377/2000] [Batch 9/10] [D loss: 0.705648] [G loss: 0.692454]\n",
      "[Epoch 378/2000] [Batch 9/10] [D loss: 0.705805] [G loss: 0.691532]\n",
      "[Epoch 379/2000] [Batch 9/10] [D loss: 0.704363] [G loss: 0.693837]\n",
      "[Epoch 380/2000] [Batch 9/10] [D loss: 0.704451] [G loss: 0.692921]\n",
      "[Epoch 381/2000] [Batch 9/10] [D loss: 0.703862] [G loss: 0.693379]\n",
      "[Epoch 382/2000] [Batch 9/10] [D loss: 0.703467] [G loss: 0.693386]\n",
      "[Epoch 383/2000] [Batch 9/10] [D loss: 0.702658] [G loss: 0.694355]\n",
      "[Epoch 384/2000] [Batch 9/10] [D loss: 0.702177] [G loss: 0.694581]\n",
      "[Epoch 385/2000] [Batch 9/10] [D loss: 0.701672] [G loss: 0.694860]\n",
      "[Epoch 386/2000] [Batch 9/10] [D loss: 0.700963] [G loss: 0.695649]\n",
      "[Epoch 387/2000] [Batch 9/10] [D loss: 0.700424] [G loss: 0.696080]\n",
      "[Epoch 388/2000] [Batch 9/10] [D loss: 0.699733] [G loss: 0.696833]\n",
      "[Epoch 389/2000] [Batch 9/10] [D loss: 0.699480] [G loss: 0.696765]\n",
      "[Epoch 390/2000] [Batch 9/10] [D loss: 0.699184] [G loss: 0.696820]\n",
      "[Epoch 391/2000] [Batch 9/10] [D loss: 0.698815] [G loss: 0.697095]\n",
      "[Epoch 392/2000] [Batch 9/10] [D loss: 0.698584] [G loss: 0.697160]\n",
      "[Epoch 393/2000] [Batch 9/10] [D loss: 0.698393] [G loss: 0.697209]\n",
      "[Epoch 394/2000] [Batch 9/10] [D loss: 0.698244] [G loss: 0.697286]\n",
      "[Epoch 395/2000] [Batch 9/10] [D loss: 0.698420] [G loss: 0.696812]\n",
      "[Epoch 396/2000] [Batch 9/10] [D loss: 0.698337] [G loss: 0.697030]\n",
      "[Epoch 397/2000] [Batch 9/10] [D loss: 0.698097] [G loss: 0.697710]\n",
      "[Epoch 398/2000] [Batch 9/10] [D loss: 0.697846] [G loss: 0.698471]\n",
      "[Epoch 399/2000] [Batch 9/10] [D loss: 0.697232] [G loss: 0.700013]\n",
      "[Epoch 400/2000] [Batch 9/10] [D loss: 0.696409] [G loss: 0.701965]\n",
      "[Epoch 401/2000] [Batch 9/10] [D loss: 0.695835] [G loss: 0.703420]\n",
      "[Epoch 402/2000] [Batch 9/10] [D loss: 0.694969] [G loss: 0.705445]\n",
      "[Epoch 403/2000] [Batch 9/10] [D loss: 0.694190] [G loss: 0.707286]\n",
      "[Epoch 404/2000] [Batch 9/10] [D loss: 0.693402] [G loss: 0.709076]\n",
      "[Epoch 405/2000] [Batch 9/10] [D loss: 0.692245] [G loss: 0.711626]\n",
      "[Epoch 406/2000] [Batch 9/10] [D loss: 0.691300] [G loss: 0.713671]\n",
      "[Epoch 407/2000] [Batch 9/10] [D loss: 0.690371] [G loss: 0.715625]\n",
      "[Epoch 408/2000] [Batch 9/10] [D loss: 0.689421] [G loss: 0.717556]\n",
      "[Epoch 409/2000] [Batch 9/10] [D loss: 0.688464] [G loss: 0.719432]\n",
      "[Epoch 410/2000] [Batch 9/10] [D loss: 0.687468] [G loss: 0.721360]\n",
      "[Epoch 411/2000] [Batch 9/10] [D loss: 0.686288] [G loss: 0.723626]\n",
      "[Epoch 412/2000] [Batch 9/10] [D loss: 0.685512] [G loss: 0.724999]\n",
      "[Epoch 413/2000] [Batch 9/10] [D loss: 0.684307] [G loss: 0.727183]\n",
      "[Epoch 414/2000] [Batch 9/10] [D loss: 0.683514] [G loss: 0.728470]\n",
      "[Epoch 415/2000] [Batch 9/10] [D loss: 0.682728] [G loss: 0.729673]\n",
      "[Epoch 416/2000] [Batch 9/10] [D loss: 0.682079] [G loss: 0.730530]\n",
      "[Epoch 417/2000] [Batch 9/10] [D loss: 0.680991] [G loss: 0.732274]\n",
      "[Epoch 418/2000] [Batch 9/10] [D loss: 0.680099] [G loss: 0.733593]\n",
      "[Epoch 419/2000] [Batch 9/10] [D loss: 0.679649] [G loss: 0.733881]\n",
      "[Epoch 420/2000] [Batch 9/10] [D loss: 0.678799] [G loss: 0.734957]\n",
      "[Epoch 421/2000] [Batch 9/10] [D loss: 0.678405] [G loss: 0.735022]\n",
      "[Epoch 422/2000] [Batch 9/10] [D loss: 0.677506] [G loss: 0.736136]\n",
      "[Epoch 423/2000] [Batch 9/10] [D loss: 0.676854] [G loss: 0.736659]\n",
      "[Epoch 424/2000] [Batch 9/10] [D loss: 0.676544] [G loss: 0.736362]\n",
      "[Epoch 425/2000] [Batch 9/10] [D loss: 0.677014] [G loss: 0.734317]\n",
      "[Epoch 426/2000] [Batch 9/10] [D loss: 0.676876] [G loss: 0.733589]\n",
      "[Epoch 427/2000] [Batch 9/10] [D loss: 0.676500] [G loss: 0.733323]\n",
      "[Epoch 428/2000] [Batch 9/10] [D loss: 0.677320] [G loss: 0.730478]\n",
      "[Epoch 429/2000] [Batch 9/10] [D loss: 0.677113] [G loss: 0.729843]\n",
      "[Epoch 430/2000] [Batch 9/10] [D loss: 0.677429] [G loss: 0.728035]\n",
      "[Epoch 431/2000] [Batch 9/10] [D loss: 0.677931] [G loss: 0.725836]\n",
      "[Epoch 432/2000] [Batch 9/10] [D loss: 0.678010] [G loss: 0.724555]\n",
      "[Epoch 433/2000] [Batch 9/10] [D loss: 0.678093] [G loss: 0.723214]\n",
      "[Epoch 434/2000] [Batch 9/10] [D loss: 0.678544] [G loss: 0.721067]\n",
      "[Epoch 435/2000] [Batch 9/10] [D loss: 0.678146] [G loss: 0.720843]\n",
      "[Epoch 436/2000] [Batch 9/10] [D loss: 0.678298] [G loss: 0.719507]\n",
      "[Epoch 437/2000] [Batch 9/10] [D loss: 0.678146] [G loss: 0.718852]\n",
      "[Epoch 438/2000] [Batch 9/10] [D loss: 0.677588] [G loss: 0.719090]\n",
      "[Epoch 439/2000] [Batch 9/10] [D loss: 0.678059] [G loss: 0.717177]\n",
      "[Epoch 440/2000] [Batch 9/10] [D loss: 0.677523] [G loss: 0.717409]\n",
      "[Epoch 441/2000] [Batch 9/10] [D loss: 0.677458] [G loss: 0.716691]\n",
      "[Epoch 442/2000] [Batch 9/10] [D loss: 0.677683] [G loss: 0.715425]\n",
      "[Epoch 443/2000] [Batch 9/10] [D loss: 0.678092] [G loss: 0.713898]\n",
      "[Epoch 444/2000] [Batch 9/10] [D loss: 0.678640] [G loss: 0.712295]\n",
      "[Epoch 445/2000] [Batch 9/10] [D loss: 0.680399] [G loss: 0.708432]\n",
      "[Epoch 446/2000] [Batch 9/10] [D loss: 0.683709] [G loss: 0.701936]\n",
      "[Epoch 447/2000] [Batch 9/10] [D loss: 0.686834] [G loss: 0.696428]\n",
      "[Epoch 448/2000] [Batch 9/10] [D loss: 0.689441] [G loss: 0.692005]\n",
      "[Epoch 449/2000] [Batch 9/10] [D loss: 0.690945] [G loss: 0.689584]\n",
      "[Epoch 450/2000] [Batch 9/10] [D loss: 0.690742] [G loss: 0.690201]\n",
      "[Epoch 451/2000] [Batch 9/10] [D loss: 0.690008] [G loss: 0.691746]\n",
      "[Epoch 452/2000] [Batch 9/10] [D loss: 0.689470] [G loss: 0.692693]\n",
      "[Epoch 453/2000] [Batch 9/10] [D loss: 0.688791] [G loss: 0.693741]\n",
      "[Epoch 454/2000] [Batch 9/10] [D loss: 0.687138] [G loss: 0.696781]\n",
      "[Epoch 455/2000] [Batch 9/10] [D loss: 0.684823] [G loss: 0.700870]\n",
      "[Epoch 456/2000] [Batch 9/10] [D loss: 0.683262] [G loss: 0.703476]\n",
      "[Epoch 457/2000] [Batch 9/10] [D loss: 0.681751] [G loss: 0.705815]\n",
      "[Epoch 458/2000] [Batch 9/10] [D loss: 0.679441] [G loss: 0.709760]\n",
      "[Epoch 459/2000] [Batch 9/10] [D loss: 0.676930] [G loss: 0.714022]\n",
      "[Epoch 460/2000] [Batch 9/10] [D loss: 0.675562] [G loss: 0.715821]\n",
      "[Epoch 461/2000] [Batch 9/10] [D loss: 0.673730] [G loss: 0.718566]\n",
      "[Epoch 462/2000] [Batch 9/10] [D loss: 0.671681] [G loss: 0.721738]\n",
      "[Epoch 463/2000] [Batch 9/10] [D loss: 0.669643] [G loss: 0.724810]\n",
      "[Epoch 464/2000] [Batch 9/10] [D loss: 0.667846] [G loss: 0.727371]\n",
      "[Epoch 465/2000] [Batch 9/10] [D loss: 0.666124] [G loss: 0.729654]\n",
      "[Epoch 466/2000] [Batch 9/10] [D loss: 0.664419] [G loss: 0.731826]\n",
      "[Epoch 467/2000] [Batch 9/10] [D loss: 0.663158] [G loss: 0.732972]\n",
      "[Epoch 468/2000] [Batch 9/10] [D loss: 0.662149] [G loss: 0.733591]\n",
      "[Epoch 469/2000] [Batch 9/10] [D loss: 0.661182] [G loss: 0.734036]\n",
      "[Epoch 470/2000] [Batch 9/10] [D loss: 0.660239] [G loss: 0.734334]\n",
      "[Epoch 471/2000] [Batch 9/10] [D loss: 0.659149] [G loss: 0.735043]\n",
      "[Epoch 472/2000] [Batch 9/10] [D loss: 0.658663] [G loss: 0.734510]\n",
      "[Epoch 473/2000] [Batch 9/10] [D loss: 0.657922] [G loss: 0.734733]\n",
      "[Epoch 474/2000] [Batch 9/10] [D loss: 0.657606] [G loss: 0.734230]\n",
      "[Epoch 475/2000] [Batch 9/10] [D loss: 0.657284] [G loss: 0.733978]\n",
      "[Epoch 476/2000] [Batch 9/10] [D loss: 0.656536] [G loss: 0.734823]\n",
      "[Epoch 477/2000] [Batch 9/10] [D loss: 0.656928] [G loss: 0.733811]\n",
      "[Epoch 478/2000] [Batch 9/10] [D loss: 0.658540] [G loss: 0.730941]\n",
      "[Epoch 479/2000] [Batch 9/10] [D loss: 0.660064] [G loss: 0.728912]\n",
      "[Epoch 480/2000] [Batch 9/10] [D loss: 0.662378] [G loss: 0.725618]\n",
      "[Epoch 481/2000] [Batch 9/10] [D loss: 0.664095] [G loss: 0.724035]\n",
      "[Epoch 482/2000] [Batch 9/10] [D loss: 0.665555] [G loss: 0.723413]\n",
      "[Epoch 483/2000] [Batch 9/10] [D loss: 0.667079] [G loss: 0.722869]\n",
      "[Epoch 484/2000] [Batch 9/10] [D loss: 0.667340] [G loss: 0.724909]\n",
      "[Epoch 485/2000] [Batch 9/10] [D loss: 0.667552] [G loss: 0.727027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 486/2000] [Batch 9/10] [D loss: 0.666976] [G loss: 0.730759]\n",
      "[Epoch 487/2000] [Batch 9/10] [D loss: 0.667103] [G loss: 0.732882]\n",
      "[Epoch 488/2000] [Batch 9/10] [D loss: 0.668317] [G loss: 0.732580]\n",
      "[Epoch 489/2000] [Batch 9/10] [D loss: 0.667416] [G loss: 0.736483]\n",
      "[Epoch 490/2000] [Batch 9/10] [D loss: 0.666571] [G loss: 0.740070]\n",
      "[Epoch 491/2000] [Batch 9/10] [D loss: 0.666194] [G loss: 0.742561]\n",
      "[Epoch 492/2000] [Batch 9/10] [D loss: 0.665740] [G loss: 0.744999]\n",
      "[Epoch 493/2000] [Batch 9/10] [D loss: 0.666484] [G loss: 0.744645]\n",
      "[Epoch 494/2000] [Batch 9/10] [D loss: 0.666654] [G loss: 0.745398]\n",
      "[Epoch 495/2000] [Batch 9/10] [D loss: 0.666394] [G loss: 0.746939]\n",
      "[Epoch 496/2000] [Batch 9/10] [D loss: 0.667847] [G loss: 0.744708]\n",
      "[Epoch 497/2000] [Batch 9/10] [D loss: 0.667173] [G loss: 0.746974]\n",
      "[Epoch 498/2000] [Batch 9/10] [D loss: 0.668633] [G loss: 0.744505]\n",
      "[Epoch 499/2000] [Batch 9/10] [D loss: 0.670348] [G loss: 0.741456]\n",
      "[Epoch 500/2000] [Batch 9/10] [D loss: 0.670236] [G loss: 0.742375]\n",
      "[Epoch 501/2000] [Batch 9/10] [D loss: 0.671161] [G loss: 0.741008]\n",
      "[Epoch 502/2000] [Batch 9/10] [D loss: 0.672633] [G loss: 0.738469]\n",
      "[Epoch 503/2000] [Batch 9/10] [D loss: 0.673666] [G loss: 0.736812]\n",
      "[Epoch 504/2000] [Batch 9/10] [D loss: 0.675901] [G loss: 0.732322]\n",
      "[Epoch 505/2000] [Batch 9/10] [D loss: 0.678292] [G loss: 0.727664]\n",
      "[Epoch 506/2000] [Batch 9/10] [D loss: 0.680041] [G loss: 0.724570]\n",
      "[Epoch 507/2000] [Batch 9/10] [D loss: 0.681251] [G loss: 0.722651]\n",
      "[Epoch 508/2000] [Batch 9/10] [D loss: 0.682719] [G loss: 0.720260]\n",
      "[Epoch 509/2000] [Batch 9/10] [D loss: 0.682889] [G loss: 0.720501]\n",
      "[Epoch 510/2000] [Batch 9/10] [D loss: 0.683131] [G loss: 0.720592]\n",
      "[Epoch 511/2000] [Batch 9/10] [D loss: 0.683019] [G loss: 0.721243]\n",
      "[Epoch 512/2000] [Batch 9/10] [D loss: 0.682794] [G loss: 0.721985]\n",
      "[Epoch 513/2000] [Batch 9/10] [D loss: 0.681990] [G loss: 0.723773]\n",
      "[Epoch 514/2000] [Batch 9/10] [D loss: 0.681208] [G loss: 0.725286]\n",
      "[Epoch 515/2000] [Batch 9/10] [D loss: 0.680238] [G loss: 0.727086]\n",
      "[Epoch 516/2000] [Batch 9/10] [D loss: 0.679430] [G loss: 0.728393]\n",
      "[Epoch 517/2000] [Batch 9/10] [D loss: 0.678060] [G loss: 0.730772]\n",
      "[Epoch 518/2000] [Batch 9/10] [D loss: 0.676940] [G loss: 0.732479]\n",
      "[Epoch 519/2000] [Batch 9/10] [D loss: 0.675930] [G loss: 0.733887]\n",
      "[Epoch 520/2000] [Batch 9/10] [D loss: 0.674884] [G loss: 0.735262]\n",
      "[Epoch 521/2000] [Batch 9/10] [D loss: 0.673920] [G loss: 0.736461]\n",
      "[Epoch 522/2000] [Batch 9/10] [D loss: 0.673151] [G loss: 0.737243]\n",
      "[Epoch 523/2000] [Batch 9/10] [D loss: 0.672755] [G loss: 0.737301]\n",
      "[Epoch 524/2000] [Batch 9/10] [D loss: 0.672724] [G loss: 0.736690]\n",
      "[Epoch 525/2000] [Batch 9/10] [D loss: 0.674245] [G loss: 0.732991]\n",
      "[Epoch 526/2000] [Batch 9/10] [D loss: 0.675416] [G loss: 0.730478]\n",
      "[Epoch 527/2000] [Batch 9/10] [D loss: 0.679234] [G loss: 0.723055]\n",
      "[Epoch 528/2000] [Batch 9/10] [D loss: 0.684105] [G loss: 0.714587]\n",
      "[Epoch 529/2000] [Batch 9/10] [D loss: 0.693352] [G loss: 0.698968]\n",
      "[Epoch 530/2000] [Batch 9/10] [D loss: 0.698515] [G loss: 0.692253]\n",
      "[Epoch 531/2000] [Batch 9/10] [D loss: 0.702721] [G loss: 0.687112]\n",
      "[Epoch 532/2000] [Batch 9/10] [D loss: 0.702645] [G loss: 0.689270]\n",
      "[Epoch 533/2000] [Batch 9/10] [D loss: 0.703163] [G loss: 0.689353]\n",
      "[Epoch 534/2000] [Batch 9/10] [D loss: 0.702874] [G loss: 0.690344]\n",
      "[Epoch 535/2000] [Batch 9/10] [D loss: 0.702578] [G loss: 0.690836]\n",
      "[Epoch 536/2000] [Batch 9/10] [D loss: 0.701388] [G loss: 0.692672]\n",
      "[Epoch 537/2000] [Batch 9/10] [D loss: 0.697263] [G loss: 0.700132]\n",
      "[Epoch 538/2000] [Batch 9/10] [D loss: 0.697037] [G loss: 0.699566]\n",
      "[Epoch 539/2000] [Batch 9/10] [D loss: 0.695101] [G loss: 0.702470]\n",
      "[Epoch 540/2000] [Batch 9/10] [D loss: 0.693067] [G loss: 0.705088]\n",
      "[Epoch 541/2000] [Batch 9/10] [D loss: 0.690665] [G loss: 0.708524]\n",
      "[Epoch 542/2000] [Batch 9/10] [D loss: 0.687957] [G loss: 0.712230]\n",
      "[Epoch 543/2000] [Batch 9/10] [D loss: 0.685051] [G loss: 0.716542]\n",
      "[Epoch 544/2000] [Batch 9/10] [D loss: 0.682725] [G loss: 0.719393]\n",
      "[Epoch 545/2000] [Batch 9/10] [D loss: 0.680530] [G loss: 0.721835]\n",
      "[Epoch 546/2000] [Batch 9/10] [D loss: 0.678176] [G loss: 0.724675]\n",
      "[Epoch 547/2000] [Batch 9/10] [D loss: 0.675571] [G loss: 0.727882]\n",
      "[Epoch 548/2000] [Batch 9/10] [D loss: 0.673409] [G loss: 0.730188]\n",
      "[Epoch 549/2000] [Batch 9/10] [D loss: 0.671184] [G loss: 0.732506]\n",
      "[Epoch 550/2000] [Batch 9/10] [D loss: 0.668806] [G loss: 0.735204]\n",
      "[Epoch 551/2000] [Batch 9/10] [D loss: 0.666722] [G loss: 0.737166]\n",
      "[Epoch 552/2000] [Batch 9/10] [D loss: 0.664792] [G loss: 0.738708]\n",
      "[Epoch 553/2000] [Batch 9/10] [D loss: 0.662524] [G loss: 0.741064]\n",
      "[Epoch 554/2000] [Batch 9/10] [D loss: 0.660942] [G loss: 0.741807]\n",
      "[Epoch 555/2000] [Batch 9/10] [D loss: 0.659810] [G loss: 0.741431]\n",
      "[Epoch 556/2000] [Batch 9/10] [D loss: 0.659068] [G loss: 0.740149]\n",
      "[Epoch 557/2000] [Batch 9/10] [D loss: 0.658805] [G loss: 0.737835]\n",
      "[Epoch 558/2000] [Batch 9/10] [D loss: 0.657376] [G loss: 0.738253]\n",
      "[Epoch 559/2000] [Batch 9/10] [D loss: 0.656236] [G loss: 0.738263]\n",
      "[Epoch 560/2000] [Batch 9/10] [D loss: 0.655876] [G loss: 0.736764]\n",
      "[Epoch 561/2000] [Batch 9/10] [D loss: 0.655509] [G loss: 0.735496]\n",
      "[Epoch 562/2000] [Batch 9/10] [D loss: 0.655566] [G loss: 0.733320]\n",
      "[Epoch 563/2000] [Batch 9/10] [D loss: 0.655092] [G loss: 0.732401]\n",
      "[Epoch 564/2000] [Batch 9/10] [D loss: 0.654014] [G loss: 0.732795]\n",
      "[Epoch 565/2000] [Batch 9/10] [D loss: 0.653455] [G loss: 0.732091]\n",
      "[Epoch 566/2000] [Batch 9/10] [D loss: 0.652703] [G loss: 0.731869]\n",
      "[Epoch 567/2000] [Batch 9/10] [D loss: 0.651907] [G loss: 0.731845]\n",
      "[Epoch 568/2000] [Batch 9/10] [D loss: 0.650991] [G loss: 0.732125]\n",
      "[Epoch 569/2000] [Batch 9/10] [D loss: 0.649549] [G loss: 0.733634]\n",
      "[Epoch 570/2000] [Batch 9/10] [D loss: 0.648324] [G loss: 0.734697]\n",
      "[Epoch 571/2000] [Batch 9/10] [D loss: 0.647623] [G loss: 0.734624]\n",
      "[Epoch 572/2000] [Batch 9/10] [D loss: 0.646206] [G loss: 0.736199]\n",
      "[Epoch 573/2000] [Batch 9/10] [D loss: 0.645145] [G loss: 0.737003]\n",
      "[Epoch 574/2000] [Batch 9/10] [D loss: 0.644138] [G loss: 0.737710]\n",
      "[Epoch 575/2000] [Batch 9/10] [D loss: 0.643271] [G loss: 0.738166]\n",
      "[Epoch 576/2000] [Batch 9/10] [D loss: 0.642117] [G loss: 0.739296]\n",
      "[Epoch 577/2000] [Batch 9/10] [D loss: 0.640965] [G loss: 0.740457]\n",
      "[Epoch 578/2000] [Batch 9/10] [D loss: 0.640113] [G loss: 0.740997]\n",
      "[Epoch 579/2000] [Batch 9/10] [D loss: 0.639278] [G loss: 0.741564]\n",
      "[Epoch 580/2000] [Batch 9/10] [D loss: 0.638535] [G loss: 0.741979]\n",
      "[Epoch 581/2000] [Batch 9/10] [D loss: 0.638167] [G loss: 0.741672]\n",
      "[Epoch 582/2000] [Batch 9/10] [D loss: 0.638035] [G loss: 0.741080]\n",
      "[Epoch 583/2000] [Batch 9/10] [D loss: 0.638886] [G loss: 0.738761]\n",
      "[Epoch 584/2000] [Batch 9/10] [D loss: 0.640618] [G loss: 0.734891]\n",
      "[Epoch 585/2000] [Batch 9/10] [D loss: 0.643210] [G loss: 0.729708]\n",
      "[Epoch 586/2000] [Batch 9/10] [D loss: 0.647627] [G loss: 0.721516]\n",
      "[Epoch 587/2000] [Batch 9/10] [D loss: 0.651628] [G loss: 0.715284]\n",
      "[Epoch 588/2000] [Batch 9/10] [D loss: 0.657867] [G loss: 0.705114]\n",
      "[Epoch 589/2000] [Batch 9/10] [D loss: 0.662277] [G loss: 0.699466]\n",
      "[Epoch 590/2000] [Batch 9/10] [D loss: 0.667332] [G loss: 0.692594]\n",
      "[Epoch 591/2000] [Batch 9/10] [D loss: 0.670527] [G loss: 0.689638]\n",
      "[Epoch 592/2000] [Batch 9/10] [D loss: 0.673103] [G loss: 0.687775]\n",
      "[Epoch 593/2000] [Batch 9/10] [D loss: 0.674955] [G loss: 0.687182]\n",
      "[Epoch 594/2000] [Batch 9/10] [D loss: 0.678134] [G loss: 0.683630]\n",
      "[Epoch 595/2000] [Batch 9/10] [D loss: 0.678979] [G loss: 0.684579]\n",
      "[Epoch 596/2000] [Batch 9/10] [D loss: 0.679250] [G loss: 0.686495]\n",
      "[Epoch 597/2000] [Batch 9/10] [D loss: 0.680700] [G loss: 0.685873]\n",
      "[Epoch 598/2000] [Batch 9/10] [D loss: 0.680745] [G loss: 0.687843]\n",
      "[Epoch 599/2000] [Batch 9/10] [D loss: 0.682554] [G loss: 0.685933]\n",
      "[Epoch 600/2000] [Batch 9/10] [D loss: 0.681225] [G loss: 0.690515]\n",
      "[Epoch 601/2000] [Batch 9/10] [D loss: 0.682120] [G loss: 0.690285]\n",
      "[Epoch 602/2000] [Batch 9/10] [D loss: 0.681972] [G loss: 0.692089]\n",
      "[Epoch 603/2000] [Batch 9/10] [D loss: 0.681852] [G loss: 0.693696]\n",
      "[Epoch 604/2000] [Batch 9/10] [D loss: 0.681608] [G loss: 0.695474]\n",
      "[Epoch 605/2000] [Batch 9/10] [D loss: 0.682365] [G loss: 0.695163]\n",
      "[Epoch 606/2000] [Batch 9/10] [D loss: 0.681291] [G loss: 0.698718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 607/2000] [Batch 9/10] [D loss: 0.680068] [G loss: 0.702656]\n",
      "[Epoch 608/2000] [Batch 9/10] [D loss: 0.681178] [G loss: 0.701636]\n",
      "[Epoch 609/2000] [Batch 9/10] [D loss: 0.680778] [G loss: 0.703566]\n",
      "[Epoch 610/2000] [Batch 9/10] [D loss: 0.680731] [G loss: 0.704588]\n",
      "[Epoch 611/2000] [Batch 9/10] [D loss: 0.679247] [G loss: 0.708688]\n",
      "[Epoch 612/2000] [Batch 9/10] [D loss: 0.679834] [G loss: 0.708282]\n",
      "[Epoch 613/2000] [Batch 9/10] [D loss: 0.679001] [G loss: 0.710753]\n",
      "[Epoch 614/2000] [Batch 9/10] [D loss: 0.678480] [G loss: 0.712506]\n",
      "[Epoch 615/2000] [Batch 9/10] [D loss: 0.678624] [G loss: 0.712826]\n",
      "[Epoch 616/2000] [Batch 9/10] [D loss: 0.677165] [G loss: 0.716382]\n",
      "[Epoch 617/2000] [Batch 9/10] [D loss: 0.677203] [G loss: 0.716774]\n",
      "[Epoch 618/2000] [Batch 9/10] [D loss: 0.676499] [G loss: 0.718664]\n",
      "[Epoch 619/2000] [Batch 9/10] [D loss: 0.675888] [G loss: 0.720214]\n",
      "[Epoch 620/2000] [Batch 9/10] [D loss: 0.675558] [G loss: 0.721121]\n",
      "[Epoch 621/2000] [Batch 9/10] [D loss: 0.674954] [G loss: 0.722601]\n",
      "[Epoch 622/2000] [Batch 9/10] [D loss: 0.674533] [G loss: 0.723458]\n",
      "[Epoch 623/2000] [Batch 9/10] [D loss: 0.674076] [G loss: 0.724110]\n",
      "[Epoch 624/2000] [Batch 9/10] [D loss: 0.673679] [G loss: 0.724620]\n",
      "[Epoch 625/2000] [Batch 9/10] [D loss: 0.673189] [G loss: 0.725186]\n",
      "[Epoch 626/2000] [Batch 9/10] [D loss: 0.672850] [G loss: 0.725510]\n",
      "[Epoch 627/2000] [Batch 9/10] [D loss: 0.672269] [G loss: 0.726316]\n",
      "[Epoch 628/2000] [Batch 9/10] [D loss: 0.671155] [G loss: 0.728243]\n",
      "[Epoch 629/2000] [Batch 9/10] [D loss: 0.671002] [G loss: 0.728085]\n",
      "[Epoch 630/2000] [Batch 9/10] [D loss: 0.670689] [G loss: 0.728279]\n",
      "[Epoch 631/2000] [Batch 9/10] [D loss: 0.670197] [G loss: 0.728853]\n",
      "[Epoch 632/2000] [Batch 9/10] [D loss: 0.669737] [G loss: 0.729294]\n",
      "[Epoch 633/2000] [Batch 9/10] [D loss: 0.668975] [G loss: 0.730483]\n",
      "[Epoch 634/2000] [Batch 9/10] [D loss: 0.668643] [G loss: 0.730713]\n",
      "[Epoch 635/2000] [Batch 9/10] [D loss: 0.667974] [G loss: 0.731674]\n",
      "[Epoch 636/2000] [Batch 9/10] [D loss: 0.667840] [G loss: 0.731415]\n",
      "[Epoch 637/2000] [Batch 9/10] [D loss: 0.667212] [G loss: 0.732254]\n",
      "[Epoch 638/2000] [Batch 9/10] [D loss: 0.666713] [G loss: 0.732830]\n",
      "[Epoch 639/2000] [Batch 9/10] [D loss: 0.666261] [G loss: 0.733268]\n",
      "[Epoch 640/2000] [Batch 9/10] [D loss: 0.665870] [G loss: 0.733661]\n",
      "[Epoch 641/2000] [Batch 9/10] [D loss: 0.665395] [G loss: 0.734288]\n",
      "[Epoch 642/2000] [Batch 9/10] [D loss: 0.665063] [G loss: 0.734583]\n",
      "[Epoch 643/2000] [Batch 9/10] [D loss: 0.664286] [G loss: 0.735841]\n",
      "[Epoch 644/2000] [Batch 9/10] [D loss: 0.664119] [G loss: 0.735820]\n",
      "[Epoch 645/2000] [Batch 9/10] [D loss: 0.663516] [G loss: 0.736707]\n",
      "[Epoch 646/2000] [Batch 9/10] [D loss: 0.663078] [G loss: 0.737306]\n",
      "[Epoch 647/2000] [Batch 9/10] [D loss: 0.662865] [G loss: 0.737448]\n",
      "[Epoch 648/2000] [Batch 9/10] [D loss: 0.662895] [G loss: 0.737111]\n",
      "[Epoch 649/2000] [Batch 9/10] [D loss: 0.662026] [G loss: 0.738668]\n",
      "[Epoch 650/2000] [Batch 9/10] [D loss: 0.661976] [G loss: 0.738611]\n",
      "[Epoch 651/2000] [Batch 9/10] [D loss: 0.661823] [G loss: 0.738750]\n",
      "[Epoch 652/2000] [Batch 9/10] [D loss: 0.661739] [G loss: 0.738844]\n",
      "[Epoch 653/2000] [Batch 9/10] [D loss: 0.661555] [G loss: 0.739205]\n",
      "[Epoch 654/2000] [Batch 9/10] [D loss: 0.661571] [G loss: 0.739186]\n",
      "[Epoch 655/2000] [Batch 9/10] [D loss: 0.660975] [G loss: 0.740363]\n",
      "[Epoch 656/2000] [Batch 9/10] [D loss: 0.660697] [G loss: 0.741076]\n",
      "[Epoch 657/2000] [Batch 9/10] [D loss: 0.660621] [G loss: 0.741476]\n",
      "[Epoch 658/2000] [Batch 9/10] [D loss: 0.660940] [G loss: 0.741079]\n",
      "[Epoch 659/2000] [Batch 9/10] [D loss: 0.660917] [G loss: 0.741530]\n",
      "[Epoch 660/2000] [Batch 9/10] [D loss: 0.661628] [G loss: 0.740625]\n",
      "[Epoch 661/2000] [Batch 9/10] [D loss: 0.662469] [G loss: 0.739590]\n",
      "[Epoch 662/2000] [Batch 9/10] [D loss: 0.663545] [G loss: 0.738238]\n",
      "[Epoch 663/2000] [Batch 9/10] [D loss: 0.665765] [G loss: 0.734695]\n",
      "[Epoch 664/2000] [Batch 9/10] [D loss: 0.666332] [G loss: 0.734697]\n",
      "[Epoch 665/2000] [Batch 9/10] [D loss: 0.668978] [G loss: 0.730678]\n",
      "[Epoch 666/2000] [Batch 9/10] [D loss: 0.671305] [G loss: 0.727697]\n",
      "[Epoch 667/2000] [Batch 9/10] [D loss: 0.673663] [G loss: 0.724980]\n",
      "[Epoch 668/2000] [Batch 9/10] [D loss: 0.676880] [G loss: 0.721137]\n",
      "[Epoch 669/2000] [Batch 9/10] [D loss: 0.677559] [G loss: 0.722625]\n",
      "[Epoch 670/2000] [Batch 9/10] [D loss: 0.678990] [G loss: 0.722497]\n",
      "[Epoch 671/2000] [Batch 9/10] [D loss: 0.681720] [G loss: 0.719898]\n",
      "[Epoch 672/2000] [Batch 9/10] [D loss: 0.682433] [G loss: 0.720925]\n",
      "[Epoch 673/2000] [Batch 9/10] [D loss: 0.684212] [G loss: 0.719813]\n",
      "[Epoch 674/2000] [Batch 9/10] [D loss: 0.686078] [G loss: 0.718288]\n",
      "[Epoch 675/2000] [Batch 9/10] [D loss: 0.687213] [G loss: 0.717996]\n",
      "[Epoch 676/2000] [Batch 9/10] [D loss: 0.685344] [G loss: 0.723831]\n",
      "[Epoch 677/2000] [Batch 9/10] [D loss: 0.683392] [G loss: 0.729313]\n",
      "[Epoch 678/2000] [Batch 9/10] [D loss: 0.680427] [G loss: 0.736675]\n",
      "[Epoch 679/2000] [Batch 9/10] [D loss: 0.676994] [G loss: 0.744713]\n",
      "[Epoch 680/2000] [Batch 9/10] [D loss: 0.674271] [G loss: 0.750826]\n",
      "[Epoch 681/2000] [Batch 9/10] [D loss: 0.670526] [G loss: 0.758954]\n",
      "[Epoch 682/2000] [Batch 9/10] [D loss: 0.667304] [G loss: 0.765698]\n",
      "[Epoch 683/2000] [Batch 9/10] [D loss: 0.664384] [G loss: 0.771453]\n",
      "[Epoch 684/2000] [Batch 9/10] [D loss: 0.661558] [G loss: 0.776878]\n",
      "[Epoch 685/2000] [Batch 9/10] [D loss: 0.658561] [G loss: 0.782597]\n",
      "[Epoch 686/2000] [Batch 9/10] [D loss: 0.656357] [G loss: 0.786348]\n",
      "[Epoch 687/2000] [Batch 9/10] [D loss: 0.653899] [G loss: 0.790635]\n",
      "[Epoch 688/2000] [Batch 9/10] [D loss: 0.651173] [G loss: 0.795570]\n",
      "[Epoch 689/2000] [Batch 9/10] [D loss: 0.649497] [G loss: 0.797889]\n",
      "[Epoch 690/2000] [Batch 9/10] [D loss: 0.647977] [G loss: 0.799765]\n",
      "[Epoch 691/2000] [Batch 9/10] [D loss: 0.646787] [G loss: 0.800911]\n",
      "[Epoch 692/2000] [Batch 9/10] [D loss: 0.647122] [G loss: 0.797945]\n",
      "[Epoch 693/2000] [Batch 9/10] [D loss: 0.653214] [G loss: 0.780826]\n",
      "[Epoch 694/2000] [Batch 9/10] [D loss: 0.661731] [G loss: 0.760089]\n",
      "[Epoch 695/2000] [Batch 9/10] [D loss: 0.670557] [G loss: 0.741007]\n",
      "[Epoch 696/2000] [Batch 9/10] [D loss: 0.679227] [G loss: 0.724516]\n",
      "[Epoch 697/2000] [Batch 9/10] [D loss: 0.688158] [G loss: 0.709817]\n",
      "[Epoch 698/2000] [Batch 9/10] [D loss: 0.693710] [G loss: 0.702496]\n",
      "[Epoch 699/2000] [Batch 9/10] [D loss: 0.696005] [G loss: 0.701341]\n",
      "[Epoch 700/2000] [Batch 9/10] [D loss: 0.697009] [G loss: 0.701079]\n",
      "[Epoch 701/2000] [Batch 9/10] [D loss: 0.695251] [G loss: 0.706491]\n",
      "[Epoch 702/2000] [Batch 9/10] [D loss: 0.694892] [G loss: 0.707164]\n",
      "[Epoch 703/2000] [Batch 9/10] [D loss: 0.694342] [G loss: 0.708555]\n",
      "[Epoch 704/2000] [Batch 9/10] [D loss: 0.692797] [G loss: 0.711378]\n",
      "[Epoch 705/2000] [Batch 9/10] [D loss: 0.691048] [G loss: 0.713933]\n",
      "[Epoch 706/2000] [Batch 9/10] [D loss: 0.689849] [G loss: 0.715584]\n",
      "[Epoch 707/2000] [Batch 9/10] [D loss: 0.688202] [G loss: 0.717883]\n",
      "[Epoch 708/2000] [Batch 9/10] [D loss: 0.686024] [G loss: 0.720803]\n",
      "[Epoch 709/2000] [Batch 9/10] [D loss: 0.684176] [G loss: 0.723315]\n",
      "[Epoch 710/2000] [Batch 9/10] [D loss: 0.681794] [G loss: 0.726864]\n",
      "[Epoch 711/2000] [Batch 9/10] [D loss: 0.678956] [G loss: 0.730985]\n",
      "[Epoch 712/2000] [Batch 9/10] [D loss: 0.676535] [G loss: 0.734737]\n",
      "[Epoch 713/2000] [Batch 9/10] [D loss: 0.673424] [G loss: 0.739543]\n",
      "[Epoch 714/2000] [Batch 9/10] [D loss: 0.671502] [G loss: 0.741243]\n",
      "[Epoch 715/2000] [Batch 9/10] [D loss: 0.668798] [G loss: 0.745032]\n",
      "[Epoch 716/2000] [Batch 9/10] [D loss: 0.666330] [G loss: 0.748046]\n",
      "[Epoch 717/2000] [Batch 9/10] [D loss: 0.663286] [G loss: 0.752693]\n",
      "[Epoch 718/2000] [Batch 9/10] [D loss: 0.659844] [G loss: 0.758267]\n",
      "[Epoch 719/2000] [Batch 9/10] [D loss: 0.658834] [G loss: 0.757774]\n",
      "[Epoch 720/2000] [Batch 9/10] [D loss: 0.656056] [G loss: 0.761556]\n",
      "[Epoch 721/2000] [Batch 9/10] [D loss: 0.652974] [G loss: 0.766154]\n",
      "[Epoch 722/2000] [Batch 9/10] [D loss: 0.650179] [G loss: 0.770244]\n",
      "[Epoch 723/2000] [Batch 9/10] [D loss: 0.648546] [G loss: 0.771211]\n",
      "[Epoch 724/2000] [Batch 9/10] [D loss: 0.645156] [G loss: 0.776720]\n",
      "[Epoch 725/2000] [Batch 9/10] [D loss: 0.642722] [G loss: 0.779893]\n",
      "[Epoch 726/2000] [Batch 9/10] [D loss: 0.639506] [G loss: 0.784992]\n",
      "[Epoch 727/2000] [Batch 9/10] [D loss: 0.637387] [G loss: 0.787224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 728/2000] [Batch 9/10] [D loss: 0.634917] [G loss: 0.790429]\n",
      "[Epoch 729/2000] [Batch 9/10] [D loss: 0.631975] [G loss: 0.794893]\n",
      "[Epoch 730/2000] [Batch 9/10] [D loss: 0.629001] [G loss: 0.799428]\n",
      "[Epoch 731/2000] [Batch 9/10] [D loss: 0.626874] [G loss: 0.801877]\n",
      "[Epoch 732/2000] [Batch 9/10] [D loss: 0.625007] [G loss: 0.803586]\n",
      "[Epoch 733/2000] [Batch 9/10] [D loss: 0.621628] [G loss: 0.809295]\n",
      "[Epoch 734/2000] [Batch 9/10] [D loss: 0.619428] [G loss: 0.811954]\n",
      "[Epoch 735/2000] [Batch 9/10] [D loss: 0.617175] [G loss: 0.814718]\n",
      "[Epoch 736/2000] [Batch 9/10] [D loss: 0.614421] [G loss: 0.818962]\n",
      "[Epoch 737/2000] [Batch 9/10] [D loss: 0.612800] [G loss: 0.820102]\n",
      "[Epoch 738/2000] [Batch 9/10] [D loss: 0.610399] [G loss: 0.823492]\n",
      "[Epoch 739/2000] [Batch 9/10] [D loss: 0.608784] [G loss: 0.824761]\n",
      "[Epoch 740/2000] [Batch 9/10] [D loss: 0.606463] [G loss: 0.827970]\n",
      "[Epoch 741/2000] [Batch 9/10] [D loss: 0.604267] [G loss: 0.830929]\n",
      "[Epoch 742/2000] [Batch 9/10] [D loss: 0.601945] [G loss: 0.834330]\n",
      "[Epoch 743/2000] [Batch 9/10] [D loss: 0.600536] [G loss: 0.835323]\n",
      "[Epoch 744/2000] [Batch 9/10] [D loss: 0.599044] [G loss: 0.836604]\n",
      "[Epoch 745/2000] [Batch 9/10] [D loss: 0.597798] [G loss: 0.837371]\n",
      "[Epoch 746/2000] [Batch 9/10] [D loss: 0.597007] [G loss: 0.837017]\n",
      "[Epoch 747/2000] [Batch 9/10] [D loss: 0.596595] [G loss: 0.835769]\n",
      "[Epoch 748/2000] [Batch 9/10] [D loss: 0.596119] [G loss: 0.835032]\n",
      "[Epoch 749/2000] [Batch 9/10] [D loss: 0.596330] [G loss: 0.832573]\n",
      "[Epoch 750/2000] [Batch 9/10] [D loss: 0.596710] [G loss: 0.829996]\n",
      "[Epoch 751/2000] [Batch 9/10] [D loss: 0.597854] [G loss: 0.825371]\n",
      "[Epoch 752/2000] [Batch 9/10] [D loss: 0.598771] [G loss: 0.821562]\n",
      "[Epoch 753/2000] [Batch 9/10] [D loss: 0.599464] [G loss: 0.818511]\n",
      "[Epoch 754/2000] [Batch 9/10] [D loss: 0.599779] [G loss: 0.816517]\n",
      "[Epoch 755/2000] [Batch 9/10] [D loss: 0.600171] [G loss: 0.814266]\n",
      "[Epoch 756/2000] [Batch 9/10] [D loss: 0.600429] [G loss: 0.812361]\n",
      "[Epoch 757/2000] [Batch 9/10] [D loss: 0.600265] [G loss: 0.811576]\n",
      "[Epoch 758/2000] [Batch 9/10] [D loss: 0.599563] [G loss: 0.812307]\n",
      "[Epoch 759/2000] [Batch 9/10] [D loss: 0.599856] [G loss: 0.810166]\n",
      "[Epoch 760/2000] [Batch 9/10] [D loss: 0.599293] [G loss: 0.810425]\n",
      "[Epoch 761/2000] [Batch 9/10] [D loss: 0.599119] [G loss: 0.809574]\n",
      "[Epoch 762/2000] [Batch 9/10] [D loss: 0.598748] [G loss: 0.809317]\n",
      "[Epoch 763/2000] [Batch 9/10] [D loss: 0.598423] [G loss: 0.809000]\n",
      "[Epoch 764/2000] [Batch 9/10] [D loss: 0.598453] [G loss: 0.807781]\n",
      "[Epoch 765/2000] [Batch 9/10] [D loss: 0.598313] [G loss: 0.807152]\n",
      "[Epoch 766/2000] [Batch 9/10] [D loss: 0.599218] [G loss: 0.803924]\n",
      "[Epoch 767/2000] [Batch 9/10] [D loss: 0.599992] [G loss: 0.801768]\n",
      "[Epoch 768/2000] [Batch 9/10] [D loss: 0.602430] [G loss: 0.796082]\n",
      "[Epoch 769/2000] [Batch 9/10] [D loss: 0.606914] [G loss: 0.785937]\n",
      "[Epoch 770/2000] [Batch 9/10] [D loss: 0.611425] [G loss: 0.776444]\n",
      "[Epoch 771/2000] [Batch 9/10] [D loss: 0.615416] [G loss: 0.768948]\n",
      "[Epoch 772/2000] [Batch 9/10] [D loss: 0.618949] [G loss: 0.762875]\n",
      "[Epoch 773/2000] [Batch 9/10] [D loss: 0.623467] [G loss: 0.754392]\n",
      "[Epoch 774/2000] [Batch 9/10] [D loss: 0.626860] [G loss: 0.749081]\n",
      "[Epoch 775/2000] [Batch 9/10] [D loss: 0.631492] [G loss: 0.740950]\n",
      "[Epoch 776/2000] [Batch 9/10] [D loss: 0.636766] [G loss: 0.732405]\n",
      "[Epoch 777/2000] [Batch 9/10] [D loss: 0.644124] [G loss: 0.720183]\n",
      "[Epoch 778/2000] [Batch 9/10] [D loss: 0.654771] [G loss: 0.702837]\n",
      "[Epoch 779/2000] [Batch 9/10] [D loss: 0.672209] [G loss: 0.674479]\n",
      "[Epoch 780/2000] [Batch 9/10] [D loss: 0.691031] [G loss: 0.645452]\n",
      "[Epoch 781/2000] [Batch 9/10] [D loss: 0.711674] [G loss: 0.615447]\n",
      "[Epoch 782/2000] [Batch 9/10] [D loss: 0.723457] [G loss: 0.602101]\n",
      "[Epoch 783/2000] [Batch 9/10] [D loss: 0.733552] [G loss: 0.591640]\n",
      "[Epoch 784/2000] [Batch 9/10] [D loss: 0.734260] [G loss: 0.597520]\n",
      "[Epoch 785/2000] [Batch 9/10] [D loss: 0.738112] [G loss: 0.595587]\n",
      "[Epoch 786/2000] [Batch 9/10] [D loss: 0.741874] [G loss: 0.594665]\n",
      "[Epoch 787/2000] [Batch 9/10] [D loss: 0.743655] [G loss: 0.596238]\n",
      "[Epoch 788/2000] [Batch 9/10] [D loss: 0.742249] [G loss: 0.602841]\n",
      "[Epoch 789/2000] [Batch 9/10] [D loss: 0.743224] [G loss: 0.605732]\n",
      "[Epoch 790/2000] [Batch 9/10] [D loss: 0.740452] [G loss: 0.615543]\n",
      "[Epoch 791/2000] [Batch 9/10] [D loss: 0.739459] [G loss: 0.620763]\n",
      "[Epoch 792/2000] [Batch 9/10] [D loss: 0.739514] [G loss: 0.624023]\n",
      "[Epoch 793/2000] [Batch 9/10] [D loss: 0.738303] [G loss: 0.629651]\n",
      "[Epoch 794/2000] [Batch 9/10] [D loss: 0.736253] [G loss: 0.636815]\n",
      "[Epoch 795/2000] [Batch 9/10] [D loss: 0.734547] [G loss: 0.642745]\n",
      "[Epoch 796/2000] [Batch 9/10] [D loss: 0.734402] [G loss: 0.645298]\n",
      "[Epoch 797/2000] [Batch 9/10] [D loss: 0.731419] [G loss: 0.654321]\n",
      "[Epoch 798/2000] [Batch 9/10] [D loss: 0.731970] [G loss: 0.654718]\n",
      "[Epoch 799/2000] [Batch 9/10] [D loss: 0.728109] [G loss: 0.664758]\n",
      "[Epoch 800/2000] [Batch 9/10] [D loss: 0.727960] [G loss: 0.666547]\n",
      "[Epoch 801/2000] [Batch 9/10] [D loss: 0.726660] [G loss: 0.670866]\n",
      "[Epoch 802/2000] [Batch 9/10] [D loss: 0.725204] [G loss: 0.675023]\n",
      "[Epoch 803/2000] [Batch 9/10] [D loss: 0.724530] [G loss: 0.677396]\n",
      "[Epoch 804/2000] [Batch 9/10] [D loss: 0.722983] [G loss: 0.681771]\n",
      "[Epoch 805/2000] [Batch 9/10] [D loss: 0.721739] [G loss: 0.685177]\n",
      "[Epoch 806/2000] [Batch 9/10] [D loss: 0.720668] [G loss: 0.687712]\n",
      "[Epoch 807/2000] [Batch 9/10] [D loss: 0.719296] [G loss: 0.691341]\n",
      "[Epoch 808/2000] [Batch 9/10] [D loss: 0.717899] [G loss: 0.694524]\n",
      "[Epoch 809/2000] [Batch 9/10] [D loss: 0.717703] [G loss: 0.694922]\n",
      "[Epoch 810/2000] [Batch 9/10] [D loss: 0.716428] [G loss: 0.697741]\n",
      "[Epoch 811/2000] [Batch 9/10] [D loss: 0.715140] [G loss: 0.700403]\n",
      "[Epoch 812/2000] [Batch 9/10] [D loss: 0.714450] [G loss: 0.701616]\n",
      "[Epoch 813/2000] [Batch 9/10] [D loss: 0.713380] [G loss: 0.703682]\n",
      "[Epoch 814/2000] [Batch 9/10] [D loss: 0.713697] [G loss: 0.702753]\n",
      "[Epoch 815/2000] [Batch 9/10] [D loss: 0.711432] [G loss: 0.706875]\n",
      "[Epoch 816/2000] [Batch 9/10] [D loss: 0.711637] [G loss: 0.706012]\n",
      "[Epoch 817/2000] [Batch 9/10] [D loss: 0.711724] [G loss: 0.705232]\n",
      "[Epoch 818/2000] [Batch 9/10] [D loss: 0.712205] [G loss: 0.703673]\n",
      "[Epoch 819/2000] [Batch 9/10] [D loss: 0.712584] [G loss: 0.702062]\n",
      "[Epoch 820/2000] [Batch 9/10] [D loss: 0.713132] [G loss: 0.699855]\n",
      "[Epoch 821/2000] [Batch 9/10] [D loss: 0.714283] [G loss: 0.696468]\n",
      "[Epoch 822/2000] [Batch 9/10] [D loss: 0.718628] [G loss: 0.687357]\n",
      "[Epoch 823/2000] [Batch 9/10] [D loss: 0.719985] [G loss: 0.683560]\n",
      "[Epoch 824/2000] [Batch 9/10] [D loss: 0.722618] [G loss: 0.677452]\n",
      "[Epoch 825/2000] [Batch 9/10] [D loss: 0.726179] [G loss: 0.670192]\n",
      "[Epoch 826/2000] [Batch 9/10] [D loss: 0.729202] [G loss: 0.663876]\n",
      "[Epoch 827/2000] [Batch 9/10] [D loss: 0.732129] [G loss: 0.658071]\n",
      "[Epoch 828/2000] [Batch 9/10] [D loss: 0.736129] [G loss: 0.650956]\n",
      "[Epoch 829/2000] [Batch 9/10] [D loss: 0.739586] [G loss: 0.644505]\n",
      "[Epoch 830/2000] [Batch 9/10] [D loss: 0.738718] [G loss: 0.646672]\n",
      "[Epoch 831/2000] [Batch 9/10] [D loss: 0.741605] [G loss: 0.641222]\n",
      "[Epoch 832/2000] [Batch 9/10] [D loss: 0.740881] [G loss: 0.642528]\n",
      "[Epoch 833/2000] [Batch 9/10] [D loss: 0.739568] [G loss: 0.642949]\n",
      "[Epoch 834/2000] [Batch 9/10] [D loss: 0.738462] [G loss: 0.643796]\n",
      "[Epoch 835/2000] [Batch 9/10] [D loss: 0.738230] [G loss: 0.642442]\n",
      "[Epoch 836/2000] [Batch 9/10] [D loss: 0.738080] [G loss: 0.641623]\n",
      "[Epoch 837/2000] [Batch 9/10] [D loss: 0.734520] [G loss: 0.646494]\n",
      "[Epoch 838/2000] [Batch 9/10] [D loss: 0.731733] [G loss: 0.648698]\n",
      "[Epoch 839/2000] [Batch 9/10] [D loss: 0.730684] [G loss: 0.649965]\n",
      "[Epoch 840/2000] [Batch 9/10] [D loss: 0.729660] [G loss: 0.650714]\n",
      "[Epoch 841/2000] [Batch 9/10] [D loss: 0.727967] [G loss: 0.652376]\n",
      "[Epoch 842/2000] [Batch 9/10] [D loss: 0.726539] [G loss: 0.654382]\n",
      "[Epoch 843/2000] [Batch 9/10] [D loss: 0.723496] [G loss: 0.657832]\n",
      "[Epoch 844/2000] [Batch 9/10] [D loss: 0.720542] [G loss: 0.662691]\n",
      "[Epoch 845/2000] [Batch 9/10] [D loss: 0.722669] [G loss: 0.658306]\n",
      "[Epoch 846/2000] [Batch 9/10] [D loss: 0.722418] [G loss: 0.657912]\n",
      "[Epoch 847/2000] [Batch 9/10] [D loss: 0.721060] [G loss: 0.660477]\n",
      "[Epoch 848/2000] [Batch 9/10] [D loss: 0.716977] [G loss: 0.665252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 849/2000] [Batch 9/10] [D loss: 0.719539] [G loss: 0.661425]\n",
      "[Epoch 850/2000] [Batch 9/10] [D loss: 0.717745] [G loss: 0.664278]\n",
      "[Epoch 851/2000] [Batch 9/10] [D loss: 0.717446] [G loss: 0.664444]\n",
      "[Epoch 852/2000] [Batch 9/10] [D loss: 0.717350] [G loss: 0.664750]\n",
      "[Epoch 853/2000] [Batch 9/10] [D loss: 0.716875] [G loss: 0.665968]\n",
      "[Epoch 854/2000] [Batch 9/10] [D loss: 0.715918] [G loss: 0.667505]\n",
      "[Epoch 855/2000] [Batch 9/10] [D loss: 0.714198] [G loss: 0.669189]\n",
      "[Epoch 856/2000] [Batch 9/10] [D loss: 0.716047] [G loss: 0.666057]\n",
      "[Epoch 857/2000] [Batch 9/10] [D loss: 0.715838] [G loss: 0.666439]\n",
      "[Epoch 858/2000] [Batch 9/10] [D loss: 0.718133] [G loss: 0.662353]\n",
      "[Epoch 859/2000] [Batch 9/10] [D loss: 0.718164] [G loss: 0.662570]\n",
      "[Epoch 860/2000] [Batch 9/10] [D loss: 0.718558] [G loss: 0.661501]\n",
      "[Epoch 861/2000] [Batch 9/10] [D loss: 0.720268] [G loss: 0.659176]\n",
      "[Epoch 862/2000] [Batch 9/10] [D loss: 0.718815] [G loss: 0.661324]\n",
      "[Epoch 863/2000] [Batch 9/10] [D loss: 0.721365] [G loss: 0.657245]\n",
      "[Epoch 864/2000] [Batch 9/10] [D loss: 0.719079] [G loss: 0.661014]\n",
      "[Epoch 865/2000] [Batch 9/10] [D loss: 0.719064] [G loss: 0.661660]\n",
      "[Epoch 866/2000] [Batch 9/10] [D loss: 0.720534] [G loss: 0.659424]\n",
      "[Epoch 867/2000] [Batch 9/10] [D loss: 0.717327] [G loss: 0.665385]\n",
      "[Epoch 868/2000] [Batch 9/10] [D loss: 0.715821] [G loss: 0.668186]\n",
      "[Epoch 869/2000] [Batch 9/10] [D loss: 0.711898] [G loss: 0.675457]\n",
      "[Epoch 870/2000] [Batch 9/10] [D loss: 0.710917] [G loss: 0.677884]\n",
      "[Epoch 871/2000] [Batch 9/10] [D loss: 0.710691] [G loss: 0.678397]\n",
      "[Epoch 872/2000] [Batch 9/10] [D loss: 0.711592] [G loss: 0.676763]\n",
      "[Epoch 873/2000] [Batch 9/10] [D loss: 0.709777] [G loss: 0.680417]\n",
      "[Epoch 874/2000] [Batch 9/10] [D loss: 0.707249] [G loss: 0.685252]\n",
      "[Epoch 875/2000] [Batch 9/10] [D loss: 0.706968] [G loss: 0.685880]\n",
      "[Epoch 876/2000] [Batch 9/10] [D loss: 0.705261] [G loss: 0.689016]\n",
      "[Epoch 877/2000] [Batch 9/10] [D loss: 0.702725] [G loss: 0.693852]\n",
      "[Epoch 878/2000] [Batch 9/10] [D loss: 0.701488] [G loss: 0.695849]\n",
      "[Epoch 879/2000] [Batch 9/10] [D loss: 0.700404] [G loss: 0.697779]\n",
      "[Epoch 880/2000] [Batch 9/10] [D loss: 0.698043] [G loss: 0.702347]\n",
      "[Epoch 881/2000] [Batch 9/10] [D loss: 0.697030] [G loss: 0.703909]\n",
      "[Epoch 882/2000] [Batch 9/10] [D loss: 0.694955] [G loss: 0.707659]\n",
      "[Epoch 883/2000] [Batch 9/10] [D loss: 0.694050] [G loss: 0.708862]\n",
      "[Epoch 884/2000] [Batch 9/10] [D loss: 0.692069] [G loss: 0.712085]\n",
      "[Epoch 885/2000] [Batch 9/10] [D loss: 0.691637] [G loss: 0.712418]\n",
      "[Epoch 886/2000] [Batch 9/10] [D loss: 0.688495] [G loss: 0.717916]\n",
      "[Epoch 887/2000] [Batch 9/10] [D loss: 0.687239] [G loss: 0.719887]\n",
      "[Epoch 888/2000] [Batch 9/10] [D loss: 0.686190] [G loss: 0.720824]\n",
      "[Epoch 889/2000] [Batch 9/10] [D loss: 0.684768] [G loss: 0.723139]\n",
      "[Epoch 890/2000] [Batch 9/10] [D loss: 0.684163] [G loss: 0.722994]\n",
      "[Epoch 891/2000] [Batch 9/10] [D loss: 0.683129] [G loss: 0.724262]\n",
      "[Epoch 892/2000] [Batch 9/10] [D loss: 0.681689] [G loss: 0.726302]\n",
      "[Epoch 893/2000] [Batch 9/10] [D loss: 0.680205] [G loss: 0.728206]\n",
      "[Epoch 894/2000] [Batch 9/10] [D loss: 0.680078] [G loss: 0.727257]\n",
      "[Epoch 895/2000] [Batch 9/10] [D loss: 0.677802] [G loss: 0.731219]\n",
      "[Epoch 896/2000] [Batch 9/10] [D loss: 0.676576] [G loss: 0.733023]\n",
      "[Epoch 897/2000] [Batch 9/10] [D loss: 0.675937] [G loss: 0.733126]\n",
      "[Epoch 898/2000] [Batch 9/10] [D loss: 0.674690] [G loss: 0.734806]\n",
      "[Epoch 899/2000] [Batch 9/10] [D loss: 0.673633] [G loss: 0.735867]\n",
      "[Epoch 900/2000] [Batch 9/10] [D loss: 0.672711] [G loss: 0.736672]\n",
      "[Epoch 901/2000] [Batch 9/10] [D loss: 0.671929] [G loss: 0.737361]\n",
      "[Epoch 902/2000] [Batch 9/10] [D loss: 0.671139] [G loss: 0.738002]\n",
      "[Epoch 903/2000] [Batch 9/10] [D loss: 0.670630] [G loss: 0.737922]\n",
      "[Epoch 904/2000] [Batch 9/10] [D loss: 0.670630] [G loss: 0.736630]\n",
      "[Epoch 905/2000] [Batch 9/10] [D loss: 0.668879] [G loss: 0.739842]\n",
      "[Epoch 906/2000] [Batch 9/10] [D loss: 0.668685] [G loss: 0.739303]\n",
      "[Epoch 907/2000] [Batch 9/10] [D loss: 0.666673] [G loss: 0.743176]\n",
      "[Epoch 908/2000] [Batch 9/10] [D loss: 0.666428] [G loss: 0.742808]\n",
      "[Epoch 909/2000] [Batch 9/10] [D loss: 0.666519] [G loss: 0.741660]\n",
      "[Epoch 910/2000] [Batch 9/10] [D loss: 0.665660] [G loss: 0.742654]\n",
      "[Epoch 911/2000] [Batch 9/10] [D loss: 0.665473] [G loss: 0.742521]\n",
      "[Epoch 912/2000] [Batch 9/10] [D loss: 0.665143] [G loss: 0.742499]\n",
      "[Epoch 913/2000] [Batch 9/10] [D loss: 0.664717] [G loss: 0.742812]\n",
      "[Epoch 914/2000] [Batch 9/10] [D loss: 0.664461] [G loss: 0.742625]\n",
      "[Epoch 915/2000] [Batch 9/10] [D loss: 0.662103] [G loss: 0.747703]\n",
      "[Epoch 916/2000] [Batch 9/10] [D loss: 0.664446] [G loss: 0.741564]\n",
      "[Epoch 917/2000] [Batch 9/10] [D loss: 0.661758] [G loss: 0.747183]\n",
      "[Epoch 918/2000] [Batch 9/10] [D loss: 0.663070] [G loss: 0.743527]\n",
      "[Epoch 919/2000] [Batch 9/10] [D loss: 0.662530] [G loss: 0.744488]\n",
      "[Epoch 920/2000] [Batch 9/10] [D loss: 0.661855] [G loss: 0.745543]\n",
      "[Epoch 921/2000] [Batch 9/10] [D loss: 0.661796] [G loss: 0.745086]\n",
      "[Epoch 922/2000] [Batch 9/10] [D loss: 0.662765] [G loss: 0.742354]\n",
      "[Epoch 923/2000] [Batch 9/10] [D loss: 0.662542] [G loss: 0.742316]\n",
      "[Epoch 924/2000] [Batch 9/10] [D loss: 0.661954] [G loss: 0.743433]\n",
      "[Epoch 925/2000] [Batch 9/10] [D loss: 0.661544] [G loss: 0.743825]\n",
      "[Epoch 926/2000] [Batch 9/10] [D loss: 0.660223] [G loss: 0.746674]\n",
      "[Epoch 927/2000] [Batch 9/10] [D loss: 0.659917] [G loss: 0.746937]\n",
      "[Epoch 928/2000] [Batch 9/10] [D loss: 0.661273] [G loss: 0.743241]\n",
      "[Epoch 929/2000] [Batch 9/10] [D loss: 0.658807] [G loss: 0.748647]\n",
      "[Epoch 930/2000] [Batch 9/10] [D loss: 0.659580] [G loss: 0.746176]\n",
      "[Epoch 931/2000] [Batch 9/10] [D loss: 0.659756] [G loss: 0.745119]\n",
      "[Epoch 932/2000] [Batch 9/10] [D loss: 0.658995] [G loss: 0.746461]\n",
      "[Epoch 933/2000] [Batch 9/10] [D loss: 0.661198] [G loss: 0.740480]\n",
      "[Epoch 934/2000] [Batch 9/10] [D loss: 0.657898] [G loss: 0.747700]\n",
      "[Epoch 935/2000] [Batch 9/10] [D loss: 0.658558] [G loss: 0.745596]\n",
      "[Epoch 936/2000] [Batch 9/10] [D loss: 0.658214] [G loss: 0.745488]\n",
      "[Epoch 937/2000] [Batch 9/10] [D loss: 0.657735] [G loss: 0.746224]\n",
      "[Epoch 938/2000] [Batch 9/10] [D loss: 0.660153] [G loss: 0.739981]\n",
      "[Epoch 939/2000] [Batch 9/10] [D loss: 0.659033] [G loss: 0.742287]\n",
      "[Epoch 940/2000] [Batch 9/10] [D loss: 0.658903] [G loss: 0.742218]\n",
      "[Epoch 941/2000] [Batch 9/10] [D loss: 0.658572] [G loss: 0.742568]\n",
      "[Epoch 942/2000] [Batch 9/10] [D loss: 0.658897] [G loss: 0.741628]\n",
      "[Epoch 943/2000] [Batch 9/10] [D loss: 0.659505] [G loss: 0.739937]\n",
      "[Epoch 944/2000] [Batch 9/10] [D loss: 0.658095] [G loss: 0.743243]\n",
      "[Epoch 945/2000] [Batch 9/10] [D loss: 0.656932] [G loss: 0.745751]\n",
      "[Epoch 946/2000] [Batch 9/10] [D loss: 0.657479] [G loss: 0.744200]\n",
      "[Epoch 947/2000] [Batch 9/10] [D loss: 0.659796] [G loss: 0.738669]\n",
      "[Epoch 948/2000] [Batch 9/10] [D loss: 0.657435] [G loss: 0.744283]\n",
      "[Epoch 949/2000] [Batch 9/10] [D loss: 0.658672] [G loss: 0.741284]\n",
      "[Epoch 950/2000] [Batch 9/10] [D loss: 0.657051] [G loss: 0.744980]\n",
      "[Epoch 951/2000] [Batch 9/10] [D loss: 0.657706] [G loss: 0.743194]\n",
      "[Epoch 952/2000] [Batch 9/10] [D loss: 0.656178] [G loss: 0.746840]\n",
      "[Epoch 953/2000] [Batch 9/10] [D loss: 0.656761] [G loss: 0.745616]\n",
      "[Epoch 954/2000] [Batch 9/10] [D loss: 0.655645] [G loss: 0.748075]\n",
      "[Epoch 955/2000] [Batch 9/10] [D loss: 0.655688] [G loss: 0.747940]\n",
      "[Epoch 956/2000] [Batch 9/10] [D loss: 0.656257] [G loss: 0.746625]\n",
      "[Epoch 957/2000] [Batch 9/10] [D loss: 0.656247] [G loss: 0.746668]\n",
      "[Epoch 958/2000] [Batch 9/10] [D loss: 0.656213] [G loss: 0.746660]\n",
      "[Epoch 959/2000] [Batch 9/10] [D loss: 0.655558] [G loss: 0.748230]\n",
      "[Epoch 960/2000] [Batch 9/10] [D loss: 0.655173] [G loss: 0.749144]\n",
      "[Epoch 961/2000] [Batch 9/10] [D loss: 0.655904] [G loss: 0.747357]\n",
      "[Epoch 962/2000] [Batch 9/10] [D loss: 0.654282] [G loss: 0.751239]\n",
      "[Epoch 963/2000] [Batch 9/10] [D loss: 0.654659] [G loss: 0.750364]\n",
      "[Epoch 964/2000] [Batch 9/10] [D loss: 0.654915] [G loss: 0.749616]\n",
      "[Epoch 965/2000] [Batch 9/10] [D loss: 0.653954] [G loss: 0.751760]\n",
      "[Epoch 966/2000] [Batch 9/10] [D loss: 0.653804] [G loss: 0.752064]\n",
      "[Epoch 967/2000] [Batch 9/10] [D loss: 0.654152] [G loss: 0.751405]\n",
      "[Epoch 968/2000] [Batch 9/10] [D loss: 0.654441] [G loss: 0.750638]\n",
      "[Epoch 969/2000] [Batch 9/10] [D loss: 0.652358] [G loss: 0.755149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 970/2000] [Batch 9/10] [D loss: 0.653305] [G loss: 0.753074]\n",
      "[Epoch 971/2000] [Batch 9/10] [D loss: 0.652375] [G loss: 0.755184]\n",
      "[Epoch 972/2000] [Batch 9/10] [D loss: 0.652436] [G loss: 0.754933]\n",
      "[Epoch 973/2000] [Batch 9/10] [D loss: 0.651851] [G loss: 0.756114]\n",
      "[Epoch 974/2000] [Batch 9/10] [D loss: 0.652002] [G loss: 0.755804]\n",
      "[Epoch 975/2000] [Batch 9/10] [D loss: 0.651669] [G loss: 0.756431]\n",
      "[Epoch 976/2000] [Batch 9/10] [D loss: 0.652229] [G loss: 0.755105]\n",
      "[Epoch 977/2000] [Batch 9/10] [D loss: 0.652164] [G loss: 0.755133]\n",
      "[Epoch 978/2000] [Batch 9/10] [D loss: 0.651502] [G loss: 0.756537]\n",
      "[Epoch 979/2000] [Batch 9/10] [D loss: 0.651512] [G loss: 0.756388]\n",
      "[Epoch 980/2000] [Batch 9/10] [D loss: 0.651243] [G loss: 0.756933]\n",
      "[Epoch 981/2000] [Batch 9/10] [D loss: 0.652099] [G loss: 0.754949]\n",
      "[Epoch 982/2000] [Batch 9/10] [D loss: 0.652367] [G loss: 0.754308]\n",
      "[Epoch 983/2000] [Batch 9/10] [D loss: 0.652325] [G loss: 0.754466]\n",
      "[Epoch 984/2000] [Batch 9/10] [D loss: 0.653303] [G loss: 0.752506]\n",
      "[Epoch 985/2000] [Batch 9/10] [D loss: 0.654401] [G loss: 0.750339]\n",
      "[Epoch 986/2000] [Batch 9/10] [D loss: 0.655420] [G loss: 0.748420]\n",
      "[Epoch 987/2000] [Batch 9/10] [D loss: 0.656818] [G loss: 0.745991]\n",
      "[Epoch 988/2000] [Batch 9/10] [D loss: 0.659096] [G loss: 0.741795]\n",
      "[Epoch 989/2000] [Batch 9/10] [D loss: 0.661470] [G loss: 0.737552]\n",
      "[Epoch 990/2000] [Batch 9/10] [D loss: 0.666595] [G loss: 0.728024]\n",
      "[Epoch 991/2000] [Batch 9/10] [D loss: 0.672781] [G loss: 0.716790]\n",
      "[Epoch 992/2000] [Batch 9/10] [D loss: 0.677275] [G loss: 0.709836]\n",
      "[Epoch 993/2000] [Batch 9/10] [D loss: 0.687657] [G loss: 0.692643]\n",
      "[Epoch 994/2000] [Batch 9/10] [D loss: 0.697454] [G loss: 0.678465]\n",
      "[Epoch 995/2000] [Batch 9/10] [D loss: 0.710746] [G loss: 0.659894]\n",
      "[Epoch 996/2000] [Batch 9/10] [D loss: 0.721349] [G loss: 0.647802]\n",
      "[Epoch 997/2000] [Batch 9/10] [D loss: 0.732167] [G loss: 0.637046]\n",
      "[Epoch 998/2000] [Batch 9/10] [D loss: 0.738658] [G loss: 0.634039]\n",
      "[Epoch 999/2000] [Batch 9/10] [D loss: 0.743645] [G loss: 0.633118]\n",
      "[Epoch 1000/2000] [Batch 9/10] [D loss: 0.748180] [G loss: 0.632367]\n",
      "[Epoch 1001/2000] [Batch 9/10] [D loss: 0.751249] [G loss: 0.633554]\n",
      "[Epoch 1002/2000] [Batch 9/10] [D loss: 0.748855] [G loss: 0.643687]\n",
      "[Epoch 1003/2000] [Batch 9/10] [D loss: 0.749501] [G loss: 0.647802]\n",
      "[Epoch 1004/2000] [Batch 9/10] [D loss: 0.749604] [G loss: 0.651890]\n",
      "[Epoch 1005/2000] [Batch 9/10] [D loss: 0.747628] [G loss: 0.659078]\n",
      "[Epoch 1006/2000] [Batch 9/10] [D loss: 0.747364] [G loss: 0.662812]\n",
      "[Epoch 1007/2000] [Batch 9/10] [D loss: 0.743999] [G loss: 0.671661]\n",
      "[Epoch 1008/2000] [Batch 9/10] [D loss: 0.742903] [G loss: 0.675821]\n",
      "[Epoch 1009/2000] [Batch 9/10] [D loss: 0.739316] [G loss: 0.684304]\n",
      "[Epoch 1010/2000] [Batch 9/10] [D loss: 0.739293] [G loss: 0.685451]\n",
      "[Epoch 1011/2000] [Batch 9/10] [D loss: 0.735246] [G loss: 0.694175]\n",
      "[Epoch 1012/2000] [Batch 9/10] [D loss: 0.734569] [G loss: 0.695793]\n",
      "[Epoch 1013/2000] [Batch 9/10] [D loss: 0.732878] [G loss: 0.699277]\n",
      "[Epoch 1014/2000] [Batch 9/10] [D loss: 0.730166] [G loss: 0.704738]\n",
      "[Epoch 1015/2000] [Batch 9/10] [D loss: 0.727783] [G loss: 0.709246]\n",
      "[Epoch 1016/2000] [Batch 9/10] [D loss: 0.724410] [G loss: 0.715892]\n",
      "[Epoch 1017/2000] [Batch 9/10] [D loss: 0.723115] [G loss: 0.717753]\n",
      "[Epoch 1018/2000] [Batch 9/10] [D loss: 0.720961] [G loss: 0.721594]\n",
      "[Epoch 1019/2000] [Batch 9/10] [D loss: 0.718645] [G loss: 0.725641]\n",
      "[Epoch 1020/2000] [Batch 9/10] [D loss: 0.717262] [G loss: 0.727631]\n",
      "[Epoch 1021/2000] [Batch 9/10] [D loss: 0.714668] [G loss: 0.732167]\n",
      "[Epoch 1022/2000] [Batch 9/10] [D loss: 0.711812] [G loss: 0.737238]\n",
      "[Epoch 1023/2000] [Batch 9/10] [D loss: 0.710082] [G loss: 0.739796]\n",
      "[Epoch 1024/2000] [Batch 9/10] [D loss: 0.707533] [G loss: 0.744200]\n",
      "[Epoch 1025/2000] [Batch 9/10] [D loss: 0.705517] [G loss: 0.747461]\n",
      "[Epoch 1026/2000] [Batch 9/10] [D loss: 0.703607] [G loss: 0.750459]\n",
      "[Epoch 1027/2000] [Batch 9/10] [D loss: 0.701849] [G loss: 0.753127]\n",
      "[Epoch 1028/2000] [Batch 9/10] [D loss: 0.699267] [G loss: 0.757647]\n",
      "[Epoch 1029/2000] [Batch 9/10] [D loss: 0.697689] [G loss: 0.759944]\n",
      "[Epoch 1030/2000] [Batch 9/10] [D loss: 0.695974] [G loss: 0.762571]\n",
      "[Epoch 1031/2000] [Batch 9/10] [D loss: 0.694026] [G loss: 0.765837]\n",
      "[Epoch 1032/2000] [Batch 9/10] [D loss: 0.691968] [G loss: 0.769228]\n",
      "[Epoch 1033/2000] [Batch 9/10] [D loss: 0.690078] [G loss: 0.772301]\n",
      "[Epoch 1034/2000] [Batch 9/10] [D loss: 0.688451] [G loss: 0.774845]\n",
      "[Epoch 1035/2000] [Batch 9/10] [D loss: 0.687172] [G loss: 0.776640]\n",
      "[Epoch 1036/2000] [Batch 9/10] [D loss: 0.685396] [G loss: 0.779642]\n",
      "[Epoch 1037/2000] [Batch 9/10] [D loss: 0.684080] [G loss: 0.781537]\n",
      "[Epoch 1038/2000] [Batch 9/10] [D loss: 0.682664] [G loss: 0.783748]\n",
      "[Epoch 1039/2000] [Batch 9/10] [D loss: 0.681763] [G loss: 0.784755]\n",
      "[Epoch 1040/2000] [Batch 9/10] [D loss: 0.680560] [G loss: 0.786591]\n",
      "[Epoch 1041/2000] [Batch 9/10] [D loss: 0.680025] [G loss: 0.786913]\n",
      "[Epoch 1042/2000] [Batch 9/10] [D loss: 0.680252] [G loss: 0.785383]\n",
      "[Epoch 1043/2000] [Batch 9/10] [D loss: 0.680432] [G loss: 0.784284]\n",
      "[Epoch 1044/2000] [Batch 9/10] [D loss: 0.680747] [G loss: 0.783103]\n",
      "[Epoch 1045/2000] [Batch 9/10] [D loss: 0.679518] [G loss: 0.785704]\n",
      "[Epoch 1046/2000] [Batch 9/10] [D loss: 0.677990] [G loss: 0.789105]\n",
      "[Epoch 1047/2000] [Batch 9/10] [D loss: 0.675065] [G loss: 0.795863]\n",
      "[Epoch 1048/2000] [Batch 9/10] [D loss: 0.671865] [G loss: 0.803174]\n",
      "[Epoch 1049/2000] [Batch 9/10] [D loss: 0.668405] [G loss: 0.811027]\n",
      "[Epoch 1050/2000] [Batch 9/10] [D loss: 0.665209] [G loss: 0.818065]\n",
      "[Epoch 1051/2000] [Batch 9/10] [D loss: 0.661800] [G loss: 0.825524]\n",
      "[Epoch 1052/2000] [Batch 9/10] [D loss: 0.658561] [G loss: 0.832435]\n",
      "[Epoch 1053/2000] [Batch 9/10] [D loss: 0.655394] [G loss: 0.839056]\n",
      "[Epoch 1054/2000] [Batch 9/10] [D loss: 0.651977] [G loss: 0.846247]\n",
      "[Epoch 1055/2000] [Batch 9/10] [D loss: 0.649096] [G loss: 0.851921]\n",
      "[Epoch 1056/2000] [Batch 9/10] [D loss: 0.646590] [G loss: 0.856451]\n",
      "[Epoch 1057/2000] [Batch 9/10] [D loss: 0.643448] [G loss: 0.862679]\n",
      "[Epoch 1058/2000] [Batch 9/10] [D loss: 0.640733] [G loss: 0.867750]\n",
      "[Epoch 1059/2000] [Batch 9/10] [D loss: 0.639163] [G loss: 0.869533]\n",
      "[Epoch 1060/2000] [Batch 9/10] [D loss: 0.636896] [G loss: 0.873213]\n",
      "[Epoch 1061/2000] [Batch 9/10] [D loss: 0.635219] [G loss: 0.875179]\n",
      "[Epoch 1062/2000] [Batch 9/10] [D loss: 0.634599] [G loss: 0.874211]\n",
      "[Epoch 1063/2000] [Batch 9/10] [D loss: 0.634163] [G loss: 0.872644]\n",
      "[Epoch 1064/2000] [Batch 9/10] [D loss: 0.633598] [G loss: 0.871662]\n",
      "[Epoch 1065/2000] [Batch 9/10] [D loss: 0.633047] [G loss: 0.870580]\n",
      "[Epoch 1066/2000] [Batch 9/10] [D loss: 0.633475] [G loss: 0.866898]\n",
      "[Epoch 1067/2000] [Batch 9/10] [D loss: 0.633600] [G loss: 0.864218]\n",
      "[Epoch 1068/2000] [Batch 9/10] [D loss: 0.633363] [G loss: 0.862693]\n",
      "[Epoch 1069/2000] [Batch 9/10] [D loss: 0.634587] [G loss: 0.857799]\n",
      "[Epoch 1070/2000] [Batch 9/10] [D loss: 0.640068] [G loss: 0.845238]\n",
      "[Epoch 1071/2000] [Batch 9/10] [D loss: 0.651509] [G loss: 0.822849]\n",
      "[Epoch 1072/2000] [Batch 9/10] [D loss: 0.662149] [G loss: 0.803669]\n",
      "[Epoch 1073/2000] [Batch 9/10] [D loss: 0.668975] [G loss: 0.791258]\n",
      "[Epoch 1074/2000] [Batch 9/10] [D loss: 0.675789] [G loss: 0.779126]\n",
      "[Epoch 1075/2000] [Batch 9/10] [D loss: 0.680994] [G loss: 0.771549]\n",
      "[Epoch 1076/2000] [Batch 9/10] [D loss: 0.685349] [G loss: 0.762710]\n",
      "[Epoch 1077/2000] [Batch 9/10] [D loss: 0.686556] [G loss: 0.761382]\n",
      "[Epoch 1078/2000] [Batch 9/10] [D loss: 0.689222] [G loss: 0.755165]\n",
      "[Epoch 1079/2000] [Batch 9/10] [D loss: 0.690067] [G loss: 0.753299]\n",
      "[Epoch 1080/2000] [Batch 9/10] [D loss: 0.690603] [G loss: 0.751590]\n",
      "[Epoch 1081/2000] [Batch 9/10] [D loss: 0.691903] [G loss: 0.748587]\n",
      "[Epoch 1082/2000] [Batch 9/10] [D loss: 0.691435] [G loss: 0.748230]\n",
      "[Epoch 1083/2000] [Batch 9/10] [D loss: 0.690094] [G loss: 0.749800]\n",
      "[Epoch 1084/2000] [Batch 9/10] [D loss: 0.691890] [G loss: 0.743872]\n",
      "[Epoch 1085/2000] [Batch 9/10] [D loss: 0.691634] [G loss: 0.742610]\n",
      "[Epoch 1086/2000] [Batch 9/10] [D loss: 0.690845] [G loss: 0.742658]\n",
      "[Epoch 1087/2000] [Batch 9/10] [D loss: 0.689991] [G loss: 0.742300]\n",
      "[Epoch 1088/2000] [Batch 9/10] [D loss: 0.690823] [G loss: 0.738739]\n",
      "[Epoch 1089/2000] [Batch 9/10] [D loss: 0.689918] [G loss: 0.739183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1090/2000] [Batch 9/10] [D loss: 0.688337] [G loss: 0.740105]\n",
      "[Epoch 1091/2000] [Batch 9/10] [D loss: 0.688994] [G loss: 0.736818]\n",
      "[Epoch 1092/2000] [Batch 9/10] [D loss: 0.687424] [G loss: 0.737973]\n",
      "[Epoch 1093/2000] [Batch 9/10] [D loss: 0.685908] [G loss: 0.739111]\n",
      "[Epoch 1094/2000] [Batch 9/10] [D loss: 0.685779] [G loss: 0.737371]\n",
      "[Epoch 1095/2000] [Batch 9/10] [D loss: 0.686052] [G loss: 0.734837]\n",
      "[Epoch 1096/2000] [Batch 9/10] [D loss: 0.685852] [G loss: 0.733131]\n",
      "[Epoch 1097/2000] [Batch 9/10] [D loss: 0.685740] [G loss: 0.731358]\n",
      "[Epoch 1098/2000] [Batch 9/10] [D loss: 0.685484] [G loss: 0.729798]\n",
      "[Epoch 1099/2000] [Batch 9/10] [D loss: 0.687957] [G loss: 0.722427]\n",
      "[Epoch 1100/2000] [Batch 9/10] [D loss: 0.689500] [G loss: 0.717301]\n",
      "[Epoch 1101/2000] [Batch 9/10] [D loss: 0.695283] [G loss: 0.704503]\n",
      "[Epoch 1102/2000] [Batch 9/10] [D loss: 0.704355] [G loss: 0.687296]\n",
      "[Epoch 1103/2000] [Batch 9/10] [D loss: 0.714417] [G loss: 0.669970]\n",
      "[Epoch 1104/2000] [Batch 9/10] [D loss: 0.722278] [G loss: 0.657727]\n",
      "[Epoch 1105/2000] [Batch 9/10] [D loss: 0.727811] [G loss: 0.650255]\n",
      "[Epoch 1106/2000] [Batch 9/10] [D loss: 0.731436] [G loss: 0.645809]\n",
      "[Epoch 1107/2000] [Batch 9/10] [D loss: 0.735568] [G loss: 0.640882]\n",
      "[Epoch 1108/2000] [Batch 9/10] [D loss: 0.736539] [G loss: 0.641092]\n",
      "[Epoch 1109/2000] [Batch 9/10] [D loss: 0.738447] [G loss: 0.639870]\n",
      "[Epoch 1110/2000] [Batch 9/10] [D loss: 0.738556] [G loss: 0.641947]\n",
      "[Epoch 1111/2000] [Batch 9/10] [D loss: 0.739897] [G loss: 0.641422]\n",
      "[Epoch 1112/2000] [Batch 9/10] [D loss: 0.739647] [G loss: 0.643519]\n",
      "[Epoch 1113/2000] [Batch 9/10] [D loss: 0.740816] [G loss: 0.643219]\n",
      "[Epoch 1114/2000] [Batch 9/10] [D loss: 0.740478] [G loss: 0.644681]\n",
      "[Epoch 1115/2000] [Batch 9/10] [D loss: 0.740737] [G loss: 0.645459]\n",
      "[Epoch 1116/2000] [Batch 9/10] [D loss: 0.740830] [G loss: 0.646556]\n",
      "[Epoch 1117/2000] [Batch 9/10] [D loss: 0.739702] [G loss: 0.649486]\n",
      "[Epoch 1118/2000] [Batch 9/10] [D loss: 0.738330] [G loss: 0.653610]\n",
      "[Epoch 1119/2000] [Batch 9/10] [D loss: 0.737945] [G loss: 0.654968]\n",
      "[Epoch 1120/2000] [Batch 9/10] [D loss: 0.737528] [G loss: 0.656064]\n",
      "[Epoch 1121/2000] [Batch 9/10] [D loss: 0.736589] [G loss: 0.658030]\n",
      "[Epoch 1122/2000] [Batch 9/10] [D loss: 0.738108] [G loss: 0.655217]\n",
      "[Epoch 1123/2000] [Batch 9/10] [D loss: 0.733326] [G loss: 0.664936]\n",
      "[Epoch 1124/2000] [Batch 9/10] [D loss: 0.733027] [G loss: 0.665627]\n",
      "[Epoch 1125/2000] [Batch 9/10] [D loss: 0.731210] [G loss: 0.669149]\n",
      "[Epoch 1126/2000] [Batch 9/10] [D loss: 0.730216] [G loss: 0.671107]\n",
      "[Epoch 1127/2000] [Batch 9/10] [D loss: 0.728780] [G loss: 0.674024]\n",
      "[Epoch 1128/2000] [Batch 9/10] [D loss: 0.728750] [G loss: 0.673392]\n",
      "[Epoch 1129/2000] [Batch 9/10] [D loss: 0.726776] [G loss: 0.677217]\n",
      "[Epoch 1130/2000] [Batch 9/10] [D loss: 0.726517] [G loss: 0.677081]\n",
      "[Epoch 1131/2000] [Batch 9/10] [D loss: 0.723458] [G loss: 0.682888]\n",
      "[Epoch 1132/2000] [Batch 9/10] [D loss: 0.724353] [G loss: 0.680352]\n",
      "[Epoch 1133/2000] [Batch 9/10] [D loss: 0.722954] [G loss: 0.682417]\n",
      "[Epoch 1134/2000] [Batch 9/10] [D loss: 0.720453] [G loss: 0.686645]\n",
      "[Epoch 1135/2000] [Batch 9/10] [D loss: 0.719646] [G loss: 0.687554]\n",
      "[Epoch 1136/2000] [Batch 9/10] [D loss: 0.717372] [G loss: 0.691357]\n",
      "[Epoch 1137/2000] [Batch 9/10] [D loss: 0.716664] [G loss: 0.691675]\n",
      "[Epoch 1138/2000] [Batch 9/10] [D loss: 0.715148] [G loss: 0.693949]\n",
      "[Epoch 1139/2000] [Batch 9/10] [D loss: 0.714303] [G loss: 0.694446]\n",
      "[Epoch 1140/2000] [Batch 9/10] [D loss: 0.711633] [G loss: 0.698867]\n",
      "[Epoch 1141/2000] [Batch 9/10] [D loss: 0.711413] [G loss: 0.698197]\n",
      "[Epoch 1142/2000] [Batch 9/10] [D loss: 0.709585] [G loss: 0.700766]\n",
      "[Epoch 1143/2000] [Batch 9/10] [D loss: 0.707642] [G loss: 0.703573]\n",
      "[Epoch 1144/2000] [Batch 9/10] [D loss: 0.706088] [G loss: 0.705568]\n",
      "[Epoch 1145/2000] [Batch 9/10] [D loss: 0.705019] [G loss: 0.706358]\n",
      "[Epoch 1146/2000] [Batch 9/10] [D loss: 0.703584] [G loss: 0.707969]\n",
      "[Epoch 1147/2000] [Batch 9/10] [D loss: 0.701865] [G loss: 0.710177]\n",
      "[Epoch 1148/2000] [Batch 9/10] [D loss: 0.700397] [G loss: 0.711845]\n",
      "[Epoch 1149/2000] [Batch 9/10] [D loss: 0.699404] [G loss: 0.712339]\n",
      "[Epoch 1150/2000] [Batch 9/10] [D loss: 0.697706] [G loss: 0.714491]\n",
      "[Epoch 1151/2000] [Batch 9/10] [D loss: 0.696108] [G loss: 0.716328]\n",
      "[Epoch 1152/2000] [Batch 9/10] [D loss: 0.695156] [G loss: 0.716705]\n",
      "[Epoch 1153/2000] [Batch 9/10] [D loss: 0.692826] [G loss: 0.720236]\n",
      "[Epoch 1154/2000] [Batch 9/10] [D loss: 0.691727] [G loss: 0.720944]\n",
      "[Epoch 1155/2000] [Batch 9/10] [D loss: 0.691048] [G loss: 0.720732]\n",
      "[Epoch 1156/2000] [Batch 9/10] [D loss: 0.690431] [G loss: 0.720306]\n",
      "[Epoch 1157/2000] [Batch 9/10] [D loss: 0.689120] [G loss: 0.721411]\n",
      "[Epoch 1158/2000] [Batch 9/10] [D loss: 0.688523] [G loss: 0.720947]\n",
      "[Epoch 1159/2000] [Batch 9/10] [D loss: 0.688072] [G loss: 0.720139]\n",
      "[Epoch 1160/2000] [Batch 9/10] [D loss: 0.687396] [G loss: 0.719987]\n",
      "[Epoch 1161/2000] [Batch 9/10] [D loss: 0.686454] [G loss: 0.720404]\n",
      "[Epoch 1162/2000] [Batch 9/10] [D loss: 0.685580] [G loss: 0.720711]\n",
      "[Epoch 1163/2000] [Batch 9/10] [D loss: 0.684862] [G loss: 0.720687]\n",
      "[Epoch 1164/2000] [Batch 9/10] [D loss: 0.684170] [G loss: 0.720692]\n",
      "[Epoch 1165/2000] [Batch 9/10] [D loss: 0.683421] [G loss: 0.720860]\n",
      "[Epoch 1166/2000] [Batch 9/10] [D loss: 0.682682] [G loss: 0.720961]\n",
      "[Epoch 1167/2000] [Batch 9/10] [D loss: 0.681636] [G loss: 0.721770]\n",
      "[Epoch 1168/2000] [Batch 9/10] [D loss: 0.680993] [G loss: 0.721797]\n",
      "[Epoch 1169/2000] [Batch 9/10] [D loss: 0.680459] [G loss: 0.721549]\n",
      "[Epoch 1170/2000] [Batch 9/10] [D loss: 0.679534] [G loss: 0.722210]\n",
      "[Epoch 1171/2000] [Batch 9/10] [D loss: 0.678967] [G loss: 0.722091]\n",
      "[Epoch 1172/2000] [Batch 9/10] [D loss: 0.678223] [G loss: 0.722405]\n",
      "[Epoch 1173/2000] [Batch 9/10] [D loss: 0.677257] [G loss: 0.723197]\n",
      "[Epoch 1174/2000] [Batch 9/10] [D loss: 0.676931] [G loss: 0.722592]\n",
      "[Epoch 1175/2000] [Batch 9/10] [D loss: 0.675544] [G loss: 0.724299]\n",
      "[Epoch 1176/2000] [Batch 9/10] [D loss: 0.674571] [G loss: 0.725136]\n",
      "[Epoch 1177/2000] [Batch 9/10] [D loss: 0.674161] [G loss: 0.724764]\n",
      "[Epoch 1178/2000] [Batch 9/10] [D loss: 0.673032] [G loss: 0.725947]\n",
      "[Epoch 1179/2000] [Batch 9/10] [D loss: 0.672184] [G loss: 0.726557]\n",
      "[Epoch 1180/2000] [Batch 9/10] [D loss: 0.671439] [G loss: 0.726938]\n",
      "[Epoch 1181/2000] [Batch 9/10] [D loss: 0.670259] [G loss: 0.728240]\n",
      "[Epoch 1182/2000] [Batch 9/10] [D loss: 0.669649] [G loss: 0.728359]\n",
      "[Epoch 1183/2000] [Batch 9/10] [D loss: 0.668823] [G loss: 0.728935]\n",
      "[Epoch 1184/2000] [Batch 9/10] [D loss: 0.667997] [G loss: 0.730134]\n",
      "[Epoch 1185/2000] [Batch 9/10] [D loss: 0.667699] [G loss: 0.730333]\n",
      "[Epoch 1186/2000] [Batch 9/10] [D loss: 0.667416] [G loss: 0.730537]\n",
      "[Epoch 1187/2000] [Batch 9/10] [D loss: 0.666562] [G loss: 0.731989]\n",
      "[Epoch 1188/2000] [Batch 9/10] [D loss: 0.666091] [G loss: 0.732598]\n",
      "[Epoch 1189/2000] [Batch 9/10] [D loss: 0.665351] [G loss: 0.733805]\n",
      "[Epoch 1190/2000] [Batch 9/10] [D loss: 0.664890] [G loss: 0.734451]\n",
      "[Epoch 1191/2000] [Batch 9/10] [D loss: 0.664892] [G loss: 0.734095]\n",
      "[Epoch 1192/2000] [Batch 9/10] [D loss: 0.664196] [G loss: 0.735256]\n",
      "[Epoch 1193/2000] [Batch 9/10] [D loss: 0.663682] [G loss: 0.736023]\n",
      "[Epoch 1194/2000] [Batch 9/10] [D loss: 0.663468] [G loss: 0.736173]\n",
      "[Epoch 1195/2000] [Batch 9/10] [D loss: 0.662420] [G loss: 0.738137]\n",
      "[Epoch 1196/2000] [Batch 9/10] [D loss: 0.662470] [G loss: 0.737732]\n",
      "[Epoch 1197/2000] [Batch 9/10] [D loss: 0.661634] [G loss: 0.739242]\n",
      "[Epoch 1198/2000] [Batch 9/10] [D loss: 0.661525] [G loss: 0.739205]\n",
      "[Epoch 1199/2000] [Batch 9/10] [D loss: 0.660733] [G loss: 0.740651]\n",
      "[Epoch 1200/2000] [Batch 9/10] [D loss: 0.660468] [G loss: 0.741007]\n",
      "[Epoch 1201/2000] [Batch 9/10] [D loss: 0.659859] [G loss: 0.742076]\n",
      "[Epoch 1202/2000] [Batch 9/10] [D loss: 0.659751] [G loss: 0.742142]\n",
      "[Epoch 1203/2000] [Batch 9/10] [D loss: 0.659768] [G loss: 0.741375]\n",
      "[Epoch 1204/2000] [Batch 9/10] [D loss: 0.659439] [G loss: 0.741204]\n",
      "[Epoch 1205/2000] [Batch 9/10] [D loss: 0.659944] [G loss: 0.739413]\n",
      "[Epoch 1206/2000] [Batch 9/10] [D loss: 0.658988] [G loss: 0.740810]\n",
      "[Epoch 1207/2000] [Batch 9/10] [D loss: 0.659787] [G loss: 0.738625]\n",
      "[Epoch 1208/2000] [Batch 9/10] [D loss: 0.660443] [G loss: 0.736911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1209/2000] [Batch 9/10] [D loss: 0.659969] [G loss: 0.737673]\n",
      "[Epoch 1210/2000] [Batch 9/10] [D loss: 0.661097] [G loss: 0.735299]\n",
      "[Epoch 1211/2000] [Batch 9/10] [D loss: 0.660944] [G loss: 0.735616]\n",
      "[Epoch 1212/2000] [Batch 9/10] [D loss: 0.661741] [G loss: 0.734324]\n",
      "[Epoch 1213/2000] [Batch 9/10] [D loss: 0.661856] [G loss: 0.734519]\n",
      "[Epoch 1214/2000] [Batch 9/10] [D loss: 0.664286] [G loss: 0.730368]\n",
      "[Epoch 1215/2000] [Batch 9/10] [D loss: 0.667677] [G loss: 0.724370]\n",
      "[Epoch 1216/2000] [Batch 9/10] [D loss: 0.671935] [G loss: 0.716288]\n",
      "[Epoch 1217/2000] [Batch 9/10] [D loss: 0.680902] [G loss: 0.700052]\n",
      "[Epoch 1218/2000] [Batch 9/10] [D loss: 0.685908] [G loss: 0.693547]\n",
      "[Epoch 1219/2000] [Batch 9/10] [D loss: 0.686745] [G loss: 0.695803]\n",
      "[Epoch 1220/2000] [Batch 9/10] [D loss: 0.685665] [G loss: 0.701798]\n",
      "[Epoch 1221/2000] [Batch 9/10] [D loss: 0.683788] [G loss: 0.709092]\n",
      "[Epoch 1222/2000] [Batch 9/10] [D loss: 0.681642] [G loss: 0.716585]\n",
      "[Epoch 1223/2000] [Batch 9/10] [D loss: 0.679708] [G loss: 0.723359]\n",
      "[Epoch 1224/2000] [Batch 9/10] [D loss: 0.677564] [G loss: 0.730242]\n",
      "[Epoch 1225/2000] [Batch 9/10] [D loss: 0.675287] [G loss: 0.737094]\n",
      "[Epoch 1226/2000] [Batch 9/10] [D loss: 0.673448] [G loss: 0.742733]\n",
      "[Epoch 1227/2000] [Batch 9/10] [D loss: 0.671249] [G loss: 0.748905]\n",
      "[Epoch 1228/2000] [Batch 9/10] [D loss: 0.669515] [G loss: 0.753828]\n",
      "[Epoch 1229/2000] [Batch 9/10] [D loss: 0.667473] [G loss: 0.759154]\n",
      "[Epoch 1230/2000] [Batch 9/10] [D loss: 0.665323] [G loss: 0.764507]\n",
      "[Epoch 1231/2000] [Batch 9/10] [D loss: 0.663556] [G loss: 0.768846]\n",
      "[Epoch 1232/2000] [Batch 9/10] [D loss: 0.661729] [G loss: 0.773203]\n",
      "[Epoch 1233/2000] [Batch 9/10] [D loss: 0.659631] [G loss: 0.777984]\n",
      "[Epoch 1234/2000] [Batch 9/10] [D loss: 0.658108] [G loss: 0.781318]\n",
      "[Epoch 1235/2000] [Batch 9/10] [D loss: 0.655997] [G loss: 0.785889]\n",
      "[Epoch 1236/2000] [Batch 9/10] [D loss: 0.654652] [G loss: 0.788587]\n",
      "[Epoch 1237/2000] [Batch 9/10] [D loss: 0.652951] [G loss: 0.792024]\n",
      "[Epoch 1238/2000] [Batch 9/10] [D loss: 0.651721] [G loss: 0.794284]\n",
      "[Epoch 1239/2000] [Batch 9/10] [D loss: 0.649498] [G loss: 0.798881]\n",
      "[Epoch 1240/2000] [Batch 9/10] [D loss: 0.648461] [G loss: 0.800558]\n",
      "[Epoch 1241/2000] [Batch 9/10] [D loss: 0.647058] [G loss: 0.803059]\n",
      "[Epoch 1242/2000] [Batch 9/10] [D loss: 0.645855] [G loss: 0.805026]\n",
      "[Epoch 1243/2000] [Batch 9/10] [D loss: 0.644337] [G loss: 0.807721]\n",
      "[Epoch 1244/2000] [Batch 9/10] [D loss: 0.643483] [G loss: 0.808787]\n",
      "[Epoch 1245/2000] [Batch 9/10] [D loss: 0.642154] [G loss: 0.810962]\n",
      "[Epoch 1246/2000] [Batch 9/10] [D loss: 0.641646] [G loss: 0.811118]\n",
      "[Epoch 1247/2000] [Batch 9/10] [D loss: 0.639217] [G loss: 0.815992]\n",
      "[Epoch 1248/2000] [Batch 9/10] [D loss: 0.637906] [G loss: 0.818060]\n",
      "[Epoch 1249/2000] [Batch 9/10] [D loss: 0.638338] [G loss: 0.815893]\n",
      "[Epoch 1250/2000] [Batch 9/10] [D loss: 0.636902] [G loss: 0.818240]\n",
      "[Epoch 1251/2000] [Batch 9/10] [D loss: 0.636085] [G loss: 0.819082]\n",
      "[Epoch 1252/2000] [Batch 9/10] [D loss: 0.634452] [G loss: 0.822090]\n",
      "[Epoch 1253/2000] [Batch 9/10] [D loss: 0.634261] [G loss: 0.821317]\n",
      "[Epoch 1254/2000] [Batch 9/10] [D loss: 0.633949] [G loss: 0.820951]\n",
      "[Epoch 1255/2000] [Batch 9/10] [D loss: 0.633651] [G loss: 0.820420]\n",
      "[Epoch 1256/2000] [Batch 9/10] [D loss: 0.633862] [G loss: 0.818454]\n",
      "[Epoch 1257/2000] [Batch 9/10] [D loss: 0.635487] [G loss: 0.812790]\n",
      "[Epoch 1258/2000] [Batch 9/10] [D loss: 0.641442] [G loss: 0.796028]\n",
      "[Epoch 1259/2000] [Batch 9/10] [D loss: 0.646819] [G loss: 0.782196]\n",
      "[Epoch 1260/2000] [Batch 9/10] [D loss: 0.650643] [G loss: 0.772962]\n",
      "[Epoch 1261/2000] [Batch 9/10] [D loss: 0.653565] [G loss: 0.765947]\n",
      "[Epoch 1262/2000] [Batch 9/10] [D loss: 0.654777] [G loss: 0.763096]\n",
      "[Epoch 1263/2000] [Batch 9/10] [D loss: 0.655501] [G loss: 0.761378]\n",
      "[Epoch 1264/2000] [Batch 9/10] [D loss: 0.655611] [G loss: 0.761155]\n",
      "[Epoch 1265/2000] [Batch 9/10] [D loss: 0.656457] [G loss: 0.759302]\n",
      "[Epoch 1266/2000] [Batch 9/10] [D loss: 0.657212] [G loss: 0.757695]\n",
      "[Epoch 1267/2000] [Batch 9/10] [D loss: 0.657503] [G loss: 0.757185]\n",
      "[Epoch 1268/2000] [Batch 9/10] [D loss: 0.657387] [G loss: 0.757782]\n",
      "[Epoch 1269/2000] [Batch 9/10] [D loss: 0.657530] [G loss: 0.757764]\n",
      "[Epoch 1270/2000] [Batch 9/10] [D loss: 0.657528] [G loss: 0.758069]\n",
      "[Epoch 1271/2000] [Batch 9/10] [D loss: 0.658165] [G loss: 0.756956]\n",
      "[Epoch 1272/2000] [Batch 9/10] [D loss: 0.658248] [G loss: 0.756881]\n",
      "[Epoch 1273/2000] [Batch 9/10] [D loss: 0.658572] [G loss: 0.756126]\n",
      "[Epoch 1274/2000] [Batch 9/10] [D loss: 0.658566] [G loss: 0.756277]\n",
      "[Epoch 1275/2000] [Batch 9/10] [D loss: 0.658951] [G loss: 0.755551]\n",
      "[Epoch 1276/2000] [Batch 9/10] [D loss: 0.658994] [G loss: 0.755656]\n",
      "[Epoch 1277/2000] [Batch 9/10] [D loss: 0.658372] [G loss: 0.757234]\n",
      "[Epoch 1278/2000] [Batch 9/10] [D loss: 0.658278] [G loss: 0.757736]\n",
      "[Epoch 1279/2000] [Batch 9/10] [D loss: 0.658167] [G loss: 0.758161]\n",
      "[Epoch 1280/2000] [Batch 9/10] [D loss: 0.659047] [G loss: 0.756480]\n",
      "[Epoch 1281/2000] [Batch 9/10] [D loss: 0.658788] [G loss: 0.757510]\n",
      "[Epoch 1282/2000] [Batch 9/10] [D loss: 0.658365] [G loss: 0.758625]\n",
      "[Epoch 1283/2000] [Batch 9/10] [D loss: 0.658058] [G loss: 0.759643]\n",
      "[Epoch 1284/2000] [Batch 9/10] [D loss: 0.658530] [G loss: 0.758787]\n",
      "[Epoch 1285/2000] [Batch 9/10] [D loss: 0.658910] [G loss: 0.758243]\n",
      "[Epoch 1286/2000] [Batch 9/10] [D loss: 0.658019] [G loss: 0.760421]\n",
      "[Epoch 1287/2000] [Batch 9/10] [D loss: 0.658993] [G loss: 0.758455]\n",
      "[Epoch 1288/2000] [Batch 9/10] [D loss: 0.658111] [G loss: 0.760629]\n",
      "[Epoch 1289/2000] [Batch 9/10] [D loss: 0.657777] [G loss: 0.761722]\n",
      "[Epoch 1290/2000] [Batch 9/10] [D loss: 0.657730] [G loss: 0.762197]\n",
      "[Epoch 1291/2000] [Batch 9/10] [D loss: 0.657381] [G loss: 0.763192]\n",
      "[Epoch 1292/2000] [Batch 9/10] [D loss: 0.657811] [G loss: 0.762422]\n",
      "[Epoch 1293/2000] [Batch 9/10] [D loss: 0.658367] [G loss: 0.761349]\n",
      "[Epoch 1294/2000] [Batch 9/10] [D loss: 0.658354] [G loss: 0.761299]\n",
      "[Epoch 1295/2000] [Batch 9/10] [D loss: 0.659160] [G loss: 0.759503]\n",
      "[Epoch 1296/2000] [Batch 9/10] [D loss: 0.658521] [G loss: 0.760589]\n",
      "[Epoch 1297/2000] [Batch 9/10] [D loss: 0.659427] [G loss: 0.758166]\n",
      "[Epoch 1298/2000] [Batch 9/10] [D loss: 0.659626] [G loss: 0.757073]\n",
      "[Epoch 1299/2000] [Batch 9/10] [D loss: 0.660252] [G loss: 0.754910]\n",
      "[Epoch 1300/2000] [Batch 9/10] [D loss: 0.662043] [G loss: 0.750196]\n",
      "[Epoch 1301/2000] [Batch 9/10] [D loss: 0.664101] [G loss: 0.744724]\n",
      "[Epoch 1302/2000] [Batch 9/10] [D loss: 0.667618] [G loss: 0.736001]\n",
      "[Epoch 1303/2000] [Batch 9/10] [D loss: 0.672524] [G loss: 0.724880]\n",
      "[Epoch 1304/2000] [Batch 9/10] [D loss: 0.678356] [G loss: 0.712462]\n",
      "[Epoch 1305/2000] [Batch 9/10] [D loss: 0.682701] [G loss: 0.703331]\n",
      "[Epoch 1306/2000] [Batch 9/10] [D loss: 0.686513] [G loss: 0.695114]\n",
      "[Epoch 1307/2000] [Batch 9/10] [D loss: 0.687749] [G loss: 0.691717]\n",
      "[Epoch 1308/2000] [Batch 9/10] [D loss: 0.689290] [G loss: 0.687622]\n",
      "[Epoch 1309/2000] [Batch 9/10] [D loss: 0.689538] [G loss: 0.685608]\n",
      "[Epoch 1310/2000] [Batch 9/10] [D loss: 0.688585] [G loss: 0.685842]\n",
      "[Epoch 1311/2000] [Batch 9/10] [D loss: 0.688319] [G loss: 0.684555]\n",
      "[Epoch 1312/2000] [Batch 9/10] [D loss: 0.687044] [G loss: 0.685050]\n",
      "[Epoch 1313/2000] [Batch 9/10] [D loss: 0.686482] [G loss: 0.684135]\n",
      "[Epoch 1314/2000] [Batch 9/10] [D loss: 0.683970] [G loss: 0.686849]\n",
      "[Epoch 1315/2000] [Batch 9/10] [D loss: 0.682115] [G loss: 0.688239]\n",
      "[Epoch 1316/2000] [Batch 9/10] [D loss: 0.680453] [G loss: 0.689172]\n",
      "[Epoch 1317/2000] [Batch 9/10] [D loss: 0.678087] [G loss: 0.691476]\n",
      "[Epoch 1318/2000] [Batch 9/10] [D loss: 0.676627] [G loss: 0.692022]\n",
      "[Epoch 1319/2000] [Batch 9/10] [D loss: 0.674077] [G loss: 0.694717]\n",
      "[Epoch 1320/2000] [Batch 9/10] [D loss: 0.672501] [G loss: 0.695422]\n",
      "[Epoch 1321/2000] [Batch 9/10] [D loss: 0.669897] [G loss: 0.698251]\n",
      "[Epoch 1322/2000] [Batch 9/10] [D loss: 0.668107] [G loss: 0.699450]\n",
      "[Epoch 1323/2000] [Batch 9/10] [D loss: 0.665546] [G loss: 0.702256]\n",
      "[Epoch 1324/2000] [Batch 9/10] [D loss: 0.663581] [G loss: 0.703929]\n",
      "[Epoch 1325/2000] [Batch 9/10] [D loss: 0.661500] [G loss: 0.705870]\n",
      "[Epoch 1326/2000] [Batch 9/10] [D loss: 0.659487] [G loss: 0.707774]\n",
      "[Epoch 1327/2000] [Batch 9/10] [D loss: 0.657058] [G loss: 0.710627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1328/2000] [Batch 9/10] [D loss: 0.654603] [G loss: 0.713550]\n",
      "[Epoch 1329/2000] [Batch 9/10] [D loss: 0.652934] [G loss: 0.714895]\n",
      "[Epoch 1330/2000] [Batch 9/10] [D loss: 0.651211] [G loss: 0.716459]\n",
      "[Epoch 1331/2000] [Batch 9/10] [D loss: 0.649381] [G loss: 0.718334]\n",
      "[Epoch 1332/2000] [Batch 9/10] [D loss: 0.647449] [G loss: 0.720492]\n",
      "[Epoch 1333/2000] [Batch 9/10] [D loss: 0.645248] [G loss: 0.723278]\n",
      "[Epoch 1334/2000] [Batch 9/10] [D loss: 0.643087] [G loss: 0.726168]\n",
      "[Epoch 1335/2000] [Batch 9/10] [D loss: 0.641863] [G loss: 0.727221]\n",
      "[Epoch 1336/2000] [Batch 9/10] [D loss: 0.640321] [G loss: 0.729037]\n",
      "[Epoch 1337/2000] [Batch 9/10] [D loss: 0.639322] [G loss: 0.729863]\n",
      "[Epoch 1338/2000] [Batch 9/10] [D loss: 0.636985] [G loss: 0.733517]\n",
      "[Epoch 1339/2000] [Batch 9/10] [D loss: 0.636390] [G loss: 0.733735]\n",
      "[Epoch 1340/2000] [Batch 9/10] [D loss: 0.634387] [G loss: 0.737038]\n",
      "[Epoch 1341/2000] [Batch 9/10] [D loss: 0.633724] [G loss: 0.737706]\n",
      "[Epoch 1342/2000] [Batch 9/10] [D loss: 0.633846] [G loss: 0.737043]\n",
      "[Epoch 1343/2000] [Batch 9/10] [D loss: 0.631788] [G loss: 0.740835]\n",
      "[Epoch 1344/2000] [Batch 9/10] [D loss: 0.630928] [G loss: 0.742446]\n",
      "[Epoch 1345/2000] [Batch 9/10] [D loss: 0.630484] [G loss: 0.743492]\n",
      "[Epoch 1346/2000] [Batch 9/10] [D loss: 0.631380] [G loss: 0.741990]\n",
      "[Epoch 1347/2000] [Batch 9/10] [D loss: 0.629593] [G loss: 0.745959]\n",
      "[Epoch 1348/2000] [Batch 9/10] [D loss: 0.630014] [G loss: 0.745840]\n",
      "[Epoch 1349/2000] [Batch 9/10] [D loss: 0.628602] [G loss: 0.749246]\n",
      "[Epoch 1350/2000] [Batch 9/10] [D loss: 0.629167] [G loss: 0.749439]\n",
      "[Epoch 1351/2000] [Batch 9/10] [D loss: 0.630654] [G loss: 0.747530]\n",
      "[Epoch 1352/2000] [Batch 9/10] [D loss: 0.630588] [G loss: 0.749078]\n",
      "[Epoch 1353/2000] [Batch 9/10] [D loss: 0.633433] [G loss: 0.745394]\n",
      "[Epoch 1354/2000] [Batch 9/10] [D loss: 0.633813] [G loss: 0.746648]\n",
      "[Epoch 1355/2000] [Batch 9/10] [D loss: 0.634701] [G loss: 0.746784]\n",
      "[Epoch 1356/2000] [Batch 9/10] [D loss: 0.636975] [G loss: 0.744765]\n",
      "[Epoch 1357/2000] [Batch 9/10] [D loss: 0.639047] [G loss: 0.743666]\n",
      "[Epoch 1358/2000] [Batch 9/10] [D loss: 0.642484] [G loss: 0.739813]\n",
      "[Epoch 1359/2000] [Batch 9/10] [D loss: 0.642111] [G loss: 0.742937]\n",
      "[Epoch 1360/2000] [Batch 9/10] [D loss: 0.644528] [G loss: 0.741488]\n",
      "[Epoch 1361/2000] [Batch 9/10] [D loss: 0.649242] [G loss: 0.735644]\n",
      "[Epoch 1362/2000] [Batch 9/10] [D loss: 0.650180] [G loss: 0.736760]\n",
      "[Epoch 1363/2000] [Batch 9/10] [D loss: 0.652924] [G loss: 0.734709]\n",
      "[Epoch 1364/2000] [Batch 9/10] [D loss: 0.654679] [G loss: 0.733470]\n",
      "[Epoch 1365/2000] [Batch 9/10] [D loss: 0.653922] [G loss: 0.737572]\n",
      "[Epoch 1366/2000] [Batch 9/10] [D loss: 0.657749] [G loss: 0.732215]\n",
      "[Epoch 1367/2000] [Batch 9/10] [D loss: 0.658246] [G loss: 0.733869]\n",
      "[Epoch 1368/2000] [Batch 9/10] [D loss: 0.657507] [G loss: 0.737577]\n",
      "[Epoch 1369/2000] [Batch 9/10] [D loss: 0.657823] [G loss: 0.738665]\n",
      "[Epoch 1370/2000] [Batch 9/10] [D loss: 0.659948] [G loss: 0.736559]\n",
      "[Epoch 1371/2000] [Batch 9/10] [D loss: 0.664449] [G loss: 0.728888]\n",
      "[Epoch 1372/2000] [Batch 9/10] [D loss: 0.666533] [G loss: 0.726731]\n",
      "[Epoch 1373/2000] [Batch 9/10] [D loss: 0.666679] [G loss: 0.729064]\n",
      "[Epoch 1374/2000] [Batch 9/10] [D loss: 0.664819] [G loss: 0.735875]\n",
      "[Epoch 1375/2000] [Batch 9/10] [D loss: 0.663444] [G loss: 0.741307]\n",
      "[Epoch 1376/2000] [Batch 9/10] [D loss: 0.662153] [G loss: 0.745734]\n",
      "[Epoch 1377/2000] [Batch 9/10] [D loss: 0.659842] [G loss: 0.753136]\n",
      "[Epoch 1378/2000] [Batch 9/10] [D loss: 0.658080] [G loss: 0.758851]\n",
      "[Epoch 1379/2000] [Batch 9/10] [D loss: 0.655663] [G loss: 0.765816]\n",
      "[Epoch 1380/2000] [Batch 9/10] [D loss: 0.654388] [G loss: 0.769710]\n",
      "[Epoch 1381/2000] [Batch 9/10] [D loss: 0.652288] [G loss: 0.775510]\n",
      "[Epoch 1382/2000] [Batch 9/10] [D loss: 0.651241] [G loss: 0.778512]\n",
      "[Epoch 1383/2000] [Batch 9/10] [D loss: 0.650271] [G loss: 0.781391]\n",
      "[Epoch 1384/2000] [Batch 9/10] [D loss: 0.649181] [G loss: 0.784307]\n",
      "[Epoch 1385/2000] [Batch 9/10] [D loss: 0.648454] [G loss: 0.786388]\n",
      "[Epoch 1386/2000] [Batch 9/10] [D loss: 0.647323] [G loss: 0.789301]\n",
      "[Epoch 1387/2000] [Batch 9/10] [D loss: 0.647490] [G loss: 0.789083]\n",
      "[Epoch 1388/2000] [Batch 9/10] [D loss: 0.647595] [G loss: 0.789032]\n",
      "[Epoch 1389/2000] [Batch 9/10] [D loss: 0.647982] [G loss: 0.788538]\n",
      "[Epoch 1390/2000] [Batch 9/10] [D loss: 0.648751] [G loss: 0.787275]\n",
      "[Epoch 1391/2000] [Batch 9/10] [D loss: 0.649807] [G loss: 0.785215]\n",
      "[Epoch 1392/2000] [Batch 9/10] [D loss: 0.650787] [G loss: 0.783733]\n",
      "[Epoch 1393/2000] [Batch 9/10] [D loss: 0.652022] [G loss: 0.781302]\n",
      "[Epoch 1394/2000] [Batch 9/10] [D loss: 0.652407] [G loss: 0.780741]\n",
      "[Epoch 1395/2000] [Batch 9/10] [D loss: 0.654271] [G loss: 0.777252]\n",
      "[Epoch 1396/2000] [Batch 9/10] [D loss: 0.656839] [G loss: 0.772137]\n",
      "[Epoch 1397/2000] [Batch 9/10] [D loss: 0.657915] [G loss: 0.770251]\n",
      "[Epoch 1398/2000] [Batch 9/10] [D loss: 0.661451] [G loss: 0.763543]\n",
      "[Epoch 1399/2000] [Batch 9/10] [D loss: 0.661629] [G loss: 0.763558]\n",
      "[Epoch 1400/2000] [Batch 9/10] [D loss: 0.660154] [G loss: 0.767406]\n",
      "[Epoch 1401/2000] [Batch 9/10] [D loss: 0.659273] [G loss: 0.769862]\n",
      "[Epoch 1402/2000] [Batch 9/10] [D loss: 0.659213] [G loss: 0.770205]\n",
      "[Epoch 1403/2000] [Batch 9/10] [D loss: 0.657803] [G loss: 0.773687]\n",
      "[Epoch 1404/2000] [Batch 9/10] [D loss: 0.654487] [G loss: 0.780899]\n",
      "[Epoch 1405/2000] [Batch 9/10] [D loss: 0.652406] [G loss: 0.785908]\n",
      "[Epoch 1406/2000] [Batch 9/10] [D loss: 0.651553] [G loss: 0.787661]\n",
      "[Epoch 1407/2000] [Batch 9/10] [D loss: 0.651763] [G loss: 0.786624]\n",
      "[Epoch 1408/2000] [Batch 9/10] [D loss: 0.660142] [G loss: 0.770067]\n",
      "[Epoch 1409/2000] [Batch 9/10] [D loss: 0.669031] [G loss: 0.754930]\n",
      "[Epoch 1410/2000] [Batch 9/10] [D loss: 0.672610] [G loss: 0.751000]\n",
      "[Epoch 1411/2000] [Batch 9/10] [D loss: 0.675102] [G loss: 0.748657]\n",
      "[Epoch 1412/2000] [Batch 9/10] [D loss: 0.676352] [G loss: 0.748529]\n",
      "[Epoch 1413/2000] [Batch 9/10] [D loss: 0.674153] [G loss: 0.755051]\n",
      "[Epoch 1414/2000] [Batch 9/10] [D loss: 0.678140] [G loss: 0.747887]\n",
      "[Epoch 1415/2000] [Batch 9/10] [D loss: 0.677861] [G loss: 0.749556]\n",
      "[Epoch 1416/2000] [Batch 9/10] [D loss: 0.678247] [G loss: 0.749317]\n",
      "[Epoch 1417/2000] [Batch 9/10] [D loss: 0.679814] [G loss: 0.746584]\n",
      "[Epoch 1418/2000] [Batch 9/10] [D loss: 0.676357] [G loss: 0.753612]\n",
      "[Epoch 1419/2000] [Batch 9/10] [D loss: 0.676932] [G loss: 0.752092]\n",
      "[Epoch 1420/2000] [Batch 9/10] [D loss: 0.681355] [G loss: 0.741499]\n",
      "[Epoch 1421/2000] [Batch 9/10] [D loss: 0.679259] [G loss: 0.743046]\n",
      "[Epoch 1422/2000] [Batch 9/10] [D loss: 0.686241] [G loss: 0.724616]\n",
      "[Epoch 1423/2000] [Batch 9/10] [D loss: 0.685555] [G loss: 0.723559]\n",
      "[Epoch 1424/2000] [Batch 9/10] [D loss: 0.693915] [G loss: 0.700287]\n",
      "[Epoch 1425/2000] [Batch 9/10] [D loss: 0.700353] [G loss: 0.684532]\n",
      "[Epoch 1426/2000] [Batch 9/10] [D loss: 0.703824] [G loss: 0.676868]\n",
      "[Epoch 1427/2000] [Batch 9/10] [D loss: 0.703466] [G loss: 0.676518]\n",
      "[Epoch 1428/2000] [Batch 9/10] [D loss: 0.703504] [G loss: 0.675183]\n",
      "[Epoch 1429/2000] [Batch 9/10] [D loss: 0.704556] [G loss: 0.672173]\n",
      "[Epoch 1430/2000] [Batch 9/10] [D loss: 0.703528] [G loss: 0.673098]\n",
      "[Epoch 1431/2000] [Batch 9/10] [D loss: 0.702841] [G loss: 0.674833]\n",
      "[Epoch 1432/2000] [Batch 9/10] [D loss: 0.702511] [G loss: 0.674942]\n",
      "[Epoch 1433/2000] [Batch 9/10] [D loss: 0.701406] [G loss: 0.675353]\n",
      "[Epoch 1434/2000] [Batch 9/10] [D loss: 0.701206] [G loss: 0.674637]\n",
      "[Epoch 1435/2000] [Batch 9/10] [D loss: 0.700199] [G loss: 0.675530]\n",
      "[Epoch 1436/2000] [Batch 9/10] [D loss: 0.699872] [G loss: 0.675312]\n",
      "[Epoch 1437/2000] [Batch 9/10] [D loss: 0.697514] [G loss: 0.678717]\n",
      "[Epoch 1438/2000] [Batch 9/10] [D loss: 0.696179] [G loss: 0.680098]\n",
      "[Epoch 1439/2000] [Batch 9/10] [D loss: 0.695027] [G loss: 0.680305]\n",
      "[Epoch 1440/2000] [Batch 9/10] [D loss: 0.695501] [G loss: 0.677598]\n",
      "[Epoch 1441/2000] [Batch 9/10] [D loss: 0.693039] [G loss: 0.681481]\n",
      "[Epoch 1442/2000] [Batch 9/10] [D loss: 0.693558] [G loss: 0.677794]\n",
      "[Epoch 1443/2000] [Batch 9/10] [D loss: 0.692745] [G loss: 0.676831]\n",
      "[Epoch 1444/2000] [Batch 9/10] [D loss: 0.695470] [G loss: 0.669270]\n",
      "[Epoch 1445/2000] [Batch 9/10] [D loss: 0.695039] [G loss: 0.666544]\n",
      "[Epoch 1446/2000] [Batch 9/10] [D loss: 0.694154] [G loss: 0.664570]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1447/2000] [Batch 9/10] [D loss: 0.693279] [G loss: 0.662410]\n",
      "[Epoch 1448/2000] [Batch 9/10] [D loss: 0.691429] [G loss: 0.662595]\n",
      "[Epoch 1449/2000] [Batch 9/10] [D loss: 0.692029] [G loss: 0.658723]\n",
      "[Epoch 1450/2000] [Batch 9/10] [D loss: 0.691480] [G loss: 0.656562]\n",
      "[Epoch 1451/2000] [Batch 9/10] [D loss: 0.689595] [G loss: 0.657554]\n",
      "[Epoch 1452/2000] [Batch 9/10] [D loss: 0.689012] [G loss: 0.656195]\n",
      "[Epoch 1453/2000] [Batch 9/10] [D loss: 0.687740] [G loss: 0.656561]\n",
      "[Epoch 1454/2000] [Batch 9/10] [D loss: 0.686229] [G loss: 0.657477]\n",
      "[Epoch 1455/2000] [Batch 9/10] [D loss: 0.686205] [G loss: 0.655521]\n",
      "[Epoch 1456/2000] [Batch 9/10] [D loss: 0.685607] [G loss: 0.654764]\n",
      "[Epoch 1457/2000] [Batch 9/10] [D loss: 0.685241] [G loss: 0.653883]\n",
      "[Epoch 1458/2000] [Batch 9/10] [D loss: 0.683738] [G loss: 0.655303]\n",
      "[Epoch 1459/2000] [Batch 9/10] [D loss: 0.684189] [G loss: 0.653355]\n",
      "[Epoch 1460/2000] [Batch 9/10] [D loss: 0.684019] [G loss: 0.652468]\n",
      "[Epoch 1461/2000] [Batch 9/10] [D loss: 0.683213] [G loss: 0.653049]\n",
      "[Epoch 1462/2000] [Batch 9/10] [D loss: 0.682719] [G loss: 0.653184]\n",
      "[Epoch 1463/2000] [Batch 9/10] [D loss: 0.683499] [G loss: 0.651097]\n",
      "[Epoch 1464/2000] [Batch 9/10] [D loss: 0.683362] [G loss: 0.650933]\n",
      "[Epoch 1465/2000] [Batch 9/10] [D loss: 0.683897] [G loss: 0.649630]\n",
      "[Epoch 1466/2000] [Batch 9/10] [D loss: 0.684973] [G loss: 0.647561]\n",
      "[Epoch 1467/2000] [Batch 9/10] [D loss: 0.685644] [G loss: 0.646560]\n",
      "[Epoch 1468/2000] [Batch 9/10] [D loss: 0.688269] [G loss: 0.642277]\n",
      "[Epoch 1469/2000] [Batch 9/10] [D loss: 0.688531] [G loss: 0.642501]\n",
      "[Epoch 1470/2000] [Batch 9/10] [D loss: 0.690637] [G loss: 0.639895]\n",
      "[Epoch 1471/2000] [Batch 9/10] [D loss: 0.693568] [G loss: 0.636199]\n",
      "[Epoch 1472/2000] [Batch 9/10] [D loss: 0.694476] [G loss: 0.636363]\n",
      "[Epoch 1473/2000] [Batch 9/10] [D loss: 0.695464] [G loss: 0.636473]\n",
      "[Epoch 1474/2000] [Batch 9/10] [D loss: 0.697518] [G loss: 0.634717]\n",
      "[Epoch 1475/2000] [Batch 9/10] [D loss: 0.696114] [G loss: 0.639136]\n",
      "[Epoch 1476/2000] [Batch 9/10] [D loss: 0.698019] [G loss: 0.637451]\n",
      "[Epoch 1477/2000] [Batch 9/10] [D loss: 0.697617] [G loss: 0.639815]\n",
      "[Epoch 1478/2000] [Batch 9/10] [D loss: 0.697597] [G loss: 0.641386]\n",
      "[Epoch 1479/2000] [Batch 9/10] [D loss: 0.698410] [G loss: 0.641011]\n",
      "[Epoch 1480/2000] [Batch 9/10] [D loss: 0.695736] [G loss: 0.647187]\n",
      "[Epoch 1481/2000] [Batch 9/10] [D loss: 0.697696] [G loss: 0.644484]\n",
      "[Epoch 1482/2000] [Batch 9/10] [D loss: 0.696512] [G loss: 0.647499]\n",
      "[Epoch 1483/2000] [Batch 9/10] [D loss: 0.696575] [G loss: 0.648169]\n",
      "[Epoch 1484/2000] [Batch 9/10] [D loss: 0.695121] [G loss: 0.651803]\n",
      "[Epoch 1485/2000] [Batch 9/10] [D loss: 0.695224] [G loss: 0.652409]\n",
      "[Epoch 1486/2000] [Batch 9/10] [D loss: 0.695731] [G loss: 0.652301]\n",
      "[Epoch 1487/2000] [Batch 9/10] [D loss: 0.697178] [G loss: 0.650510]\n",
      "[Epoch 1488/2000] [Batch 9/10] [D loss: 0.698028] [G loss: 0.650079]\n",
      "[Epoch 1489/2000] [Batch 9/10] [D loss: 0.698446] [G loss: 0.650658]\n",
      "[Epoch 1490/2000] [Batch 9/10] [D loss: 0.700139] [G loss: 0.648642]\n",
      "[Epoch 1491/2000] [Batch 9/10] [D loss: 0.701568] [G loss: 0.647509]\n",
      "[Epoch 1492/2000] [Batch 9/10] [D loss: 0.702640] [G loss: 0.647095]\n",
      "[Epoch 1493/2000] [Batch 9/10] [D loss: 0.704325] [G loss: 0.645636]\n",
      "[Epoch 1494/2000] [Batch 9/10] [D loss: 0.704962] [G loss: 0.646415]\n",
      "[Epoch 1495/2000] [Batch 9/10] [D loss: 0.705814] [G loss: 0.646104]\n",
      "[Epoch 1496/2000] [Batch 9/10] [D loss: 0.706982] [G loss: 0.645089]\n",
      "[Epoch 1497/2000] [Batch 9/10] [D loss: 0.706870] [G loss: 0.646579]\n",
      "[Epoch 1498/2000] [Batch 9/10] [D loss: 0.707599] [G loss: 0.646525]\n",
      "[Epoch 1499/2000] [Batch 9/10] [D loss: 0.707716] [G loss: 0.647048]\n",
      "[Epoch 1500/2000] [Batch 9/10] [D loss: 0.707806] [G loss: 0.647526]\n",
      "[Epoch 1501/2000] [Batch 9/10] [D loss: 0.706220] [G loss: 0.651644]\n",
      "[Epoch 1502/2000] [Batch 9/10] [D loss: 0.706664] [G loss: 0.651310]\n",
      "[Epoch 1503/2000] [Batch 9/10] [D loss: 0.706947] [G loss: 0.651059]\n",
      "[Epoch 1504/2000] [Batch 9/10] [D loss: 0.706131] [G loss: 0.652986]\n",
      "[Epoch 1505/2000] [Batch 9/10] [D loss: 0.706195] [G loss: 0.652717]\n",
      "[Epoch 1506/2000] [Batch 9/10] [D loss: 0.707205] [G loss: 0.650669]\n",
      "[Epoch 1507/2000] [Batch 9/10] [D loss: 0.705521] [G loss: 0.654143]\n",
      "[Epoch 1508/2000] [Batch 9/10] [D loss: 0.707782] [G loss: 0.649432]\n",
      "[Epoch 1509/2000] [Batch 9/10] [D loss: 0.707858] [G loss: 0.649528]\n",
      "[Epoch 1510/2000] [Batch 9/10] [D loss: 0.709133] [G loss: 0.647381]\n",
      "[Epoch 1511/2000] [Batch 9/10] [D loss: 0.710152] [G loss: 0.645895]\n",
      "[Epoch 1512/2000] [Batch 9/10] [D loss: 0.710690] [G loss: 0.645848]\n",
      "[Epoch 1513/2000] [Batch 9/10] [D loss: 0.711990] [G loss: 0.644196]\n",
      "[Epoch 1514/2000] [Batch 9/10] [D loss: 0.713376] [G loss: 0.642888]\n",
      "[Epoch 1515/2000] [Batch 9/10] [D loss: 0.713040] [G loss: 0.644636]\n",
      "[Epoch 1516/2000] [Batch 9/10] [D loss: 0.712507] [G loss: 0.646331]\n",
      "[Epoch 1517/2000] [Batch 9/10] [D loss: 0.712625] [G loss: 0.646958]\n",
      "[Epoch 1518/2000] [Batch 9/10] [D loss: 0.711161] [G loss: 0.650568]\n",
      "[Epoch 1519/2000] [Batch 9/10] [D loss: 0.710978] [G loss: 0.651724]\n",
      "[Epoch 1520/2000] [Batch 9/10] [D loss: 0.709382] [G loss: 0.655510]\n",
      "[Epoch 1521/2000] [Batch 9/10] [D loss: 0.710635] [G loss: 0.654155]\n",
      "[Epoch 1522/2000] [Batch 9/10] [D loss: 0.709751] [G loss: 0.656687]\n",
      "[Epoch 1523/2000] [Batch 9/10] [D loss: 0.709336] [G loss: 0.658424]\n",
      "[Epoch 1524/2000] [Batch 9/10] [D loss: 0.708639] [G loss: 0.660663]\n",
      "[Epoch 1525/2000] [Batch 9/10] [D loss: 0.708144] [G loss: 0.662756]\n",
      "[Epoch 1526/2000] [Batch 9/10] [D loss: 0.707708] [G loss: 0.665186]\n",
      "[Epoch 1527/2000] [Batch 9/10] [D loss: 0.707104] [G loss: 0.668223]\n",
      "[Epoch 1528/2000] [Batch 9/10] [D loss: 0.706946] [G loss: 0.670694]\n",
      "[Epoch 1529/2000] [Batch 9/10] [D loss: 0.707260] [G loss: 0.672308]\n",
      "[Epoch 1530/2000] [Batch 9/10] [D loss: 0.705593] [G loss: 0.677426]\n",
      "[Epoch 1531/2000] [Batch 9/10] [D loss: 0.705087] [G loss: 0.680417]\n",
      "[Epoch 1532/2000] [Batch 9/10] [D loss: 0.703345] [G loss: 0.685307]\n",
      "[Epoch 1533/2000] [Batch 9/10] [D loss: 0.702726] [G loss: 0.688031]\n",
      "[Epoch 1534/2000] [Batch 9/10] [D loss: 0.700527] [G loss: 0.693526]\n",
      "[Epoch 1535/2000] [Batch 9/10] [D loss: 0.699395] [G loss: 0.696807]\n",
      "[Epoch 1536/2000] [Batch 9/10] [D loss: 0.698282] [G loss: 0.699906]\n",
      "[Epoch 1537/2000] [Batch 9/10] [D loss: 0.697176] [G loss: 0.702916]\n",
      "[Epoch 1538/2000] [Batch 9/10] [D loss: 0.695812] [G loss: 0.705883]\n",
      "[Epoch 1539/2000] [Batch 9/10] [D loss: 0.695382] [G loss: 0.707017]\n",
      "[Epoch 1540/2000] [Batch 9/10] [D loss: 0.693576] [G loss: 0.710797]\n",
      "[Epoch 1541/2000] [Batch 9/10] [D loss: 0.692560] [G loss: 0.712657]\n",
      "[Epoch 1542/2000] [Batch 9/10] [D loss: 0.691691] [G loss: 0.714156]\n",
      "[Epoch 1543/2000] [Batch 9/10] [D loss: 0.689511] [G loss: 0.718165]\n",
      "[Epoch 1544/2000] [Batch 9/10] [D loss: 0.689111] [G loss: 0.718156]\n",
      "[Epoch 1545/2000] [Batch 9/10] [D loss: 0.688492] [G loss: 0.718276]\n",
      "[Epoch 1546/2000] [Batch 9/10] [D loss: 0.688470] [G loss: 0.717020]\n",
      "[Epoch 1547/2000] [Batch 9/10] [D loss: 0.687653] [G loss: 0.717233]\n",
      "[Epoch 1548/2000] [Batch 9/10] [D loss: 0.687700] [G loss: 0.715557]\n",
      "[Epoch 1549/2000] [Batch 9/10] [D loss: 0.687928] [G loss: 0.713535]\n",
      "[Epoch 1550/2000] [Batch 9/10] [D loss: 0.689052] [G loss: 0.709374]\n",
      "[Epoch 1551/2000] [Batch 9/10] [D loss: 0.688812] [G loss: 0.707741]\n",
      "[Epoch 1552/2000] [Batch 9/10] [D loss: 0.689435] [G loss: 0.704034]\n",
      "[Epoch 1553/2000] [Batch 9/10] [D loss: 0.688379] [G loss: 0.703262]\n",
      "[Epoch 1554/2000] [Batch 9/10] [D loss: 0.687271] [G loss: 0.702633]\n",
      "[Epoch 1555/2000] [Batch 9/10] [D loss: 0.687677] [G loss: 0.698911]\n",
      "[Epoch 1556/2000] [Batch 9/10] [D loss: 0.687206] [G loss: 0.696928]\n",
      "[Epoch 1557/2000] [Batch 9/10] [D loss: 0.686411] [G loss: 0.696105]\n",
      "[Epoch 1558/2000] [Batch 9/10] [D loss: 0.684908] [G loss: 0.696522]\n",
      "[Epoch 1559/2000] [Batch 9/10] [D loss: 0.684468] [G loss: 0.695063]\n",
      "[Epoch 1560/2000] [Batch 9/10] [D loss: 0.683614] [G loss: 0.694807]\n",
      "[Epoch 1561/2000] [Batch 9/10] [D loss: 0.684353] [G loss: 0.691544]\n",
      "[Epoch 1562/2000] [Batch 9/10] [D loss: 0.682037] [G loss: 0.694149]\n",
      "[Epoch 1563/2000] [Batch 9/10] [D loss: 0.683188] [G loss: 0.690007]\n",
      "[Epoch 1564/2000] [Batch 9/10] [D loss: 0.682147] [G loss: 0.690735]\n",
      "[Epoch 1565/2000] [Batch 9/10] [D loss: 0.681100] [G loss: 0.691297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1566/2000] [Batch 9/10] [D loss: 0.680336] [G loss: 0.691442]\n",
      "[Epoch 1567/2000] [Batch 9/10] [D loss: 0.680903] [G loss: 0.689152]\n",
      "[Epoch 1568/2000] [Batch 9/10] [D loss: 0.680580] [G loss: 0.688467]\n",
      "[Epoch 1569/2000] [Batch 9/10] [D loss: 0.680222] [G loss: 0.687891]\n",
      "[Epoch 1570/2000] [Batch 9/10] [D loss: 0.680745] [G loss: 0.686061]\n",
      "[Epoch 1571/2000] [Batch 9/10] [D loss: 0.681246] [G loss: 0.684370]\n",
      "[Epoch 1572/2000] [Batch 9/10] [D loss: 0.680812] [G loss: 0.684293]\n",
      "[Epoch 1573/2000] [Batch 9/10] [D loss: 0.680612] [G loss: 0.683647]\n",
      "[Epoch 1574/2000] [Batch 9/10] [D loss: 0.681688] [G loss: 0.680633]\n",
      "[Epoch 1575/2000] [Batch 9/10] [D loss: 0.680390] [G loss: 0.681869]\n",
      "[Epoch 1576/2000] [Batch 9/10] [D loss: 0.682436] [G loss: 0.677354]\n",
      "[Epoch 1577/2000] [Batch 9/10] [D loss: 0.681455] [G loss: 0.677601]\n",
      "[Epoch 1578/2000] [Batch 9/10] [D loss: 0.683648] [G loss: 0.672837]\n",
      "[Epoch 1579/2000] [Batch 9/10] [D loss: 0.685083] [G loss: 0.668297]\n",
      "[Epoch 1580/2000] [Batch 9/10] [D loss: 0.684447] [G loss: 0.668205]\n",
      "[Epoch 1581/2000] [Batch 9/10] [D loss: 0.684974] [G loss: 0.666101]\n",
      "[Epoch 1582/2000] [Batch 9/10] [D loss: 0.686609] [G loss: 0.662236]\n",
      "[Epoch 1583/2000] [Batch 9/10] [D loss: 0.686303] [G loss: 0.661361]\n",
      "[Epoch 1584/2000] [Batch 9/10] [D loss: 0.685711] [G loss: 0.661003]\n",
      "[Epoch 1585/2000] [Batch 9/10] [D loss: 0.685958] [G loss: 0.659277]\n",
      "[Epoch 1586/2000] [Batch 9/10] [D loss: 0.687211] [G loss: 0.656681]\n",
      "[Epoch 1587/2000] [Batch 9/10] [D loss: 0.688680] [G loss: 0.653748]\n",
      "[Epoch 1588/2000] [Batch 9/10] [D loss: 0.695768] [G loss: 0.641419]\n",
      "[Epoch 1589/2000] [Batch 9/10] [D loss: 0.702573] [G loss: 0.629904]\n",
      "[Epoch 1590/2000] [Batch 9/10] [D loss: 0.706124] [G loss: 0.624097]\n",
      "[Epoch 1591/2000] [Batch 9/10] [D loss: 0.707422] [G loss: 0.621434]\n",
      "[Epoch 1592/2000] [Batch 9/10] [D loss: 0.706728] [G loss: 0.621781]\n",
      "[Epoch 1593/2000] [Batch 9/10] [D loss: 0.704679] [G loss: 0.624006]\n",
      "[Epoch 1594/2000] [Batch 9/10] [D loss: 0.702023] [G loss: 0.627424]\n",
      "[Epoch 1595/2000] [Batch 9/10] [D loss: 0.699121] [G loss: 0.631075]\n",
      "[Epoch 1596/2000] [Batch 9/10] [D loss: 0.694664] [G loss: 0.637701]\n",
      "[Epoch 1597/2000] [Batch 9/10] [D loss: 0.693197] [G loss: 0.638860]\n",
      "[Epoch 1598/2000] [Batch 9/10] [D loss: 0.689167] [G loss: 0.644994]\n",
      "[Epoch 1599/2000] [Batch 9/10] [D loss: 0.686500] [G loss: 0.648420]\n",
      "[Epoch 1600/2000] [Batch 9/10] [D loss: 0.684464] [G loss: 0.650473]\n",
      "[Epoch 1601/2000] [Batch 9/10] [D loss: 0.682672] [G loss: 0.652301]\n",
      "[Epoch 1602/2000] [Batch 9/10] [D loss: 0.680571] [G loss: 0.654865]\n",
      "[Epoch 1603/2000] [Batch 9/10] [D loss: 0.677777] [G loss: 0.658898]\n",
      "[Epoch 1604/2000] [Batch 9/10] [D loss: 0.676345] [G loss: 0.660822]\n",
      "[Epoch 1605/2000] [Batch 9/10] [D loss: 0.674925] [G loss: 0.662673]\n",
      "[Epoch 1606/2000] [Batch 9/10] [D loss: 0.671809] [G loss: 0.668041]\n",
      "[Epoch 1607/2000] [Batch 9/10] [D loss: 0.671200] [G loss: 0.668617]\n",
      "[Epoch 1608/2000] [Batch 9/10] [D loss: 0.669653] [G loss: 0.671241]\n",
      "[Epoch 1609/2000] [Batch 9/10] [D loss: 0.669104] [G loss: 0.672490]\n",
      "[Epoch 1610/2000] [Batch 9/10] [D loss: 0.667454] [G loss: 0.675983]\n",
      "[Epoch 1611/2000] [Batch 9/10] [D loss: 0.667077] [G loss: 0.677147]\n",
      "[Epoch 1612/2000] [Batch 9/10] [D loss: 0.666095] [G loss: 0.679737]\n",
      "[Epoch 1613/2000] [Batch 9/10] [D loss: 0.664414] [G loss: 0.682912]\n",
      "[Epoch 1614/2000] [Batch 9/10] [D loss: 0.666007] [G loss: 0.681276]\n",
      "[Epoch 1615/2000] [Batch 9/10] [D loss: 0.662711] [G loss: 0.687646]\n",
      "[Epoch 1616/2000] [Batch 9/10] [D loss: 0.663755] [G loss: 0.686550]\n",
      "[Epoch 1617/2000] [Batch 9/10] [D loss: 0.662718] [G loss: 0.689374]\n",
      "[Epoch 1618/2000] [Batch 9/10] [D loss: 0.662702] [G loss: 0.690443]\n",
      "[Epoch 1619/2000] [Batch 9/10] [D loss: 0.662176] [G loss: 0.692727]\n",
      "[Epoch 1620/2000] [Batch 9/10] [D loss: 0.660693] [G loss: 0.696290]\n",
      "[Epoch 1621/2000] [Batch 9/10] [D loss: 0.663885] [G loss: 0.691668]\n",
      "[Epoch 1622/2000] [Batch 9/10] [D loss: 0.661194] [G loss: 0.696545]\n",
      "[Epoch 1623/2000] [Batch 9/10] [D loss: 0.662504] [G loss: 0.694494]\n",
      "[Epoch 1624/2000] [Batch 9/10] [D loss: 0.662544] [G loss: 0.695097]\n",
      "[Epoch 1625/2000] [Batch 9/10] [D loss: 0.661468] [G loss: 0.697653]\n",
      "[Epoch 1626/2000] [Batch 9/10] [D loss: 0.661781] [G loss: 0.698148]\n",
      "[Epoch 1627/2000] [Batch 9/10] [D loss: 0.661434] [G loss: 0.699730]\n",
      "[Epoch 1628/2000] [Batch 9/10] [D loss: 0.661689] [G loss: 0.700331]\n",
      "[Epoch 1629/2000] [Batch 9/10] [D loss: 0.663680] [G loss: 0.698049]\n",
      "[Epoch 1630/2000] [Batch 9/10] [D loss: 0.663791] [G loss: 0.699111]\n",
      "[Epoch 1631/2000] [Batch 9/10] [D loss: 0.664208] [G loss: 0.699306]\n",
      "[Epoch 1632/2000] [Batch 9/10] [D loss: 0.664201] [G loss: 0.700959]\n",
      "[Epoch 1633/2000] [Batch 9/10] [D loss: 0.662831] [G loss: 0.704786]\n",
      "[Epoch 1634/2000] [Batch 9/10] [D loss: 0.667032] [G loss: 0.698809]\n",
      "[Epoch 1635/2000] [Batch 9/10] [D loss: 0.664845] [G loss: 0.703506]\n",
      "[Epoch 1636/2000] [Batch 9/10] [D loss: 0.666815] [G loss: 0.702399]\n",
      "[Epoch 1637/2000] [Batch 9/10] [D loss: 0.666250] [G loss: 0.704552]\n",
      "[Epoch 1638/2000] [Batch 9/10] [D loss: 0.667150] [G loss: 0.705432]\n",
      "[Epoch 1639/2000] [Batch 9/10] [D loss: 0.668897] [G loss: 0.704219]\n",
      "[Epoch 1640/2000] [Batch 9/10] [D loss: 0.668642] [G loss: 0.707170]\n",
      "[Epoch 1641/2000] [Batch 9/10] [D loss: 0.671140] [G loss: 0.704889]\n",
      "[Epoch 1642/2000] [Batch 9/10] [D loss: 0.671525] [G loss: 0.706165]\n",
      "[Epoch 1643/2000] [Batch 9/10] [D loss: 0.673188] [G loss: 0.705235]\n",
      "[Epoch 1644/2000] [Batch 9/10] [D loss: 0.675106] [G loss: 0.703423]\n",
      "[Epoch 1645/2000] [Batch 9/10] [D loss: 0.675559] [G loss: 0.704563]\n",
      "[Epoch 1646/2000] [Batch 9/10] [D loss: 0.676304] [G loss: 0.704667]\n",
      "[Epoch 1647/2000] [Batch 9/10] [D loss: 0.676368] [G loss: 0.706419]\n",
      "[Epoch 1648/2000] [Batch 9/10] [D loss: 0.677331] [G loss: 0.706169]\n",
      "[Epoch 1649/2000] [Batch 9/10] [D loss: 0.676568] [G loss: 0.710089]\n",
      "[Epoch 1650/2000] [Batch 9/10] [D loss: 0.677598] [G loss: 0.711031]\n",
      "[Epoch 1651/2000] [Batch 9/10] [D loss: 0.674861] [G loss: 0.721503]\n",
      "[Epoch 1652/2000] [Batch 9/10] [D loss: 0.674558] [G loss: 0.726166]\n",
      "[Epoch 1653/2000] [Batch 9/10] [D loss: 0.673437] [G loss: 0.731873]\n",
      "[Epoch 1654/2000] [Batch 9/10] [D loss: 0.670893] [G loss: 0.740866]\n",
      "[Epoch 1655/2000] [Batch 9/10] [D loss: 0.670049] [G loss: 0.745384]\n",
      "[Epoch 1656/2000] [Batch 9/10] [D loss: 0.666774] [G loss: 0.755447]\n",
      "[Epoch 1657/2000] [Batch 9/10] [D loss: 0.666394] [G loss: 0.757755]\n",
      "[Epoch 1658/2000] [Batch 9/10] [D loss: 0.664425] [G loss: 0.763518]\n",
      "[Epoch 1659/2000] [Batch 9/10] [D loss: 0.662880] [G loss: 0.767564]\n",
      "[Epoch 1660/2000] [Batch 9/10] [D loss: 0.661754] [G loss: 0.770723]\n",
      "[Epoch 1661/2000] [Batch 9/10] [D loss: 0.659561] [G loss: 0.775517]\n",
      "[Epoch 1662/2000] [Batch 9/10] [D loss: 0.657675] [G loss: 0.779091]\n",
      "[Epoch 1663/2000] [Batch 9/10] [D loss: 0.656679] [G loss: 0.781198]\n",
      "[Epoch 1664/2000] [Batch 9/10] [D loss: 0.656485] [G loss: 0.780840]\n",
      "[Epoch 1665/2000] [Batch 9/10] [D loss: 0.655390] [G loss: 0.782762]\n",
      "[Epoch 1666/2000] [Batch 9/10] [D loss: 0.653308] [G loss: 0.786016]\n",
      "[Epoch 1667/2000] [Batch 9/10] [D loss: 0.653609] [G loss: 0.784279]\n",
      "[Epoch 1668/2000] [Batch 9/10] [D loss: 0.653269] [G loss: 0.782814]\n",
      "[Epoch 1669/2000] [Batch 9/10] [D loss: 0.652486] [G loss: 0.782953]\n",
      "[Epoch 1670/2000] [Batch 9/10] [D loss: 0.651106] [G loss: 0.783600]\n",
      "[Epoch 1671/2000] [Batch 9/10] [D loss: 0.651371] [G loss: 0.780866]\n",
      "[Epoch 1672/2000] [Batch 9/10] [D loss: 0.652501] [G loss: 0.775937]\n",
      "[Epoch 1673/2000] [Batch 9/10] [D loss: 0.651438] [G loss: 0.774978]\n",
      "[Epoch 1674/2000] [Batch 9/10] [D loss: 0.653155] [G loss: 0.768424]\n",
      "[Epoch 1675/2000] [Batch 9/10] [D loss: 0.656756] [G loss: 0.757200]\n",
      "[Epoch 1676/2000] [Batch 9/10] [D loss: 0.662370] [G loss: 0.741663]\n",
      "[Epoch 1677/2000] [Batch 9/10] [D loss: 0.661176] [G loss: 0.739680]\n",
      "[Epoch 1678/2000] [Batch 9/10] [D loss: 0.661998] [G loss: 0.734252]\n",
      "[Epoch 1679/2000] [Batch 9/10] [D loss: 0.660887] [G loss: 0.732454]\n",
      "[Epoch 1680/2000] [Batch 9/10] [D loss: 0.660156] [G loss: 0.730846]\n",
      "[Epoch 1681/2000] [Batch 9/10] [D loss: 0.660503] [G loss: 0.727044]\n",
      "[Epoch 1682/2000] [Batch 9/10] [D loss: 0.659963] [G loss: 0.724895]\n",
      "[Epoch 1683/2000] [Batch 9/10] [D loss: 0.660210] [G loss: 0.721649]\n",
      "[Epoch 1684/2000] [Batch 9/10] [D loss: 0.659069] [G loss: 0.720913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1685/2000] [Batch 9/10] [D loss: 0.659550] [G loss: 0.717617]\n",
      "[Epoch 1686/2000] [Batch 9/10] [D loss: 0.659195] [G loss: 0.715719]\n",
      "[Epoch 1687/2000] [Batch 9/10] [D loss: 0.657912] [G loss: 0.715853]\n",
      "[Epoch 1688/2000] [Batch 9/10] [D loss: 0.656067] [G loss: 0.717570]\n",
      "[Epoch 1689/2000] [Batch 9/10] [D loss: 0.657111] [G loss: 0.713627]\n",
      "[Epoch 1690/2000] [Batch 9/10] [D loss: 0.658360] [G loss: 0.709635]\n",
      "[Epoch 1691/2000] [Batch 9/10] [D loss: 0.656033] [G loss: 0.712324]\n",
      "[Epoch 1692/2000] [Batch 9/10] [D loss: 0.657841] [G loss: 0.707596]\n",
      "[Epoch 1693/2000] [Batch 9/10] [D loss: 0.657375] [G loss: 0.707097]\n",
      "[Epoch 1694/2000] [Batch 9/10] [D loss: 0.657286] [G loss: 0.706303]\n",
      "[Epoch 1695/2000] [Batch 9/10] [D loss: 0.658348] [G loss: 0.703111]\n",
      "[Epoch 1696/2000] [Batch 9/10] [D loss: 0.656158] [G loss: 0.706681]\n",
      "[Epoch 1697/2000] [Batch 9/10] [D loss: 0.657234] [G loss: 0.704242]\n",
      "[Epoch 1698/2000] [Batch 9/10] [D loss: 0.656669] [G loss: 0.705053]\n",
      "[Epoch 1699/2000] [Batch 9/10] [D loss: 0.657839] [G loss: 0.702567]\n",
      "[Epoch 1700/2000] [Batch 9/10] [D loss: 0.657413] [G loss: 0.703350]\n",
      "[Epoch 1701/2000] [Batch 9/10] [D loss: 0.656085] [G loss: 0.705531]\n",
      "[Epoch 1702/2000] [Batch 9/10] [D loss: 0.656680] [G loss: 0.704112]\n",
      "[Epoch 1703/2000] [Batch 9/10] [D loss: 0.656317] [G loss: 0.704512]\n",
      "[Epoch 1704/2000] [Batch 9/10] [D loss: 0.653971] [G loss: 0.708606]\n",
      "[Epoch 1705/2000] [Batch 9/10] [D loss: 0.654678] [G loss: 0.706879]\n",
      "[Epoch 1706/2000] [Batch 9/10] [D loss: 0.654647] [G loss: 0.706468]\n",
      "[Epoch 1707/2000] [Batch 9/10] [D loss: 0.653423] [G loss: 0.707827]\n",
      "[Epoch 1708/2000] [Batch 9/10] [D loss: 0.651798] [G loss: 0.710228]\n",
      "[Epoch 1709/2000] [Batch 9/10] [D loss: 0.650776] [G loss: 0.711543]\n",
      "[Epoch 1710/2000] [Batch 9/10] [D loss: 0.651476] [G loss: 0.709402]\n",
      "[Epoch 1711/2000] [Batch 9/10] [D loss: 0.650670] [G loss: 0.710144]\n",
      "[Epoch 1712/2000] [Batch 9/10] [D loss: 0.649118] [G loss: 0.712204]\n",
      "[Epoch 1713/2000] [Batch 9/10] [D loss: 0.649976] [G loss: 0.709596]\n",
      "[Epoch 1714/2000] [Batch 9/10] [D loss: 0.651222] [G loss: 0.706089]\n",
      "[Epoch 1715/2000] [Batch 9/10] [D loss: 0.649963] [G loss: 0.707747]\n",
      "[Epoch 1716/2000] [Batch 9/10] [D loss: 0.659485] [G loss: 0.688849]\n",
      "[Epoch 1717/2000] [Batch 9/10] [D loss: 0.664635] [G loss: 0.679418]\n",
      "[Epoch 1718/2000] [Batch 9/10] [D loss: 0.665129] [G loss: 0.679076]\n",
      "[Epoch 1719/2000] [Batch 9/10] [D loss: 0.663878] [G loss: 0.681462]\n",
      "[Epoch 1720/2000] [Batch 9/10] [D loss: 0.664131] [G loss: 0.681466]\n",
      "[Epoch 1721/2000] [Batch 9/10] [D loss: 0.663751] [G loss: 0.682207]\n",
      "[Epoch 1722/2000] [Batch 9/10] [D loss: 0.662961] [G loss: 0.683898]\n",
      "[Epoch 1723/2000] [Batch 9/10] [D loss: 0.661297] [G loss: 0.686998]\n",
      "[Epoch 1724/2000] [Batch 9/10] [D loss: 0.661407] [G loss: 0.686997]\n",
      "[Epoch 1725/2000] [Batch 9/10] [D loss: 0.660612] [G loss: 0.688900]\n",
      "[Epoch 1726/2000] [Batch 9/10] [D loss: 0.660349] [G loss: 0.689561]\n",
      "[Epoch 1727/2000] [Batch 9/10] [D loss: 0.660584] [G loss: 0.689669]\n",
      "[Epoch 1728/2000] [Batch 9/10] [D loss: 0.661011] [G loss: 0.689424]\n",
      "[Epoch 1729/2000] [Batch 9/10] [D loss: 0.662894] [G loss: 0.686686]\n",
      "[Epoch 1730/2000] [Batch 9/10] [D loss: 0.664427] [G loss: 0.684975]\n",
      "[Epoch 1731/2000] [Batch 9/10] [D loss: 0.667257] [G loss: 0.680718]\n",
      "[Epoch 1732/2000] [Batch 9/10] [D loss: 0.666599] [G loss: 0.683135]\n",
      "[Epoch 1733/2000] [Batch 9/10] [D loss: 0.669196] [G loss: 0.680052]\n",
      "[Epoch 1734/2000] [Batch 9/10] [D loss: 0.666313] [G loss: 0.685640]\n",
      "[Epoch 1735/2000] [Batch 9/10] [D loss: 0.668525] [G loss: 0.682805]\n",
      "[Epoch 1736/2000] [Batch 9/10] [D loss: 0.672668] [G loss: 0.676786]\n",
      "[Epoch 1737/2000] [Batch 9/10] [D loss: 0.670035] [G loss: 0.681391]\n",
      "[Epoch 1738/2000] [Batch 9/10] [D loss: 0.668914] [G loss: 0.683759]\n",
      "[Epoch 1739/2000] [Batch 9/10] [D loss: 0.670633] [G loss: 0.681183]\n",
      "[Epoch 1740/2000] [Batch 9/10] [D loss: 0.672409] [G loss: 0.678310]\n",
      "[Epoch 1741/2000] [Batch 9/10] [D loss: 0.676675] [G loss: 0.670746]\n",
      "[Epoch 1742/2000] [Batch 9/10] [D loss: 0.678860] [G loss: 0.667737]\n",
      "[Epoch 1743/2000] [Batch 9/10] [D loss: 0.679309] [G loss: 0.667773]\n",
      "[Epoch 1744/2000] [Batch 9/10] [D loss: 0.682043] [G loss: 0.664843]\n",
      "[Epoch 1745/2000] [Batch 9/10] [D loss: 0.680877] [G loss: 0.667895]\n",
      "[Epoch 1746/2000] [Batch 9/10] [D loss: 0.683386] [G loss: 0.664939]\n",
      "[Epoch 1747/2000] [Batch 9/10] [D loss: 0.683364] [G loss: 0.665822]\n",
      "[Epoch 1748/2000] [Batch 9/10] [D loss: 0.682536] [G loss: 0.668723]\n",
      "[Epoch 1749/2000] [Batch 9/10] [D loss: 0.683262] [G loss: 0.668780]\n",
      "[Epoch 1750/2000] [Batch 9/10] [D loss: 0.681364] [G loss: 0.673735]\n",
      "[Epoch 1751/2000] [Batch 9/10] [D loss: 0.680241] [G loss: 0.677300]\n",
      "[Epoch 1752/2000] [Batch 9/10] [D loss: 0.680226] [G loss: 0.678508]\n",
      "[Epoch 1753/2000] [Batch 9/10] [D loss: 0.680258] [G loss: 0.679521]\n",
      "[Epoch 1754/2000] [Batch 9/10] [D loss: 0.676921] [G loss: 0.687431]\n",
      "[Epoch 1755/2000] [Batch 9/10] [D loss: 0.677816] [G loss: 0.686873]\n",
      "[Epoch 1756/2000] [Batch 9/10] [D loss: 0.675559] [G loss: 0.692082]\n",
      "[Epoch 1757/2000] [Batch 9/10] [D loss: 0.673781] [G loss: 0.696580]\n",
      "[Epoch 1758/2000] [Batch 9/10] [D loss: 0.672878] [G loss: 0.699722]\n",
      "[Epoch 1759/2000] [Batch 9/10] [D loss: 0.672177] [G loss: 0.701950]\n",
      "[Epoch 1760/2000] [Batch 9/10] [D loss: 0.669524] [G loss: 0.708207]\n",
      "[Epoch 1761/2000] [Batch 9/10] [D loss: 0.669543] [G loss: 0.709046]\n",
      "[Epoch 1762/2000] [Batch 9/10] [D loss: 0.669541] [G loss: 0.710259]\n",
      "[Epoch 1763/2000] [Batch 9/10] [D loss: 0.669604] [G loss: 0.711327]\n",
      "[Epoch 1764/2000] [Batch 9/10] [D loss: 0.670143] [G loss: 0.712142]\n",
      "[Epoch 1765/2000] [Batch 9/10] [D loss: 0.671660] [G loss: 0.710701]\n",
      "[Epoch 1766/2000] [Batch 9/10] [D loss: 0.673595] [G loss: 0.708957]\n",
      "[Epoch 1767/2000] [Batch 9/10] [D loss: 0.671408] [G loss: 0.714753]\n",
      "[Epoch 1768/2000] [Batch 9/10] [D loss: 0.676074] [G loss: 0.708771]\n",
      "[Epoch 1769/2000] [Batch 9/10] [D loss: 0.675565] [G loss: 0.711389]\n",
      "[Epoch 1770/2000] [Batch 9/10] [D loss: 0.678011] [G loss: 0.708987]\n",
      "[Epoch 1771/2000] [Batch 9/10] [D loss: 0.679076] [G loss: 0.708905]\n",
      "[Epoch 1772/2000] [Batch 9/10] [D loss: 0.681474] [G loss: 0.707230]\n",
      "[Epoch 1773/2000] [Batch 9/10] [D loss: 0.682160] [G loss: 0.708180]\n",
      "[Epoch 1774/2000] [Batch 9/10] [D loss: 0.683972] [G loss: 0.707222]\n",
      "[Epoch 1775/2000] [Batch 9/10] [D loss: 0.683721] [G loss: 0.709388]\n",
      "[Epoch 1776/2000] [Batch 9/10] [D loss: 0.681886] [G loss: 0.715458]\n",
      "[Epoch 1777/2000] [Batch 9/10] [D loss: 0.681602] [G loss: 0.718680]\n",
      "[Epoch 1778/2000] [Batch 9/10] [D loss: 0.683381] [G loss: 0.717819]\n",
      "[Epoch 1779/2000] [Batch 9/10] [D loss: 0.683707] [G loss: 0.719103]\n",
      "[Epoch 1780/2000] [Batch 9/10] [D loss: 0.684246] [G loss: 0.720258]\n",
      "[Epoch 1781/2000] [Batch 9/10] [D loss: 0.685653] [G loss: 0.720771]\n",
      "[Epoch 1782/2000] [Batch 9/10] [D loss: 0.687470] [G loss: 0.718956]\n",
      "[Epoch 1783/2000] [Batch 9/10] [D loss: 0.696008] [G loss: 0.703005]\n",
      "[Epoch 1784/2000] [Batch 9/10] [D loss: 0.703910] [G loss: 0.691718]\n",
      "[Epoch 1785/2000] [Batch 9/10] [D loss: 0.706807] [G loss: 0.691253]\n",
      "[Epoch 1786/2000] [Batch 9/10] [D loss: 0.709975] [G loss: 0.691110]\n",
      "[Epoch 1787/2000] [Batch 9/10] [D loss: 0.710877] [G loss: 0.694015]\n",
      "[Epoch 1788/2000] [Batch 9/10] [D loss: 0.712021] [G loss: 0.696970]\n",
      "[Epoch 1789/2000] [Batch 9/10] [D loss: 0.710225] [G loss: 0.705190]\n",
      "[Epoch 1790/2000] [Batch 9/10] [D loss: 0.711527] [G loss: 0.707329]\n",
      "[Epoch 1791/2000] [Batch 9/10] [D loss: 0.714041] [G loss: 0.708208]\n",
      "[Epoch 1792/2000] [Batch 9/10] [D loss: 0.715056] [G loss: 0.710835]\n",
      "[Epoch 1793/2000] [Batch 9/10] [D loss: 0.715414] [G loss: 0.715784]\n",
      "[Epoch 1794/2000] [Batch 9/10] [D loss: 0.713649] [G loss: 0.723279]\n",
      "[Epoch 1795/2000] [Batch 9/10] [D loss: 0.714122] [G loss: 0.726922]\n",
      "[Epoch 1796/2000] [Batch 9/10] [D loss: 0.717794] [G loss: 0.725074]\n",
      "[Epoch 1797/2000] [Batch 9/10] [D loss: 0.717588] [G loss: 0.728671]\n",
      "[Epoch 1798/2000] [Batch 9/10] [D loss: 0.720779] [G loss: 0.727017]\n",
      "[Epoch 1799/2000] [Batch 9/10] [D loss: 0.725013] [G loss: 0.722880]\n",
      "[Epoch 1800/2000] [Batch 9/10] [D loss: 0.729379] [G loss: 0.719545]\n",
      "[Epoch 1801/2000] [Batch 9/10] [D loss: 0.737624] [G loss: 0.709334]\n",
      "[Epoch 1802/2000] [Batch 9/10] [D loss: 0.742541] [G loss: 0.703708]\n",
      "[Epoch 1803/2000] [Batch 9/10] [D loss: 0.746641] [G loss: 0.700480]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1804/2000] [Batch 9/10] [D loss: 0.749603] [G loss: 0.697678]\n",
      "[Epoch 1805/2000] [Batch 9/10] [D loss: 0.749824] [G loss: 0.697963]\n",
      "[Epoch 1806/2000] [Batch 9/10] [D loss: 0.754165] [G loss: 0.691287]\n",
      "[Epoch 1807/2000] [Batch 9/10] [D loss: 0.754368] [G loss: 0.691797]\n",
      "[Epoch 1808/2000] [Batch 9/10] [D loss: 0.752773] [G loss: 0.695017]\n",
      "[Epoch 1809/2000] [Batch 9/10] [D loss: 0.754173] [G loss: 0.692559]\n",
      "[Epoch 1810/2000] [Batch 9/10] [D loss: 0.757038] [G loss: 0.687758]\n",
      "[Epoch 1811/2000] [Batch 9/10] [D loss: 0.755912] [G loss: 0.688617]\n",
      "[Epoch 1812/2000] [Batch 9/10] [D loss: 0.756969] [G loss: 0.685597]\n",
      "[Epoch 1813/2000] [Batch 9/10] [D loss: 0.757532] [G loss: 0.682391]\n",
      "[Epoch 1814/2000] [Batch 9/10] [D loss: 0.758764] [G loss: 0.679875]\n",
      "[Epoch 1815/2000] [Batch 9/10] [D loss: 0.758040] [G loss: 0.679740]\n",
      "[Epoch 1816/2000] [Batch 9/10] [D loss: 0.756955] [G loss: 0.679246]\n",
      "[Epoch 1817/2000] [Batch 9/10] [D loss: 0.756310] [G loss: 0.678791]\n",
      "[Epoch 1818/2000] [Batch 9/10] [D loss: 0.756800] [G loss: 0.675800]\n",
      "[Epoch 1819/2000] [Batch 9/10] [D loss: 0.756767] [G loss: 0.673870]\n",
      "[Epoch 1820/2000] [Batch 9/10] [D loss: 0.755726] [G loss: 0.673289]\n",
      "[Epoch 1821/2000] [Batch 9/10] [D loss: 0.755658] [G loss: 0.671251]\n",
      "[Epoch 1822/2000] [Batch 9/10] [D loss: 0.755797] [G loss: 0.669302]\n",
      "[Epoch 1823/2000] [Batch 9/10] [D loss: 0.754846] [G loss: 0.668869]\n",
      "[Epoch 1824/2000] [Batch 9/10] [D loss: 0.752795] [G loss: 0.670859]\n",
      "[Epoch 1825/2000] [Batch 9/10] [D loss: 0.751671] [G loss: 0.670931]\n",
      "[Epoch 1826/2000] [Batch 9/10] [D loss: 0.750588] [G loss: 0.671211]\n",
      "[Epoch 1827/2000] [Batch 9/10] [D loss: 0.750401] [G loss: 0.669196]\n",
      "[Epoch 1828/2000] [Batch 9/10] [D loss: 0.747689] [G loss: 0.672591]\n",
      "[Epoch 1829/2000] [Batch 9/10] [D loss: 0.744583] [G loss: 0.676501]\n",
      "[Epoch 1830/2000] [Batch 9/10] [D loss: 0.744814] [G loss: 0.674125]\n",
      "[Epoch 1831/2000] [Batch 9/10] [D loss: 0.743588] [G loss: 0.674233]\n",
      "[Epoch 1832/2000] [Batch 9/10] [D loss: 0.741306] [G loss: 0.676455]\n",
      "[Epoch 1833/2000] [Batch 9/10] [D loss: 0.738664] [G loss: 0.679472]\n",
      "[Epoch 1834/2000] [Batch 9/10] [D loss: 0.737757] [G loss: 0.678720]\n",
      "[Epoch 1835/2000] [Batch 9/10] [D loss: 0.737787] [G loss: 0.676180]\n",
      "[Epoch 1836/2000] [Batch 9/10] [D loss: 0.735575] [G loss: 0.678251]\n",
      "[Epoch 1837/2000] [Batch 9/10] [D loss: 0.733432] [G loss: 0.680564]\n",
      "[Epoch 1838/2000] [Batch 9/10] [D loss: 0.733449] [G loss: 0.678478]\n",
      "[Epoch 1839/2000] [Batch 9/10] [D loss: 0.731495] [G loss: 0.680841]\n",
      "[Epoch 1840/2000] [Batch 9/10] [D loss: 0.730722] [G loss: 0.680836]\n",
      "[Epoch 1841/2000] [Batch 9/10] [D loss: 0.729535] [G loss: 0.681927]\n",
      "[Epoch 1842/2000] [Batch 9/10] [D loss: 0.729010] [G loss: 0.681852]\n",
      "[Epoch 1843/2000] [Batch 9/10] [D loss: 0.728184] [G loss: 0.682512]\n",
      "[Epoch 1844/2000] [Batch 9/10] [D loss: 0.727139] [G loss: 0.684142]\n",
      "[Epoch 1845/2000] [Batch 9/10] [D loss: 0.726281] [G loss: 0.685468]\n",
      "[Epoch 1846/2000] [Batch 9/10] [D loss: 0.725574] [G loss: 0.686406]\n",
      "[Epoch 1847/2000] [Batch 9/10] [D loss: 0.724070] [G loss: 0.689196]\n",
      "[Epoch 1848/2000] [Batch 9/10] [D loss: 0.722847] [G loss: 0.691392]\n",
      "[Epoch 1849/2000] [Batch 9/10] [D loss: 0.722057] [G loss: 0.692624]\n",
      "[Epoch 1850/2000] [Batch 9/10] [D loss: 0.721835] [G loss: 0.692668]\n",
      "[Epoch 1851/2000] [Batch 9/10] [D loss: 0.721176] [G loss: 0.693784]\n",
      "[Epoch 1852/2000] [Batch 9/10] [D loss: 0.719856] [G loss: 0.696168]\n",
      "[Epoch 1853/2000] [Batch 9/10] [D loss: 0.719516] [G loss: 0.696383]\n",
      "[Epoch 1854/2000] [Batch 9/10] [D loss: 0.719321] [G loss: 0.696292]\n",
      "[Epoch 1855/2000] [Batch 9/10] [D loss: 0.718591] [G loss: 0.697497]\n",
      "[Epoch 1856/2000] [Batch 9/10] [D loss: 0.718075] [G loss: 0.698268]\n",
      "[Epoch 1857/2000] [Batch 9/10] [D loss: 0.718861] [G loss: 0.696091]\n",
      "[Epoch 1858/2000] [Batch 9/10] [D loss: 0.717842] [G loss: 0.697946]\n",
      "[Epoch 1859/2000] [Batch 9/10] [D loss: 0.717503] [G loss: 0.698204]\n",
      "[Epoch 1860/2000] [Batch 9/10] [D loss: 0.716532] [G loss: 0.699800]\n",
      "[Epoch 1861/2000] [Batch 9/10] [D loss: 0.717744] [G loss: 0.697360]\n",
      "[Epoch 1862/2000] [Batch 9/10] [D loss: 0.717131] [G loss: 0.698472]\n",
      "[Epoch 1863/2000] [Batch 9/10] [D loss: 0.716912] [G loss: 0.698736]\n",
      "[Epoch 1864/2000] [Batch 9/10] [D loss: 0.717017] [G loss: 0.698670]\n",
      "[Epoch 1865/2000] [Batch 9/10] [D loss: 0.716256] [G loss: 0.700063]\n",
      "[Epoch 1866/2000] [Batch 9/10] [D loss: 0.716071] [G loss: 0.700719]\n",
      "[Epoch 1867/2000] [Batch 9/10] [D loss: 0.716202] [G loss: 0.700453]\n",
      "[Epoch 1868/2000] [Batch 9/10] [D loss: 0.715400] [G loss: 0.701983]\n",
      "[Epoch 1869/2000] [Batch 9/10] [D loss: 0.715124] [G loss: 0.702588]\n",
      "[Epoch 1870/2000] [Batch 9/10] [D loss: 0.714671] [G loss: 0.703700]\n",
      "[Epoch 1871/2000] [Batch 9/10] [D loss: 0.715482] [G loss: 0.702183]\n",
      "[Epoch 1872/2000] [Batch 9/10] [D loss: 0.713890] [G loss: 0.705173]\n",
      "[Epoch 1873/2000] [Batch 9/10] [D loss: 0.715174] [G loss: 0.702767]\n",
      "[Epoch 1874/2000] [Batch 9/10] [D loss: 0.714398] [G loss: 0.704343]\n",
      "[Epoch 1875/2000] [Batch 9/10] [D loss: 0.712986] [G loss: 0.707111]\n",
      "[Epoch 1876/2000] [Batch 9/10] [D loss: 0.712384] [G loss: 0.708247]\n",
      "[Epoch 1877/2000] [Batch 9/10] [D loss: 0.711991] [G loss: 0.709120]\n",
      "[Epoch 1878/2000] [Batch 9/10] [D loss: 0.708896] [G loss: 0.715285]\n",
      "[Epoch 1879/2000] [Batch 9/10] [D loss: 0.710791] [G loss: 0.711384]\n",
      "[Epoch 1880/2000] [Batch 9/10] [D loss: 0.710965] [G loss: 0.710671]\n",
      "[Epoch 1881/2000] [Batch 9/10] [D loss: 0.710066] [G loss: 0.712201]\n",
      "[Epoch 1882/2000] [Batch 9/10] [D loss: 0.710017] [G loss: 0.711998]\n",
      "[Epoch 1883/2000] [Batch 9/10] [D loss: 0.708374] [G loss: 0.714978]\n",
      "[Epoch 1884/2000] [Batch 9/10] [D loss: 0.707499] [G loss: 0.716534]\n",
      "[Epoch 1885/2000] [Batch 9/10] [D loss: 0.708312] [G loss: 0.714390]\n",
      "[Epoch 1886/2000] [Batch 9/10] [D loss: 0.706929] [G loss: 0.716479]\n",
      "[Epoch 1887/2000] [Batch 9/10] [D loss: 0.706204] [G loss: 0.717569]\n",
      "[Epoch 1888/2000] [Batch 9/10] [D loss: 0.706928] [G loss: 0.715422]\n",
      "[Epoch 1889/2000] [Batch 9/10] [D loss: 0.706286] [G loss: 0.716144]\n",
      "[Epoch 1890/2000] [Batch 9/10] [D loss: 0.705551] [G loss: 0.716862]\n",
      "[Epoch 1891/2000] [Batch 9/10] [D loss: 0.705667] [G loss: 0.715902]\n",
      "[Epoch 1892/2000] [Batch 9/10] [D loss: 0.704479] [G loss: 0.717528]\n",
      "[Epoch 1893/2000] [Batch 9/10] [D loss: 0.705020] [G loss: 0.715611]\n",
      "[Epoch 1894/2000] [Batch 9/10] [D loss: 0.704292] [G loss: 0.716356]\n",
      "[Epoch 1895/2000] [Batch 9/10] [D loss: 0.704276] [G loss: 0.715632]\n",
      "[Epoch 1896/2000] [Batch 9/10] [D loss: 0.703894] [G loss: 0.715698]\n",
      "[Epoch 1897/2000] [Batch 9/10] [D loss: 0.704738] [G loss: 0.712992]\n",
      "[Epoch 1898/2000] [Batch 9/10] [D loss: 0.705183] [G loss: 0.711158]\n",
      "[Epoch 1899/2000] [Batch 9/10] [D loss: 0.704921] [G loss: 0.710812]\n",
      "[Epoch 1900/2000] [Batch 9/10] [D loss: 0.705168] [G loss: 0.709304]\n",
      "[Epoch 1901/2000] [Batch 9/10] [D loss: 0.704808] [G loss: 0.708944]\n",
      "[Epoch 1902/2000] [Batch 9/10] [D loss: 0.705280] [G loss: 0.706988]\n",
      "[Epoch 1903/2000] [Batch 9/10] [D loss: 0.704911] [G loss: 0.706704]\n",
      "[Epoch 1904/2000] [Batch 9/10] [D loss: 0.705601] [G loss: 0.704279]\n",
      "[Epoch 1905/2000] [Batch 9/10] [D loss: 0.705877] [G loss: 0.702834]\n",
      "[Epoch 1906/2000] [Batch 9/10] [D loss: 0.705126] [G loss: 0.703209]\n",
      "[Epoch 1907/2000] [Batch 9/10] [D loss: 0.705672] [G loss: 0.701154]\n",
      "[Epoch 1908/2000] [Batch 9/10] [D loss: 0.705473] [G loss: 0.700628]\n",
      "[Epoch 1909/2000] [Batch 9/10] [D loss: 0.704988] [G loss: 0.700683]\n",
      "[Epoch 1910/2000] [Batch 9/10] [D loss: 0.706761] [G loss: 0.696165]\n",
      "[Epoch 1911/2000] [Batch 9/10] [D loss: 0.705622] [G loss: 0.697179]\n",
      "[Epoch 1912/2000] [Batch 9/10] [D loss: 0.706087] [G loss: 0.695433]\n",
      "[Epoch 1913/2000] [Batch 9/10] [D loss: 0.706367] [G loss: 0.693929]\n",
      "[Epoch 1914/2000] [Batch 9/10] [D loss: 0.705366] [G loss: 0.694677]\n",
      "[Epoch 1915/2000] [Batch 9/10] [D loss: 0.704968] [G loss: 0.694607]\n",
      "[Epoch 1916/2000] [Batch 9/10] [D loss: 0.705779] [G loss: 0.692052]\n",
      "[Epoch 1917/2000] [Batch 9/10] [D loss: 0.704286] [G loss: 0.693906]\n",
      "[Epoch 1918/2000] [Batch 9/10] [D loss: 0.704198] [G loss: 0.692972]\n",
      "[Epoch 1919/2000] [Batch 9/10] [D loss: 0.705564] [G loss: 0.689381]\n",
      "[Epoch 1920/2000] [Batch 9/10] [D loss: 0.703814] [G loss: 0.691518]\n",
      "[Epoch 1921/2000] [Batch 9/10] [D loss: 0.704947] [G loss: 0.688176]\n",
      "[Epoch 1922/2000] [Batch 9/10] [D loss: 0.703513] [G loss: 0.689979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1923/2000] [Batch 9/10] [D loss: 0.705449] [G loss: 0.685266]\n",
      "[Epoch 1924/2000] [Batch 9/10] [D loss: 0.704968] [G loss: 0.685054]\n",
      "[Epoch 1925/2000] [Batch 9/10] [D loss: 0.706049] [G loss: 0.681972]\n",
      "[Epoch 1926/2000] [Batch 9/10] [D loss: 0.705083] [G loss: 0.682891]\n",
      "[Epoch 1927/2000] [Batch 9/10] [D loss: 0.706766] [G loss: 0.678321]\n",
      "[Epoch 1928/2000] [Batch 9/10] [D loss: 0.706460] [G loss: 0.678041]\n",
      "[Epoch 1929/2000] [Batch 9/10] [D loss: 0.706839] [G loss: 0.676094]\n",
      "[Epoch 1930/2000] [Batch 9/10] [D loss: 0.706704] [G loss: 0.675859]\n",
      "[Epoch 1931/2000] [Batch 9/10] [D loss: 0.707145] [G loss: 0.674420]\n",
      "[Epoch 1932/2000] [Batch 9/10] [D loss: 0.706036] [G loss: 0.675930]\n",
      "[Epoch 1933/2000] [Batch 9/10] [D loss: 0.706666] [G loss: 0.674142]\n",
      "[Epoch 1934/2000] [Batch 9/10] [D loss: 0.707394] [G loss: 0.672342]\n",
      "[Epoch 1935/2000] [Batch 9/10] [D loss: 0.707406] [G loss: 0.671967]\n",
      "[Epoch 1936/2000] [Batch 9/10] [D loss: 0.706976] [G loss: 0.672539]\n",
      "[Epoch 1937/2000] [Batch 9/10] [D loss: 0.707373] [G loss: 0.671425]\n",
      "[Epoch 1938/2000] [Batch 9/10] [D loss: 0.706472] [G loss: 0.672744]\n",
      "[Epoch 1939/2000] [Batch 9/10] [D loss: 0.706391] [G loss: 0.672422]\n",
      "[Epoch 1940/2000] [Batch 9/10] [D loss: 0.707908] [G loss: 0.669277]\n",
      "[Epoch 1941/2000] [Batch 9/10] [D loss: 0.707255] [G loss: 0.670075]\n",
      "[Epoch 1942/2000] [Batch 9/10] [D loss: 0.706421] [G loss: 0.671490]\n",
      "[Epoch 1943/2000] [Batch 9/10] [D loss: 0.706375] [G loss: 0.671237]\n",
      "[Epoch 1944/2000] [Batch 9/10] [D loss: 0.706977] [G loss: 0.669772]\n",
      "[Epoch 1945/2000] [Batch 9/10] [D loss: 0.705679] [G loss: 0.672053]\n",
      "[Epoch 1946/2000] [Batch 9/10] [D loss: 0.705259] [G loss: 0.672643]\n",
      "[Epoch 1947/2000] [Batch 9/10] [D loss: 0.704543] [G loss: 0.673844]\n",
      "[Epoch 1948/2000] [Batch 9/10] [D loss: 0.704523] [G loss: 0.673764]\n",
      "[Epoch 1949/2000] [Batch 9/10] [D loss: 0.703056] [G loss: 0.676519]\n",
      "[Epoch 1950/2000] [Batch 9/10] [D loss: 0.702848] [G loss: 0.676937]\n",
      "[Epoch 1951/2000] [Batch 9/10] [D loss: 0.703018] [G loss: 0.676333]\n",
      "[Epoch 1952/2000] [Batch 9/10] [D loss: 0.702337] [G loss: 0.677661]\n",
      "[Epoch 1953/2000] [Batch 9/10] [D loss: 0.701292] [G loss: 0.679646]\n",
      "[Epoch 1954/2000] [Batch 9/10] [D loss: 0.700658] [G loss: 0.680654]\n",
      "[Epoch 1955/2000] [Batch 9/10] [D loss: 0.700575] [G loss: 0.680774]\n",
      "[Epoch 1956/2000] [Batch 9/10] [D loss: 0.699224] [G loss: 0.683241]\n",
      "[Epoch 1957/2000] [Batch 9/10] [D loss: 0.699082] [G loss: 0.683359]\n",
      "[Epoch 1958/2000] [Batch 9/10] [D loss: 0.698341] [G loss: 0.684648]\n",
      "[Epoch 1959/2000] [Batch 9/10] [D loss: 0.698166] [G loss: 0.684637]\n",
      "[Epoch 1960/2000] [Batch 9/10] [D loss: 0.697484] [G loss: 0.685907]\n",
      "[Epoch 1961/2000] [Batch 9/10] [D loss: 0.696387] [G loss: 0.687790]\n",
      "[Epoch 1962/2000] [Batch 9/10] [D loss: 0.695424] [G loss: 0.689559]\n",
      "[Epoch 1963/2000] [Batch 9/10] [D loss: 0.695606] [G loss: 0.688932]\n",
      "[Epoch 1964/2000] [Batch 9/10] [D loss: 0.695139] [G loss: 0.689543]\n",
      "[Epoch 1965/2000] [Batch 9/10] [D loss: 0.693808] [G loss: 0.691864]\n",
      "[Epoch 1966/2000] [Batch 9/10] [D loss: 0.693148] [G loss: 0.692996]\n",
      "[Epoch 1967/2000] [Batch 9/10] [D loss: 0.693224] [G loss: 0.692522]\n",
      "[Epoch 1968/2000] [Batch 9/10] [D loss: 0.692075] [G loss: 0.694398]\n",
      "[Epoch 1969/2000] [Batch 9/10] [D loss: 0.691563] [G loss: 0.694976]\n",
      "[Epoch 1970/2000] [Batch 9/10] [D loss: 0.691478] [G loss: 0.694594]\n",
      "[Epoch 1971/2000] [Batch 9/10] [D loss: 0.690391] [G loss: 0.696298]\n",
      "[Epoch 1972/2000] [Batch 9/10] [D loss: 0.690611] [G loss: 0.695219]\n",
      "[Epoch 1973/2000] [Batch 9/10] [D loss: 0.690570] [G loss: 0.694821]\n",
      "[Epoch 1974/2000] [Batch 9/10] [D loss: 0.690044] [G loss: 0.695123]\n",
      "[Epoch 1975/2000] [Batch 9/10] [D loss: 0.690124] [G loss: 0.694282]\n",
      "[Epoch 1976/2000] [Batch 9/10] [D loss: 0.689610] [G loss: 0.694492]\n",
      "[Epoch 1977/2000] [Batch 9/10] [D loss: 0.689803] [G loss: 0.693095]\n",
      "[Epoch 1978/2000] [Batch 9/10] [D loss: 0.689327] [G loss: 0.693006]\n",
      "[Epoch 1979/2000] [Batch 9/10] [D loss: 0.690284] [G loss: 0.690062]\n",
      "[Epoch 1980/2000] [Batch 9/10] [D loss: 0.689750] [G loss: 0.689895]\n",
      "[Epoch 1981/2000] [Batch 9/10] [D loss: 0.689861] [G loss: 0.688419]\n",
      "[Epoch 1982/2000] [Batch 9/10] [D loss: 0.689438] [G loss: 0.687848]\n",
      "[Epoch 1983/2000] [Batch 9/10] [D loss: 0.690872] [G loss: 0.683588]\n",
      "[Epoch 1984/2000] [Batch 9/10] [D loss: 0.690599] [G loss: 0.682558]\n",
      "[Epoch 1985/2000] [Batch 9/10] [D loss: 0.690223] [G loss: 0.681754]\n",
      "[Epoch 1986/2000] [Batch 9/10] [D loss: 0.691619] [G loss: 0.677482]\n",
      "[Epoch 1987/2000] [Batch 9/10] [D loss: 0.690121] [G loss: 0.678565]\n",
      "[Epoch 1988/2000] [Batch 9/10] [D loss: 0.689817] [G loss: 0.677515]\n",
      "[Epoch 1989/2000] [Batch 9/10] [D loss: 0.689173] [G loss: 0.676922]\n",
      "[Epoch 1990/2000] [Batch 9/10] [D loss: 0.689393] [G loss: 0.674922]\n",
      "[Epoch 1991/2000] [Batch 9/10] [D loss: 0.689148] [G loss: 0.673960]\n",
      "[Epoch 1992/2000] [Batch 9/10] [D loss: 0.689185] [G loss: 0.672654]\n",
      "[Epoch 1993/2000] [Batch 9/10] [D loss: 0.688150] [G loss: 0.673216]\n",
      "[Epoch 1994/2000] [Batch 9/10] [D loss: 0.688469] [G loss: 0.671370]\n",
      "[Epoch 1995/2000] [Batch 9/10] [D loss: 0.687573] [G loss: 0.671726]\n",
      "[Epoch 1996/2000] [Batch 9/10] [D loss: 0.686512] [G loss: 0.672644]\n",
      "[Epoch 1997/2000] [Batch 9/10] [D loss: 0.686745] [G loss: 0.671026]\n",
      "[Epoch 1998/2000] [Batch 9/10] [D loss: 0.686835] [G loss: 0.670256]\n",
      "[Epoch 1999/2000] [Batch 9/10] [D loss: 0.688288] [G loss: 0.666878]\n"
     ]
    }
   ],
   "source": [
    "generator_loss = []\n",
    "discriminator_loss = []\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, _) in enumerate(train_loader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "    print(\n",
    "        \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "        % (epoch, n_epochs, i, len(train_loader), d_loss.item(), g_loss.item())\n",
    "    )\n",
    "    \n",
    "    generator_loss.append(d_loss.item())\n",
    "    discriminator_loss.append(g_loss.item())\n",
    "\n",
    "        #batches_done = epoch * len(train_loader) + i\n",
    "        #if batches_done % sample_interval == 0:\n",
    "            #save_image(gen_imgs.data[:25], \"images_generated/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "    torch.save(generator.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))\n",
    "    torch.save(discriminator.state_dict(), '%s/netD_epoch_%d.pth' % (outf, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([generator_loss, discriminator_loss], open('gen_dis_loss3.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate results for Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "[mean_MNpdf, cov_MNpdf] = torch.load( 'MultiVariateNormalParameters.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    mean_MNpdf = mean_MNpdf.cuda()\n",
    "    cov_MNpdf = cov_MNpdf.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_generate_images = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=8, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (2): Linear(in_features=8, out_features=16, bias=True)\n",
       "    (3): BatchNorm1d(16, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (5): Linear(in_features=16, out_features=32, bias=True)\n",
       "    (6): BatchNorm1d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (8): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (9): BatchNorm1d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (11): Linear(in_features=64, out_features=25, bias=True)\n",
       "    (12): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_cov = torch.inverse(cov_MNpdf)\n",
    "determinant_cov = torch.cholesky(cov_MNpdf).diag().prod()\n",
    "const_part = -(img_size*img_size)/2 * torch.log(torch.tensor(2*3.141592653)) - 1/2*torch.log(determinant_cov)\n",
    "\n",
    "def pdf(X):\n",
    "    X_flattened =  X.flatten()\n",
    "    diff = (X_flattened - mean_MNpdf)\n",
    "    pdf_value = torch.matmul( torch.matmul(diff.reshape(1,-1), inverse_cov), diff)[0]\n",
    "    return -1/2*pdf_value + const_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample noise as generator input\n",
    "z = Variable(Tensor(np.random.normal(0, 1, (batch_size, latent_dim))))\n",
    "\n",
    "# Generate a batch of images\n",
    "gen_imgs = generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 5, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_log_likelihood = 0\n",
    "for each_img in gen_imgs:\n",
    "    tot_log_likelihood +=   pdf( each_img.squeeze(0) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-34720.4844, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = multivariate_normal(mean=np.zeros(28*28), cov=np.eye(28*28,28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_x = np.random.multivariate_normal(np.zeros(28*28), np.eye(28*28,28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_x = np.random.uniform(high=1, low=0, size=784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword can't be an expression (<ipython-input-33-de24086a803a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-de24086a803a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    np.random.normal(loc=0, scale=1, s-ze=1)\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword can't be an expression\n"
     ]
    }
   ],
   "source": [
    "np.random.normal(loc=0, scale=1, s-ze=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.pdf(my_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_list = []\n",
    "for each_img in gen_imgs:\n",
    "    my_x = each_img.squeeze(0).cpu().detach().numpy()\n",
    "    my_x = my_x.flatten()\n",
    "    probs = multivariate_normal.pdf(my_x, mean=np.zeros(28*28), cov=np.eye(28*28,28*28))\n",
    "    prob_list.append(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
